#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
VisionAI-ClipsMaster æ€§èƒ½åˆ†æå·¥å…·
åˆ†æå½“å‰ç³»ç»Ÿçš„æ€§èƒ½çŠ¶å†µï¼Œè¯†åˆ«ä¼˜åŒ–ç‚¹
"""

import sys
import os
import time
import psutil
import gc
from pathlib import Path
sys.path.append('.')

def analyze_startup_performance():
    """åˆ†æå¯åŠ¨æ€§èƒ½"""
    print("ğŸš€ å¯åŠ¨æ€§èƒ½åˆ†æ")
    print("-" * 50)
    
    startup_times = {}
    
    # æµ‹è¯•æ ¸å¿ƒæ¨¡å—å¯¼å…¥æ—¶é—´
    modules_to_test = [
        ('screenplay_engineer', 'src.core.screenplay_engineer'),
        ('model_switcher', 'src.core.model_switcher'),
        ('language_detector', 'src.core.language_detector'),
        ('jianying_exporter', 'src.exporters.jianying_pro_exporter'),
    ]
    
    for module_name, module_path in modules_to_test:
        start_time = time.time()
        try:
            __import__(module_path)
            import_time = time.time() - start_time
            startup_times[module_name] = import_time
            print(f"âœ… {module_name}: {import_time:.3f}ç§’")
        except Exception as e:
            print(f"âŒ {module_name}: å¯¼å…¥å¤±è´¥ - {e}")
            startup_times[module_name] = -1
    
    total_startup_time = sum(t for t in startup_times.values() if t > 0)
    print(f"\nğŸ“Š æ€»å¯åŠ¨æ—¶é—´: {total_startup_time:.3f}ç§’")
    
    # è¯„ä¼°å¯åŠ¨æ€§èƒ½
    if total_startup_time <= 5.0:
        print("ğŸ‰ å¯åŠ¨æ€§èƒ½ä¼˜ç§€ (â‰¤5ç§’)")
    elif total_startup_time <= 10.0:
        print("âœ… å¯åŠ¨æ€§èƒ½è‰¯å¥½ (â‰¤10ç§’)")
    else:
        print("âš ï¸  å¯åŠ¨æ€§èƒ½éœ€è¦ä¼˜åŒ– (>10ç§’)")
    
    return startup_times

def analyze_memory_usage():
    """åˆ†æå†…å­˜ä½¿ç”¨æƒ…å†µ"""
    print("\nğŸ’¾ å†…å­˜ä½¿ç”¨åˆ†æ")
    print("-" * 50)
    
    # è·å–ç³»ç»Ÿå†…å­˜ä¿¡æ¯
    memory = psutil.virtual_memory()
    print(f"ç³»ç»Ÿæ€»å†…å­˜: {memory.total / 1024**3:.2f} GB")
    print(f"å¯ç”¨å†…å­˜: {memory.available / 1024**3:.2f} GB")
    print(f"å†…å­˜ä½¿ç”¨ç‡: {memory.percent:.1f}%")
    
    # è·å–å½“å‰è¿›ç¨‹å†…å­˜ä½¿ç”¨
    process = psutil.Process()
    memory_info = process.memory_info()
    print(f"å½“å‰è¿›ç¨‹å†…å­˜: {memory_info.rss / 1024**2:.2f} MB")
    
    # æµ‹è¯•æ¨¡å—åŠ è½½åçš„å†…å­˜ä½¿ç”¨
    print("\næ¨¡å—åŠ è½½å†…å­˜å½±å“:")
    
    # è®°å½•åŸºå‡†å†…å­˜
    gc.collect()
    baseline_memory = process.memory_info().rss
    
    # æµ‹è¯•åŠ è½½å¤§å‹æ¨¡å—
    try:
        import torch
        torch_memory = process.memory_info().rss
        torch_impact = (torch_memory - baseline_memory) / 1024**2
        print(f"PyTorchåŠ è½½: +{torch_impact:.2f} MB")
    except ImportError:
        print("PyTorchæœªå®‰è£…")
    
    # è¯„ä¼°å†…å­˜ä½¿ç”¨
    current_memory_mb = memory_info.rss / 1024**2
    if current_memory_mb <= 400:
        print(f"ğŸ‰ å†…å­˜ä½¿ç”¨ä¼˜ç§€ ({current_memory_mb:.1f}MB â‰¤ 400MB)")
    elif current_memory_mb <= 800:
        print(f"âœ… å†…å­˜ä½¿ç”¨è‰¯å¥½ ({current_memory_mb:.1f}MB â‰¤ 800MB)")
    else:
        print(f"âš ï¸  å†…å­˜ä½¿ç”¨éœ€è¦ä¼˜åŒ– ({current_memory_mb:.1f}MB > 800MB)")
    
    return {
        "total_memory_gb": memory.total / 1024**3,
        "available_memory_gb": memory.available / 1024**3,
        "memory_usage_percent": memory.percent,
        "process_memory_mb": memory_info.rss / 1024**2
    }

def analyze_file_structure():
    """åˆ†ææ–‡ä»¶ç»“æ„å’Œå¤§å°"""
    print("\nğŸ“ æ–‡ä»¶ç»“æ„åˆ†æ")
    print("-" * 50)
    
    project_root = Path('.')
    
    # ç»Ÿè®¡å„ç±»æ–‡ä»¶
    file_stats = {
        'python_files': 0,
        'config_files': 0,
        'model_files': 0,
        'test_files': 0,
        'total_size_mb': 0
    }
    
    for file_path in project_root.rglob('*'):
        if file_path.is_file():
            file_size = file_path.stat().st_size
            file_stats['total_size_mb'] += file_size / 1024**2
            
            if file_path.suffix == '.py':
                file_stats['python_files'] += 1
            elif file_path.suffix in ['.yaml', '.json', '.ini']:
                file_stats['config_files'] += 1
            elif 'model' in str(file_path).lower():
                file_stats['model_files'] += 1
            elif 'test' in str(file_path).lower():
                file_stats['test_files'] += 1
    
    print(f"Pythonæ–‡ä»¶: {file_stats['python_files']}")
    print(f"é…ç½®æ–‡ä»¶: {file_stats['config_files']}")
    print(f"æ¨¡å‹æ–‡ä»¶: {file_stats['model_files']}")
    print(f"æµ‹è¯•æ–‡ä»¶: {file_stats['test_files']}")
    print(f"é¡¹ç›®æ€»å¤§å°: {file_stats['total_size_mb']:.2f} MB")
    
    return file_stats

def generate_optimization_recommendations(startup_times, memory_stats, file_stats):
    """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
    print("\nğŸ¯ ä¼˜åŒ–å»ºè®®")
    print("=" * 50)
    
    recommendations = []
    
    # å¯åŠ¨æ—¶é—´ä¼˜åŒ–å»ºè®®
    total_startup = sum(t for t in startup_times.values() if t > 0)
    if total_startup > 5.0:
        recommendations.append({
            "category": "å¯åŠ¨ä¼˜åŒ–",
            "priority": "é«˜",
            "suggestion": "å®æ–½å»¶è¿ŸåŠ è½½æœºåˆ¶ï¼Œå°†éæ ¸å¿ƒæ¨¡å—æ”¹ä¸ºæŒ‰éœ€å¯¼å…¥",
            "expected_improvement": f"é¢„è®¡å¯å‡å°‘{(total_startup - 3.0):.1f}ç§’å¯åŠ¨æ—¶é—´"
        })
    
    # å†…å­˜ä¼˜åŒ–å»ºè®®
    if memory_stats['process_memory_mb'] > 400:
        recommendations.append({
            "category": "å†…å­˜ä¼˜åŒ–",
            "priority": "é«˜",
            "suggestion": "å®æ–½å†…å­˜æ± ç®¡ç†å’Œæ™ºèƒ½åƒåœ¾å›æ”¶æœºåˆ¶",
            "expected_improvement": f"é¢„è®¡å¯å‡å°‘{(memory_stats['process_memory_mb'] - 300):.0f}MBå†…å­˜ä½¿ç”¨"
        })
    
    # æ–‡ä»¶ç»“æ„ä¼˜åŒ–å»ºè®®
    if file_stats['total_size_mb'] > 100:
        recommendations.append({
            "category": "å­˜å‚¨ä¼˜åŒ–",
            "priority": "ä¸­",
            "suggestion": "æ¸…ç†å†—ä½™æ–‡ä»¶ï¼Œå‹ç¼©é™æ€èµ„æº",
            "expected_improvement": f"é¢„è®¡å¯å‡å°‘{(file_stats['total_size_mb'] * 0.3):.0f}MBå­˜å‚¨ç©ºé—´"
        })
    
    # è¾“å‡ºå»ºè®®
    for i, rec in enumerate(recommendations, 1):
        print(f"\n{i}. {rec['category']} (ä¼˜å…ˆçº§: {rec['priority']})")
        print(f"   å»ºè®®: {rec['suggestion']}")
        print(f"   é¢„æœŸæ•ˆæœ: {rec['expected_improvement']}")
    
    if not recommendations:
        print("ğŸ‰ å½“å‰æ€§èƒ½è¡¨ç°è‰¯å¥½ï¼Œæ— éœ€ç‰¹åˆ«ä¼˜åŒ–ï¼")
    
    return recommendations

def main():
    """ä¸»å‡½æ•°"""
    print("=== VisionAI-ClipsMaster æ€§èƒ½åˆ†ææŠ¥å‘Š ===")
    print(f"åˆ†ææ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # æ‰§è¡Œå„é¡¹åˆ†æ
    startup_times = analyze_startup_performance()
    memory_stats = analyze_memory_usage()
    file_stats = analyze_file_structure()
    
    # ç”Ÿæˆä¼˜åŒ–å»ºè®®
    recommendations = generate_optimization_recommendations(
        startup_times, memory_stats, file_stats
    )
    
    # ç”Ÿæˆæ€»ç»“
    print("\nğŸ“‹ æ€§èƒ½åˆ†ææ€»ç»“")
    print("=" * 50)
    
    total_startup = sum(t for t in startup_times.values() if t > 0)
    memory_mb = memory_stats['process_memory_mb']
    
    performance_score = 100
    if total_startup > 5.0:
        performance_score -= 20
    if memory_mb > 400:
        performance_score -= 20
    if len(recommendations) > 2:
        performance_score -= 10
    
    print(f"æ€§èƒ½è¯„åˆ†: {performance_score}/100")
    
    if performance_score >= 90:
        print("ğŸ† æ€§èƒ½ä¼˜ç§€ï¼Œç³»ç»Ÿè¿è¡Œæµç•…")
    elif performance_score >= 70:
        print("âœ… æ€§èƒ½è‰¯å¥½ï¼Œå¯è¿›è¡Œå°å¹…ä¼˜åŒ–")
    else:
        print("âš ï¸  æ€§èƒ½éœ€è¦æ”¹è¿›ï¼Œå»ºè®®å®æ–½ä¼˜åŒ–æªæ–½")
    
    return {
        "startup_times": startup_times,
        "memory_stats": memory_stats,
        "file_stats": file_stats,
        "recommendations": recommendations,
        "performance_score": performance_score
    }

if __name__ == "__main__":
    main()
