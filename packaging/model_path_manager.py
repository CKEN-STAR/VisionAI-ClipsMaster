#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
VisionAI-ClipsMaster æ¨¡å‹è·¯å¾„ç®¡ç†å™¨
ç¡®ä¿æ‰€æœ‰AIæ¨¡å‹å­˜å‚¨åœ¨æ•´åˆåŒ…å†…éƒ¨ï¼Œå®ç°å®Œå…¨è‡ªåŒ…å«
"""

import os
import sys
import json
import shutil
from pathlib import Path
from typing import Dict, Optional, List
import tempfile

class ModelPathManager:
    """æ¨¡å‹è·¯å¾„ç®¡ç†å™¨ - ç¡®ä¿å®Œå…¨è‡ªåŒ…å«"""
    
    def __init__(self):
        # è·å–åº”ç”¨æ ¹ç›®å½•
        if getattr(sys, 'frozen', False):
            # æ‰“åŒ…åçš„å¯æ‰§è¡Œæ–‡ä»¶ç¯å¢ƒ
            self.app_root = Path(sys.executable).parent
        else:
            # å¼€å‘ç¯å¢ƒ
            self.app_root = Path(__file__).parent.parent
        
        # å†…éƒ¨æ¨¡å‹å­˜å‚¨è·¯å¾„
        self.models_root = self.app_root / "models"
        self.downloaded_models = self.models_root / "downloaded"
        self.cache_dir = self.models_root / "cache"
        self.temp_dir = self.models_root / "temp"
        
        # é…ç½®æ–‡ä»¶
        self.config_file = self.models_root / "path_config.json"
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self._ensure_directories()
        
        # é‡å®šå‘ç¯å¢ƒå˜é‡
        self._setup_environment_variables()
    
    def _ensure_directories(self):
        """ç¡®ä¿æ‰€æœ‰å¿…è¦ç›®å½•å­˜åœ¨"""
        directories = [
            self.models_root,
            self.downloaded_models,
            self.cache_dir,
            self.temp_dir
        ]
        
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
    
    def _setup_environment_variables(self):
        """è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œé‡å®šå‘æ¨¡å‹ç¼“å­˜åˆ°å†…éƒ¨ç›®å½•"""
        # HuggingFaceç¼“å­˜ç›®å½•
        os.environ['HF_HOME'] = str(self.cache_dir)
        os.environ['HUGGINGFACE_HUB_CACHE'] = str(self.cache_dir / "hub")
        os.environ['TRANSFORMERS_CACHE'] = str(self.cache_dir / "transformers")
        
        # PyTorchç¼“å­˜ç›®å½•
        os.environ['TORCH_HOME'] = str(self.cache_dir / "torch")
        
        # ä¸´æ—¶ç›®å½•
        os.environ['TMPDIR'] = str(self.temp_dir)
        os.environ['TEMP'] = str(self.temp_dir)
        os.environ['TMP'] = str(self.temp_dir)
        
        # ç¦ç”¨å¤–éƒ¨ç¼“å­˜
        os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = "1"
        os.environ['HF_HUB_DISABLE_EXPERIMENTAL_WARNING'] = "1"
    
    def get_model_path(self, model_name: str) -> Path:
        """è·å–æ¨¡å‹çš„å†…éƒ¨å­˜å‚¨è·¯å¾„"""
        return self.downloaded_models / model_name
    
    def is_model_available(self, model_name: str) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½åˆ°å†…éƒ¨ç›®å½•"""
        model_path = self.get_model_path(model_name)
        return model_path.exists() and any(model_path.iterdir())
    
    def get_available_models(self) -> List[str]:
        """è·å–æ‰€æœ‰å·²ä¸‹è½½çš„æ¨¡å‹åˆ—è¡¨"""
        if not self.downloaded_models.exists():
            return []
        
        return [d.name for d in self.downloaded_models.iterdir() if d.is_dir()]
    
    def download_model_to_internal(self, model_name: str, repo_id: str, 
                                 progress_callback=None) -> bool:
        """ä¸‹è½½æ¨¡å‹åˆ°å†…éƒ¨ç›®å½•"""
        try:
            from huggingface_hub import snapshot_download
            
            model_path = self.get_model_path(model_name)
            
            if progress_callback:
                progress_callback(f"å¼€å§‹ä¸‹è½½æ¨¡å‹: {model_name}")
            
            # ä¸‹è½½åˆ°å†…éƒ¨ç›®å½•
            snapshot_download(
                repo_id=repo_id,
                local_dir=str(model_path),
                local_dir_use_symlinks=False,  # ä¸ä½¿ç”¨ç¬¦å·é“¾æ¥
                cache_dir=str(self.cache_dir / "hub"),
                resume_download=True
            )
            
            if progress_callback:
                progress_callback(f"æ¨¡å‹ä¸‹è½½å®Œæˆ: {model_name}")
            
            # æ›´æ–°é…ç½®
            self._update_model_config(model_name, repo_id, str(model_path))
            
            return True
            
        except Exception as e:
            if progress_callback:
                progress_callback(f"æ¨¡å‹ä¸‹è½½å¤±è´¥: {model_name} - {e}")
            return False
    
    def _update_model_config(self, model_name: str, repo_id: str, local_path: str):
        """æ›´æ–°æ¨¡å‹é…ç½®æ–‡ä»¶"""
        config = self._load_config()
        
        config["models"][model_name] = {
            "repo_id": repo_id,
            "local_path": local_path,
            "download_time": self._get_current_time(),
            "status": "available"
        }
        
        self._save_config(config)
    
    def _load_config(self) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if self.config_file.exists():
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                pass
        
        # é»˜è®¤é…ç½®
        return {
            "app_root": str(self.app_root),
            "models_root": str(self.models_root),
            "cache_dir": str(self.cache_dir),
            "models": {}
        }
    
    def _save_config(self, config: Dict):
        """ä¿å­˜é…ç½®æ–‡ä»¶"""
        with open(self.config_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
    
    def _get_current_time(self) -> str:
        """è·å–å½“å‰æ—¶é—´å­—ç¬¦ä¸²"""
        from datetime import datetime
        return datetime.now().isoformat()
    
    def cleanup_external_caches(self):
        """æ¸…ç†å¯èƒ½å­˜åœ¨çš„å¤–éƒ¨ç¼“å­˜"""
        external_cache_dirs = [
            Path.home() / ".cache" / "huggingface",
            Path.home() / ".cache" / "torch",
            Path.home() / "AppData" / "Local" / "huggingface",  # Windows
        ]
        
        for cache_dir in external_cache_dirs:
            if cache_dir.exists():
                try:
                    # ä¸ç›´æ¥åˆ é™¤ï¼Œè€Œæ˜¯ç§»åŠ¨åˆ°å†…éƒ¨ç¼“å­˜
                    if cache_dir.name == "huggingface":
                        target_dir = self.cache_dir / "imported_hf_cache"
                        if not target_dir.exists():
                            shutil.move(str(cache_dir), str(target_dir))
                except Exception as e:
                    print(f"æ¸…ç†å¤–éƒ¨ç¼“å­˜å¤±è´¥: {e}")
    
    def get_total_size(self) -> int:
        """è·å–æ¨¡å‹ç›®å½•æ€»å¤§å°ï¼ˆå­—èŠ‚ï¼‰"""
        total_size = 0
        for path in self.models_root.rglob('*'):
            if path.is_file():
                total_size += path.stat().st_size
        return total_size
    
    def get_size_info(self) -> Dict:
        """è·å–è¯¦ç»†çš„å¤§å°ä¿¡æ¯"""
        info = {
            "total_size_mb": self.get_total_size() / 1024 / 1024,
            "models": {}
        }
        
        for model_name in self.get_available_models():
            model_path = self.get_model_path(model_name)
            model_size = sum(f.stat().st_size for f in model_path.rglob('*') if f.is_file())
            info["models"][model_name] = {
                "size_mb": model_size / 1024 / 1024,
                "path": str(model_path)
            }
        
        return info
    
    def verify_self_contained(self) -> Dict:
        """éªŒè¯æ˜¯å¦å®Œå…¨è‡ªåŒ…å«"""
        verification = {
            "is_self_contained": True,
            "issues": [],
            "external_dependencies": []
        }
        
        # æ£€æŸ¥ç¯å¢ƒå˜é‡æ˜¯å¦æ­£ç¡®è®¾ç½®
        required_env_vars = [
            "HF_HOME", "HUGGINGFACE_HUB_CACHE", 
            "TRANSFORMERS_CACHE", "TORCH_HOME"
        ]
        
        for var in required_env_vars:
            if var not in os.environ:
                verification["issues"].append(f"ç¯å¢ƒå˜é‡ {var} æœªè®¾ç½®")
                verification["is_self_contained"] = False
            else:
                env_path = Path(os.environ[var])
                if not str(env_path).startswith(str(self.app_root)):
                    verification["external_dependencies"].append(f"{var}: {env_path}")
                    verification["is_self_contained"] = False
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦éƒ½åœ¨å†…éƒ¨ç›®å½•
        config = self._load_config()
        for model_name, model_info in config.get("models", {}).items():
            model_path = Path(model_info["local_path"])
            if not str(model_path).startswith(str(self.app_root)):
                verification["external_dependencies"].append(f"æ¨¡å‹ {model_name}: {model_path}")
                verification["is_self_contained"] = False
        
        return verification

class ModelDownloadUI:
    """æ¨¡å‹ä¸‹è½½ç”¨æˆ·ç•Œé¢"""
    
    def __init__(self, path_manager: ModelPathManager):
        self.path_manager = path_manager
        self.models_to_download = {
            "mistral-7b-en": "mistralai/Mistral-7B-Instruct-v0.2",
            "qwen2.5-7b-zh": "Qwen/Qwen2.5-7B-Instruct"
        }
    
    def check_and_download_models(self) -> bool:
        """æ£€æŸ¥å¹¶ä¸‹è½½ç¼ºå¤±çš„æ¨¡å‹"""
        missing_models = []
        
        for model_name in self.models_to_download:
            if not self.path_manager.is_model_available(model_name):
                missing_models.append(model_name)
        
        if not missing_models:
            print("âœ… æ‰€æœ‰æ¨¡å‹å·²å°±ç»ª")
            return True
        
        print(f"ğŸ“¥ éœ€è¦ä¸‹è½½ {len(missing_models)} ä¸ªæ¨¡å‹")
        
        for model_name in missing_models:
            repo_id = self.models_to_download[model_name]
            print(f"æ­£åœ¨ä¸‹è½½: {model_name}")
            
            success = self.path_manager.download_model_to_internal(
                model_name, repo_id, self._progress_callback
            )
            
            if not success:
                print(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {model_name}")
                return False
        
        print("âœ… æ‰€æœ‰æ¨¡å‹ä¸‹è½½å®Œæˆ")
        return True
    
    def _progress_callback(self, message: str):
        """è¿›åº¦å›è°ƒå‡½æ•°"""
        print(f"   {message}")

# å…¨å±€å®ä¾‹
_path_manager = None

def get_model_path_manager() -> ModelPathManager:
    """è·å–å…¨å±€æ¨¡å‹è·¯å¾„ç®¡ç†å™¨å®ä¾‹"""
    global _path_manager
    if _path_manager is None:
        _path_manager = ModelPathManager()
    return _path_manager

def ensure_models_available() -> bool:
    """ç¡®ä¿æ‰€æœ‰å¿…éœ€æ¨¡å‹å¯ç”¨"""
    path_manager = get_model_path_manager()
    download_ui = ModelDownloadUI(path_manager)
    return download_ui.check_and_download_models()

if __name__ == "__main__":
    # æµ‹è¯•æ¨¡å‹è·¯å¾„ç®¡ç†å™¨
    manager = get_model_path_manager()
    
    print("æ¨¡å‹è·¯å¾„ç®¡ç†å™¨ä¿¡æ¯:")
    print(f"åº”ç”¨æ ¹ç›®å½•: {manager.app_root}")
    print(f"æ¨¡å‹ç›®å½•: {manager.models_root}")
    print(f"ä¸‹è½½ç›®å½•: {manager.downloaded_models}")
    
    # éªŒè¯è‡ªåŒ…å«æ€§
    verification = manager.verify_self_contained()
    print(f"\nè‡ªåŒ…å«éªŒè¯: {'âœ… é€šè¿‡' if verification['is_self_contained'] else 'âŒ å¤±è´¥'}")
    
    if verification["issues"]:
        print("é—®é¢˜:")
        for issue in verification["issues"]:
            print(f"  - {issue}")
    
    if verification["external_dependencies"]:
        print("å¤–éƒ¨ä¾èµ–:")
        for dep in verification["external_dependencies"]:
            print(f"  - {dep}")
    
    # æ˜¾ç¤ºå¤§å°ä¿¡æ¯
    size_info = manager.get_size_info()
    print(f"\næ€»å¤§å°: {size_info['total_size_mb']:.1f} MB")
    
    for model_name, model_info in size_info["models"].items():
        print(f"  {model_name}: {model_info['size_mb']:.1f} MB")
