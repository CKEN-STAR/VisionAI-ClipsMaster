#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
VisionAI-ClipsMaster æ€§èƒ½å’Œç¨³å®šæ€§ä¸“é¡¹æµ‹è¯•
æµ‹è¯•ç³»ç»Ÿåœ¨å„ç§è´Ÿè½½æ¡ä»¶ä¸‹çš„è¡¨ç°
"""

import time
import psutil
import threading
import multiprocessing
import gc
import sys
import os
from pathlib import Path
from typing import List, Dict, Any
import json
import tempfile
from datetime import datetime, timedelta

class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self):
        self.monitoring = False
        self.metrics = {
            'memory_usage': [],
            'cpu_usage': [],
            'timestamps': []
        }
        self.monitor_thread = None
    
    def start_monitoring(self, interval=1.0):
        """å¼€å§‹ç›‘æ§"""
        self.monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop, args=(interval,))
        self.monitor_thread.daemon = True
        self.monitor_thread.start()
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=2)
    
    def _monitor_loop(self, interval):
        """ç›‘æ§å¾ªç¯"""
        process = psutil.Process()
        
        while self.monitoring:
            try:
                # è®°å½•å†…å­˜ä½¿ç”¨
                memory_info = process.memory_info()
                memory_mb = memory_info.rss / (1024 * 1024)
                
                # è®°å½•CPUä½¿ç”¨
                cpu_percent = process.cpu_percent()
                
                # è®°å½•æ—¶é—´æˆ³
                timestamp = time.time()
                
                self.metrics['memory_usage'].append(memory_mb)
                self.metrics['cpu_usage'].append(cpu_percent)
                self.metrics['timestamps'].append(timestamp)
                
                time.sleep(interval)
            except Exception as e:
                print(f"ç›‘æ§å¼‚å¸¸: {e}")
                break
    
    def get_peak_memory(self) -> float:
        """è·å–å³°å€¼å†…å­˜ä½¿ç”¨"""
        if self.metrics['memory_usage']:
            return max(self.metrics['memory_usage'])
        return 0.0
    
    def get_average_cpu(self) -> float:
        """è·å–å¹³å‡CPUä½¿ç”¨ç‡"""
        if self.metrics['cpu_usage']:
            return sum(self.metrics['cpu_usage']) / len(self.metrics['cpu_usage'])
        return 0.0
    
    def get_metrics_summary(self) -> Dict[str, Any]:
        """è·å–æŒ‡æ ‡æ‘˜è¦"""
        return {
            'peak_memory_mb': self.get_peak_memory(),
            'average_cpu_percent': self.get_average_cpu(),
            'total_samples': len(self.metrics['memory_usage']),
            'monitoring_duration': (
                self.metrics['timestamps'][-1] - self.metrics['timestamps'][0]
                if len(self.metrics['timestamps']) > 1 else 0
            )
        }

class MemoryStressTest:
    """å†…å­˜å‹åŠ›æµ‹è¯•"""
    
    def __init__(self):
        self.test_results = {}
    
    def test_memory_limit_compliance(self, limit_mb=3800):
        """æµ‹è¯•å†…å­˜é™åˆ¶åˆè§„æ€§"""
        print(f"ğŸ§ª æµ‹è¯•å†…å­˜é™åˆ¶åˆè§„æ€§ (é™åˆ¶: {limit_mb}MB)")
        
        monitor = PerformanceMonitor()
        monitor.start_monitoring(0.5)
        
        try:
            # æ¨¡æ‹Ÿå¤§é‡æ•°æ®å¤„ç†
            self._simulate_heavy_processing()
            
            time.sleep(5)  # è®©ç›‘æ§æ”¶é›†è¶³å¤Ÿæ•°æ®
            
        finally:
            monitor.stop_monitoring()
        
        peak_memory = monitor.get_peak_memory()
        compliance = peak_memory <= limit_mb
        
        self.test_results['memory_limit_test'] = {
            'peak_memory_mb': peak_memory,
            'limit_mb': limit_mb,
            'compliant': compliance,
            'margin_mb': limit_mb - peak_memory
        }
        
        print(f"  å³°å€¼å†…å­˜: {peak_memory:.1f}MB")
        print(f"  åˆè§„çŠ¶æ€: {'âœ… é€šè¿‡' if compliance else 'âŒ è¶…é™'}")
        
        return compliance
    
    def _simulate_heavy_processing(self):
        """æ¨¡æ‹Ÿé‡åº¦å¤„ç†ä»»åŠ¡"""
        # æ¨¡æ‹Ÿå­—å¹•æ•°æ®å¤„ç†
        large_data = []
        
        for i in range(1000):
            # æ¨¡æ‹Ÿå­—å¹•æ®µè½
            segment = {
                'index': i,
                'start_time': f"00:{i//60:02d}:{i%60:02d},000",
                'end_time': f"00:{(i+3)//60:02d}:{(i+3)%60:02d},000",
                'text': f"è¿™æ˜¯ç¬¬{i}æ®µå­—å¹•å†…å®¹ï¼ŒåŒ…å«ä¸€äº›æµ‹è¯•æ–‡æœ¬" * 10,
                'metadata': {
                    'emotion': 'neutral',
                    'importance': 0.5,
                    'keywords': ['æµ‹è¯•', 'å­—å¹•', 'å†…å®¹'] * 5
                }
            }
            large_data.append(segment)
        
        # æ¨¡æ‹Ÿæ•°æ®å¤„ç†
        processed_data = []
        for segment in large_data:
            processed_segment = {
                **segment,
                'processed': True,
                'analysis_result': {
                    'sentiment_score': 0.5,
                    'key_phrases': segment['text'].split()[:10],
                    'processing_timestamp': time.time()
                }
            }
            processed_data.append(processed_segment)
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        del large_data
        del processed_data
        gc.collect()
    
    def test_memory_leak_detection(self, duration_seconds=30):
        """æµ‹è¯•å†…å­˜æ³„æ¼æ£€æµ‹"""
        print(f"ğŸ” å†…å­˜æ³„æ¼æ£€æµ‹æµ‹è¯• (æŒç»­{duration_seconds}ç§’)")
        
        monitor = PerformanceMonitor()
        monitor.start_monitoring(1.0)
        
        start_time = time.time()
        iteration = 0
        
        try:
            while time.time() - start_time < duration_seconds:
                # æ¨¡æ‹Ÿé‡å¤æ“ä½œ
                self._simulate_repeated_operations()
                iteration += 1
                
                if iteration % 10 == 0:
                    gc.collect()  # å®šæœŸåƒåœ¾å›æ”¶
                
                time.sleep(0.5)
        
        finally:
            monitor.stop_monitoring()
        
        # åˆ†æå†…å­˜ä½¿ç”¨è¶‹åŠ¿
        memory_usage = monitor.metrics['memory_usage']
        if len(memory_usage) > 10:
            initial_memory = sum(memory_usage[:5]) / 5
            final_memory = sum(memory_usage[-5:]) / 5
            memory_growth = final_memory - initial_memory
            
            # åˆ¤æ–­æ˜¯å¦å­˜åœ¨å†…å­˜æ³„æ¼ï¼ˆå¢é•¿è¶…è¿‡100MBè®¤ä¸ºå¯èƒ½æ³„æ¼ï¼‰
            has_leak = memory_growth > 100
            
            self.test_results['memory_leak_test'] = {
                'initial_memory_mb': initial_memory,
                'final_memory_mb': final_memory,
                'memory_growth_mb': memory_growth,
                'iterations': iteration,
                'has_potential_leak': has_leak
            }
            
            print(f"  åˆå§‹å†…å­˜: {initial_memory:.1f}MB")
            print(f"  æœ€ç»ˆå†…å­˜: {final_memory:.1f}MB")
            print(f"  å†…å­˜å¢é•¿: {memory_growth:.1f}MB")
            print(f"  æ³„æ¼æ£€æµ‹: {'âš ï¸ å¯èƒ½å­˜åœ¨æ³„æ¼' if has_leak else 'âœ… æ— æ˜æ˜¾æ³„æ¼'}")
            
            return not has_leak
        
        return True
    
    def _simulate_repeated_operations(self):
        """æ¨¡æ‹Ÿé‡å¤æ“ä½œ"""
        # æ¨¡æ‹Ÿå­—å¹•è§£æ
        srt_content = """1
00:00:01,000 --> 00:00:03,000
æµ‹è¯•å­—å¹•å†…å®¹

2
00:00:04,000 --> 00:00:06,000
å¦ä¸€æ®µæµ‹è¯•å†…å®¹
"""
        
        # æ¨¡æ‹Ÿè§£æè¿‡ç¨‹
        lines = srt_content.strip().split('\n')
        segments = []
        
        for i in range(0, len(lines), 4):
            if i + 2 < len(lines):
                segment = {
                    'index': lines[i],
                    'time': lines[i + 1] if i + 1 < len(lines) else '',
                    'text': lines[i + 2] if i + 2 < len(lines) else ''
                }
                segments.append(segment)
        
        # æ¨¡æ‹Ÿå¤„ç†
        for segment in segments:
            processed = segment['text'].upper().replace('æµ‹è¯•', 'TEST')
        
        # æ¸…ç†ä¸´æ—¶æ•°æ®
        del segments

class StabilityTest:
    """ç¨³å®šæ€§æµ‹è¯•"""
    
    def __init__(self):
        self.test_results = {}
    
    def test_long_running_stability(self, duration_minutes=5):
        """æµ‹è¯•é•¿æ—¶é—´è¿è¡Œç¨³å®šæ€§"""
        print(f"â±ï¸ é•¿æ—¶é—´è¿è¡Œç¨³å®šæ€§æµ‹è¯• (æŒç»­{duration_minutes}åˆ†é’Ÿ)")
        
        duration_seconds = duration_minutes * 60
        monitor = PerformanceMonitor()
        monitor.start_monitoring(2.0)
        
        start_time = time.time()
        operations_completed = 0
        errors_encountered = 0
        
        try:
            while time.time() - start_time < duration_seconds:
                try:
                    # æ¨¡æ‹Ÿå„ç§æ“ä½œ
                    self._simulate_mixed_operations()
                    operations_completed += 1
                    
                    # æ¯100æ¬¡æ“ä½œä¼‘æ¯ä¸€ä¸‹
                    if operations_completed % 100 == 0:
                        time.sleep(1)
                        print(f"  å·²å®Œæˆ {operations_completed} æ¬¡æ“ä½œ...")
                
                except Exception as e:
                    errors_encountered += 1
                    print(f"  æ“ä½œå¼‚å¸¸: {e}")
                
                time.sleep(0.1)
        
        finally:
            monitor.stop_monitoring()
        
        # è®¡ç®—ç¨³å®šæ€§æŒ‡æ ‡
        actual_duration = time.time() - start_time
        success_rate = (operations_completed - errors_encountered) / operations_completed if operations_completed > 0 else 0
        
        self.test_results['stability_test'] = {
            'planned_duration_seconds': duration_seconds,
            'actual_duration_seconds': actual_duration,
            'operations_completed': operations_completed,
            'errors_encountered': errors_encountered,
            'success_rate': success_rate,
            'operations_per_second': operations_completed / actual_duration,
            'peak_memory_mb': monitor.get_peak_memory(),
            'average_cpu_percent': monitor.get_average_cpu()
        }
        
        print(f"  å®é™…è¿è¡Œæ—¶é—´: {actual_duration:.1f}ç§’")
        print(f"  å®Œæˆæ“ä½œæ•°: {operations_completed}")
        print(f"  é”™è¯¯æ¬¡æ•°: {errors_encountered}")
        print(f"  æˆåŠŸç‡: {success_rate:.2%}")
        print(f"  æ“ä½œé€Ÿç‡: {operations_completed / actual_duration:.1f} ops/sec")
        
        return success_rate > 0.95  # 95%ä»¥ä¸ŠæˆåŠŸç‡è®¤ä¸ºç¨³å®š
    
    def _simulate_mixed_operations(self):
        """æ¨¡æ‹Ÿæ··åˆæ“ä½œ"""
        import random
        
        operation_type = random.choice(['parse', 'analyze', 'generate', 'export'])
        
        if operation_type == 'parse':
            self._simulate_srt_parsing()
        elif operation_type == 'analyze':
            self._simulate_narrative_analysis()
        elif operation_type == 'generate':
            self._simulate_subtitle_generation()
        elif operation_type == 'export':
            self._simulate_video_export()
    
    def _simulate_srt_parsing(self):
        """æ¨¡æ‹ŸSRTè§£æ"""
        content = "1\n00:00:01,000 --> 00:00:03,000\næµ‹è¯•å†…å®¹\n"
        lines = content.split('\n')
        result = {'parsed': True, 'segments': len(lines)}
    
    def _simulate_narrative_analysis(self):
        """æ¨¡æ‹Ÿå™äº‹åˆ†æ"""
        text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ•…äº‹ï¼ŒåŒ…å«æƒ…èŠ‚å‘å±•å’Œè§’è‰²äº’åŠ¨ã€‚"
        words = text.split()
        analysis = {'word_count': len(words), 'sentiment': 'positive'}
    
    def _simulate_subtitle_generation(self):
        """æ¨¡æ‹Ÿå­—å¹•ç”Ÿæˆ"""
        template = "ç”Ÿæˆçš„å­—å¹•å†…å®¹ {}"
        generated = [template.format(i) for i in range(10)]
    
    def _simulate_video_export(self):
        """æ¨¡æ‹Ÿè§†é¢‘å¯¼å‡º"""
        segments = [{'start': i, 'end': i+2} for i in range(0, 20, 2)]
        export_data = {'segments': segments, 'format': 'mp4'}

class ConcurrencyTest:
    """å¹¶å‘æµ‹è¯•"""
    
    def test_concurrent_processing(self, num_threads=4):
        """æµ‹è¯•å¹¶å‘å¤„ç†èƒ½åŠ›"""
        print(f"ğŸ”„ å¹¶å‘å¤„ç†æµ‹è¯• (çº¿ç¨‹æ•°: {num_threads})")
        
        monitor = PerformanceMonitor()
        monitor.start_monitoring(1.0)
        
        results = []
        threads = []
        
        def worker_task(worker_id):
            """å·¥ä½œçº¿ç¨‹ä»»åŠ¡"""
            try:
                start_time = time.time()
                
                # æ¨¡æ‹Ÿå¤„ç†ä»»åŠ¡
                for i in range(50):
                    self._simulate_processing_task(worker_id, i)
                    time.sleep(0.01)
                
                end_time = time.time()
                results.append({
                    'worker_id': worker_id,
                    'duration': end_time - start_time,
                    'success': True
                })
            except Exception as e:
                results.append({
                    'worker_id': worker_id,
                    'error': str(e),
                    'success': False
                })
        
        # å¯åŠ¨å·¥ä½œçº¿ç¨‹
        start_time = time.time()
        for i in range(num_threads):
            thread = threading.Thread(target=worker_task, args=(i,))
            threads.append(thread)
            thread.start()
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()
        
        total_time = time.time() - start_time
        monitor.stop_monitoring()
        
        # åˆ†æç»“æœ
        successful_workers = [r for r in results if r.get('success', False)]
        failed_workers = [r for r in results if not r.get('success', False)]
        
        print(f"  æ€»è€—æ—¶: {total_time:.2f}ç§’")
        print(f"  æˆåŠŸçº¿ç¨‹: {len(successful_workers)}/{num_threads}")
        print(f"  å¤±è´¥çº¿ç¨‹: {len(failed_workers)}")
        print(f"  å³°å€¼å†…å­˜: {monitor.get_peak_memory():.1f}MB")
        
        return len(failed_workers) == 0
    
    def _simulate_processing_task(self, worker_id, task_id):
        """æ¨¡æ‹Ÿå¤„ç†ä»»åŠ¡"""
        # æ¨¡æ‹Ÿä¸€äº›è®¡ç®—
        data = f"Worker {worker_id} processing task {task_id}"
        processed = data.upper().replace(' ', '_')
        result = {'worker': worker_id, 'task': task_id, 'result': processed}

def run_performance_tests():
    """è¿è¡Œæ‰€æœ‰æ€§èƒ½æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹æ€§èƒ½å’Œç¨³å®šæ€§æµ‹è¯•")
    print("=" * 60)
    
    all_results = {}
    
    # 1. å†…å­˜å‹åŠ›æµ‹è¯•
    print("\n1. å†…å­˜å‹åŠ›æµ‹è¯•")
    print("-" * 30)
    memory_test = MemoryStressTest()
    
    memory_limit_ok = memory_test.test_memory_limit_compliance()
    memory_leak_ok = memory_test.test_memory_leak_detection(30)
    
    all_results['memory_tests'] = memory_test.test_results
    
    # 2. ç¨³å®šæ€§æµ‹è¯•
    print("\n2. ç¨³å®šæ€§æµ‹è¯•")
    print("-" * 30)
    stability_test = StabilityTest()
    
    stability_ok = stability_test.test_long_running_stability(2)  # 2åˆ†é’Ÿæµ‹è¯•
    
    all_results['stability_tests'] = stability_test.test_results
    
    # 3. å¹¶å‘æµ‹è¯•
    print("\n3. å¹¶å‘æµ‹è¯•")
    print("-" * 30)
    concurrency_test = ConcurrencyTest()
    
    concurrency_ok = concurrency_test.test_concurrent_processing(4)
    
    # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
    print("\n" + "=" * 60)
    print("ğŸ“Š æ€§èƒ½æµ‹è¯•ç»“æœæ‘˜è¦")
    print("=" * 60)
    
    tests_passed = sum([memory_limit_ok, memory_leak_ok, stability_ok, concurrency_ok])
    total_tests = 4
    
    print(f"å†…å­˜é™åˆ¶åˆè§„: {'âœ…' if memory_limit_ok else 'âŒ'}")
    print(f"å†…å­˜æ³„æ¼æ£€æµ‹: {'âœ…' if memory_leak_ok else 'âŒ'}")
    print(f"é•¿æ—¶é—´ç¨³å®šæ€§: {'âœ…' if stability_ok else 'âŒ'}")
    print(f"å¹¶å‘å¤„ç†èƒ½åŠ›: {'âœ…' if concurrency_ok else 'âŒ'}")
    print(f"\næ€»ä½“é€šè¿‡ç‡: {tests_passed}/{total_tests} ({tests_passed/total_tests:.1%})")
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_file = f"performance_test_results_{timestamp}.json"
    
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    
    return tests_passed == total_tests

if __name__ == "__main__":
    success = run_performance_tests()
    sys.exit(0 if success else 1)
