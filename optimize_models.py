#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
VisionAI-ClipsMaster æ¨¡å‹ä¼˜åŒ–è„šæœ¬
ç§»é™¤å¤§æ¨¡å‹æ–‡ä»¶ï¼Œå®ç°æŒ‰éœ€ä¸‹è½½
"""

import os
import shutil
import json
from pathlib import Path
from typing import Dict, List
import yaml

class ModelOptimizer:
    """æ¨¡å‹ä¼˜åŒ–å™¨"""
    
    def __init__(self, project_root: Path = None):
        self.project_root = project_root or Path(".")
        self.models_dir = self.project_root / "models"
        self.backup_dir = self.project_root / "models_backup"
        
    def analyze_current_models(self) -> Dict:
        """åˆ†æå½“å‰æ¨¡å‹æ–‡ä»¶"""
        analysis = {
            "total_size": 0,
            "model_files": [],
            "directories": []
        }
        
        if not self.models_dir.exists():
            return analysis
        
        for item in self.models_dir.rglob("*"):
            if item.is_file():
                size = item.stat().st_size
                analysis["total_size"] += size
                
                if size > 100 * 1024 * 1024:  # >100MB
                    analysis["model_files"].append({
                        "path": str(item.relative_to(self.project_root)),
                        "size": size,
                        "size_formatted": self._format_size(size)
                    })
            elif item.is_dir():
                analysis["directories"].append(str(item.relative_to(self.project_root)))
        
        return analysis
    
    def _format_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size_bytes < 1024.0:
                return f"{size_bytes:.1f} {unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.1f} TB"
    
    def backup_models(self) -> bool:
        """å¤‡ä»½æ¨¡å‹æ–‡ä»¶"""
        try:
            if self.backup_dir.exists():
                shutil.rmtree(self.backup_dir)
            
            if self.models_dir.exists():
                shutil.copytree(self.models_dir, self.backup_dir)
                print(f"âœ… æ¨¡å‹æ–‡ä»¶å·²å¤‡ä»½åˆ°: {self.backup_dir}")
                return True
        except Exception as e:
            print(f"âŒ å¤‡ä»½å¤±è´¥: {e}")
            return False
    
    def remove_large_models(self, size_threshold: int = 100 * 1024 * 1024) -> List[str]:
        """ç§»é™¤å¤§æ¨¡å‹æ–‡ä»¶"""
        removed_files = []
        
        if not self.models_dir.exists():
            return removed_files
        
        for item in self.models_dir.rglob("*"):
            if item.is_file() and item.stat().st_size > size_threshold:
                try:
                    # ä¿ç•™æ–‡ä»¶ä¿¡æ¯
                    file_info = {
                        "original_path": str(item.relative_to(self.project_root)),
                        "size": item.stat().st_size,
                        "removed_at": str(item.stat().st_mtime)
                    }
                    
                    # åˆ é™¤æ–‡ä»¶
                    item.unlink()
                    removed_files.append(file_info)
                    print(f"ğŸ—‘ï¸ å·²ç§»é™¤: {item.relative_to(self.project_root)} "
                          f"({self._format_size(file_info['size'])})")
                    
                except Exception as e:
                    print(f"âŒ ç§»é™¤å¤±è´¥ {item}: {e}")
        
        return removed_files
    
    def create_download_configs(self, removed_files: List[Dict]) -> bool:
        """åˆ›å»ºä¸‹è½½é…ç½®æ–‡ä»¶"""
        try:
            config_dir = self.project_root / "configs" / "downloads"
            config_dir.mkdir(parents=True, exist_ok=True)
            
            # åˆ›å»ºæ¨¡å‹ä¸‹è½½é…ç½®
            download_config = {
                "version": "1.0",
                "removed_models": removed_files,
                "download_sources": {
                    "qwen": {
                        "modelscope": "https://modelscope.cn/models/qwen/Qwen2.5-7B-Instruct-GGUF",
                        "huggingface": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct-GGUF"
                    },
                    "mistral": {
                        "modelscope": "https://modelscope.cn/models/mistralai/Mistral-7B-Instruct-v0.3-GGUF", 
                        "huggingface": "https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3-GGUF"
                    }
                },
                "quantization_options": {
                    "Q2_K": {"size_mb": 1800, "quality": 0.75},
                    "Q4_K_M": {"size_mb": 2600, "quality": 0.88},
                    "Q5_K": {"size_mb": 3800, "quality": 0.94}
                }
            }
            
            config_file = config_dir / "model_downloads.json"
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(download_config, f, indent=2, ensure_ascii=False)
            
            print(f"âœ… ä¸‹è½½é…ç½®å·²åˆ›å»º: {config_file}")
            return True
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºé…ç½®å¤±è´¥: {e}")
            return False
    
    def update_model_config(self) -> bool:
        """æ›´æ–°æ¨¡å‹é…ç½®æ–‡ä»¶"""
        try:
            config_file = self.project_root / "configs" / "model_config.yaml"
            
            if not config_file.exists():
                print(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
                return False
            
            # è¯»å–ç°æœ‰é…ç½®
            with open(config_file, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            # æ›´æ–°é…ç½®
            if 'models' in config:
                for model_name, model_config in config['models'].items():
                    # è®¾ç½®ä¸ºæŒ‰éœ€ä¸‹è½½
                    model_config['auto_download'] = True
                    model_config['preload'] = False
                    
                    # æ›´æ–°è·¯å¾„ä¸ºç›¸å¯¹è·¯å¾„
                    if 'path' in model_config:
                        path = model_config['path']
                        if not path.startswith('models/'):
                            model_config['path'] = f"models/{path}"
            
            # æ·»åŠ ä¼˜åŒ–é…ç½®
            if 'optimization' not in config:
                config['optimization'] = {
                    "deployment_mode": "lightweight",
                    "auto_download": True,
                    "cache_management": True,
                    "max_cache_size": "8GB",
                    "cleanup_policy": "lru"
                }
            
            # å†™å›é…ç½®
            with open(config_file, 'w', encoding='utf-8') as f:
                yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
            
            print(f"âœ… æ¨¡å‹é…ç½®å·²æ›´æ–°: {config_file}")
            return True
            
        except Exception as e:
            print(f"âŒ æ›´æ–°é…ç½®å¤±è´¥: {e}")
            return False
    
    def create_placeholder_files(self) -> bool:
        """åˆ›å»ºå ä½ç¬¦æ–‡ä»¶"""
        try:
            placeholder_dirs = [
                "models/qwen/base",
                "models/qwen/quantized", 
                "models/mistral/base",
                "models/mistral/quantized"
            ]
            
            for dir_path in placeholder_dirs:
                full_path = self.project_root / dir_path
                full_path.mkdir(parents=True, exist_ok=True)
                
                # åˆ›å»ºREADMEæ–‡ä»¶
                readme_file = full_path / "README.md"
                readme_content = f"""# {dir_path.split('/')[-2].title()} æ¨¡å‹ç›®å½•

æ­¤ç›®å½•ç”¨äºå­˜æ”¾ {dir_path.split('/')[-2]} æ¨¡å‹æ–‡ä»¶ã€‚

## è‡ªåŠ¨ä¸‹è½½

æ¨¡å‹æ–‡ä»¶å°†åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶è‡ªåŠ¨ä¸‹è½½ã€‚æ‚¨ä¹Ÿå¯ä»¥æ‰‹åŠ¨è§¦å‘ä¸‹è½½ï¼š

```bash
python scripts/download_models.py --model {dir_path.split('/')[-2]}
```

## é‡åŒ–é€‰é¡¹

- Q2_K: 1.8GB (æè‡´å‹ç¼©)
- Q4_K_M: 2.6GB (æ¨è)  
- Q5_K: 3.8GB (é«˜è´¨é‡)

## ä¸‹è½½æº

- å›½å†…ç”¨æˆ·æ¨èï¼šModelScope
- å›½å¤–ç”¨æˆ·æ¨èï¼šHuggingFace
"""
                
                with open(readme_file, 'w', encoding='utf-8') as f:
                    f.write(readme_content)
            
            print("âœ… å ä½ç¬¦æ–‡ä»¶å·²åˆ›å»º")
            return True
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºå ä½ç¬¦å¤±è´¥: {e}")
            return False
    
    def optimize(self, backup: bool = True) -> Dict:
        """æ‰§è¡Œå®Œæ•´ä¼˜åŒ–"""
        print("ğŸš€ å¼€å§‹æ¨¡å‹ä¼˜åŒ–...")
        
        # åˆ†æå½“å‰çŠ¶æ€
        analysis = self.analyze_current_models()
        print(f"ğŸ“Š å½“å‰æ¨¡å‹æ€»å¤§å°: {self._format_size(analysis['total_size'])}")
        print(f"ğŸ“„ å¤§æ–‡ä»¶æ•°é‡: {len(analysis['model_files'])}")
        
        results = {
            "success": False,
            "original_size": analysis['total_size'],
            "removed_files": [],
            "space_saved": 0
        }
        
        # å¤‡ä»½
        if backup and not self.backup_models():
            return results
        
        # ç§»é™¤å¤§æ–‡ä»¶
        removed_files = self.remove_large_models()
        results["removed_files"] = removed_files
        results["space_saved"] = sum(f["size"] for f in removed_files)
        
        # åˆ›å»ºé…ç½®
        if not self.create_download_configs(removed_files):
            return results
        
        # æ›´æ–°é…ç½®
        if not self.update_model_config():
            return results
        
        # åˆ›å»ºå ä½ç¬¦
        if not self.create_placeholder_files():
            return results
        
        results["success"] = True
        print(f"âœ… ä¼˜åŒ–å®Œæˆï¼ŒèŠ‚çœç©ºé—´: {self._format_size(results['space_saved'])}")
        
        return results

def main():
    """ä¸»å‡½æ•°"""
    optimizer = ModelOptimizer()
    
    print("ğŸ” VisionAI-ClipsMaster æ¨¡å‹ä¼˜åŒ–å·¥å…·")
    print("=" * 60)
    
    # æ‰§è¡Œä¼˜åŒ–
    results = optimizer.optimize()
    
    if results["success"]:
        print("\nğŸ“Š ä¼˜åŒ–ç»“æœ:")
        print(f"  åŸå§‹å¤§å°: {optimizer._format_size(results['original_size'])}")
        print(f"  èŠ‚çœç©ºé—´: {optimizer._format_size(results['space_saved'])}")
        print(f"  ç§»é™¤æ–‡ä»¶: {len(results['removed_files'])} ä¸ª")
        
        print("\nğŸ¯ ä¸‹ä¸€æ­¥:")
        print("  1. æµ‹è¯•æ ¸å¿ƒåŠŸèƒ½æ˜¯å¦æ­£å¸¸")
        print("  2. è¿è¡Œæ™ºèƒ½ä¸‹è½½å™¨æµ‹è¯•")
        print("  3. éªŒè¯UIå¯åŠ¨å’Œæ¨¡å‹åŠ è½½")
    else:
        print("âŒ ä¼˜åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

if __name__ == "__main__":
    main()
