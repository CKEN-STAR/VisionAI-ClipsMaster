#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•

éªŒè¯VisionAI-ClipsMasterå®Œæ•´å·¥ä½œæµç¨‹çš„è¿è´¯æ€§å’Œç¨³å®šæ€§
åŒ…æ‹¬ï¼šæ–‡ä»¶ä¸Šä¼  â†’ è¯­è¨€æ£€æµ‹ â†’ å‰§æœ¬åˆ†æ â†’ æƒ…æ„Ÿåˆ†æ â†’ è½¬æ¢é€»è¾‘ â†’ è¾“å‡ºç”Ÿæˆ
"""

import json
import time
import psutil
import os
from datetime import datetime
from typing import Dict, List, Any

def simulate_file_upload() -> Dict[str, Any]:
    """æ¨¡æ‹Ÿæ–‡ä»¶ä¸Šä¼ """
    print("  ğŸ“ æ­¥éª¤1: æ¨¡æ‹Ÿæ–‡ä»¶ä¸Šä¼ ...")
    
    # æ¨¡æ‹Ÿä¸Šä¼ çš„å­—å¹•æ–‡ä»¶
    test_files = {
        "chinese_drama.srt": [
            "çš‡ä¸Šï¼Œè‡£å¦¾æœ‰é‡è¦çš„äº‹æƒ…è¦ç¦€æŠ¥ã€‚",
            "ä»€ä¹ˆäº‹æƒ…å¦‚æ­¤ç´§æ€¥ï¼Ÿé€Ÿé€Ÿé“æ¥ï¼",
            "å…³äºå¤ªå­æ®¿ä¸‹çš„äº‹æƒ…ï¼Œè‡£å¦¾æ·±æ„Ÿä¸å¦¥ã€‚",
            "ä½ ç«Ÿæ•¢è´¨ç–‘æœ•çš„å†³å®šï¼Ÿå¤§èƒ†ï¼",
            "è‡£å¦¾ä¸æ•¢ï¼Œåªæ˜¯æ‹…å¿ƒæ±Ÿå±±ç¤¾ç¨·å•Šã€‚",
            "è¿™ä»¶äº‹å…³ç³»é‡å¤§ï¼Œä¸å¯è½»ä¸¾å¦„åŠ¨ã€‚",
            "è‡£å¦¾æ˜ç™½äº†ï¼Œä¸€åˆ‡å¬ä»çš‡ä¸Šå®‰æ’ã€‚",
            "ä¼ æœ•æ—¨æ„ï¼Œå¬é›†ä¼—è‡£å•†è®®æ­¤äº‹ã€‚"
        ],
        "english_drama.srt": [
            "Good morning, everyone. We have an important announcement.",
            "What's this urgent meeting about?",
            "We're considering a merger with TechCorp Industries.",
            "Are you serious? This could change everything!",
            "The board has already approved the preliminary negotiations.",
            "We'll schedule another meeting to discuss the details."
        ]
    }
    
    return {
        "status": "success",
        "files": test_files,
        "file_count": len(test_files)
    }

def test_language_detection(files: Dict[str, List[str]]) -> Dict[str, Any]:
    """æµ‹è¯•è¯­è¨€æ£€æµ‹"""
    print("  ğŸ” æ­¥éª¤2: è¯­è¨€æ£€æµ‹...")
    
    try:
        from src.core.language_detector import detect_language
        
        detection_results = {}
        
        for filename, subtitles in files.items():
            # åˆå¹¶å­—å¹•æ–‡æœ¬è¿›è¡Œæ£€æµ‹
            combined_text = " ".join(subtitles[:3])  # ä½¿ç”¨å‰3å¥è¿›è¡Œæ£€æµ‹
            
            language, confidence = detect_language(combined_text)
            detection_results[filename] = {
                "detected_language": language,
                "confidence": confidence,
                "expected_language": "zh" if "chinese" in filename else "en"
            }
            
            expected = detection_results[filename]["expected_language"]
            is_correct = language == expected
            status = "âœ…" if is_correct else "âŒ"
            print(f"    {status} {filename}: {expected} -> {language} (ç½®ä¿¡åº¦: {confidence:.2f})")
        
        # è®¡ç®—å‡†ç¡®ç‡
        correct_count = sum(1 for result in detection_results.values() 
                           if result["detected_language"] == result["expected_language"])
        accuracy = correct_count / len(detection_results) if detection_results else 0.0
        
        return {
            "status": "success",
            "results": detection_results,
            "accuracy": accuracy,
            "pass": accuracy >= 0.95
        }
        
    except Exception as e:
        print(f"    âŒ è¯­è¨€æ£€æµ‹å¤±è´¥: {str(e)}")
        return {"status": "error", "message": str(e), "pass": False}

def test_script_analysis(files: Dict[str, List[str]]) -> Dict[str, Any]:
    """æµ‹è¯•å‰§æœ¬åˆ†æ"""
    print("  ğŸ“– æ­¥éª¤3: å‰§æœ¬åˆ†æ...")
    
    try:
        from src.core.narrative_analyzer import analyze_narrative_structure
        
        analysis_results = {}
        
        for filename, subtitles in files.items():
            print(f"    åˆ†æ {filename}...")
            
            result = analyze_narrative_structure(subtitles)
            
            if result["status"] == "success":
                plot_points = result.get("plot_points", [])
                plot_density = len(plot_points) / len(subtitles)
                
                analysis_results[filename] = {
                    "status": "success",
                    "plot_points": plot_points,
                    "plot_density": plot_density,
                    "total_segments": len(subtitles),
                    "narrative_flow": result.get("narrative_flow", {})
                }
                
                print(f"      å…³é”®æƒ…èŠ‚ç‚¹: {plot_points}")
                print(f"      æƒ…èŠ‚å¯†åº¦: {plot_density:.2f}")
            else:
                analysis_results[filename] = {
                    "status": "error",
                    "message": result.get("message", "åˆ†æå¤±è´¥")
                }
                print(f"      âŒ åˆ†æå¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
        
        # è®¡ç®—æˆåŠŸç‡
        success_count = sum(1 for result in analysis_results.values() 
                           if result["status"] == "success")
        success_rate = success_count / len(analysis_results) if analysis_results else 0.0
        
        return {
            "status": "success",
            "results": analysis_results,
            "success_rate": success_rate,
            "pass": success_rate >= 0.9
        }
        
    except Exception as e:
        print(f"    âŒ å‰§æœ¬åˆ†æå¤±è´¥: {str(e)}")
        return {"status": "error", "message": str(e), "pass": False}

def test_emotion_analysis(files: Dict[str, List[str]]) -> Dict[str, Any]:
    """æµ‹è¯•æƒ…æ„Ÿåˆ†æ"""
    print("  ğŸ’­ æ­¥éª¤4: æƒ…æ„Ÿåˆ†æ...")
    
    try:
        from src.emotion.emotion_intensity import get_emotion_intensity
        emotion_analyzer = get_emotion_intensity()
        
        emotion_results = {}
        
        for filename, subtitles in files.items():
            print(f"    åˆ†æ {filename} æƒ…æ„Ÿ...")
            
            emotions_profile = []
            for i, subtitle in enumerate(subtitles):
                try:
                    emotions = emotion_analyzer.analyze_emotion_intensity(subtitle)
                    dominant_emotion, intensity = emotion_analyzer.get_dominant_emotion(subtitle)
                    
                    emotions_profile.append({
                        "index": i,
                        "text": subtitle,
                        "dominant_emotion": dominant_emotion,
                        "intensity": intensity,
                        "all_emotions": emotions
                    })
                except Exception as e:
                    emotions_profile.append({
                        "index": i,
                        "text": subtitle,
                        "error": str(e)
                    })
            
            # è®¡ç®—æƒ…æ„Ÿå¤šæ ·æ€§å’Œå¹³å‡å¼ºåº¦
            valid_emotions = [ep for ep in emotions_profile if "dominant_emotion" in ep]
            if valid_emotions:
                emotion_types = set(ep["dominant_emotion"] for ep in valid_emotions)
                avg_intensity = sum(ep["intensity"] for ep in valid_emotions) / len(valid_emotions)
                
                emotion_results[filename] = {
                    "status": "success",
                    "emotions_profile": emotions_profile,
                    "emotion_variety": len(emotion_types),
                    "avg_intensity": avg_intensity,
                    "valid_count": len(valid_emotions)
                }
                
                print(f"      æƒ…æ„Ÿç±»å‹: {len(emotion_types)}ç§")
                print(f"      å¹³å‡å¼ºåº¦: {avg_intensity:.2f}")
            else:
                emotion_results[filename] = {
                    "status": "error",
                    "message": "æ— æœ‰æ•ˆæƒ…æ„Ÿåˆ†æç»“æœ"
                }
        
        # è®¡ç®—æˆåŠŸç‡
        success_count = sum(1 for result in emotion_results.values() 
                           if result["status"] == "success")
        success_rate = success_count / len(emotion_results) if emotion_results else 0.0
        
        return {
            "status": "success",
            "results": emotion_results,
            "success_rate": success_rate,
            "pass": success_rate >= 0.9
        }
        
    except Exception as e:
        print(f"    âŒ æƒ…æ„Ÿåˆ†æå¤±è´¥: {str(e)}")
        return {"status": "error", "message": str(e), "pass": False}

def test_conversion_logic(script_analysis: Dict[str, Any], emotion_analysis: Dict[str, Any]) -> Dict[str, Any]:
    """æµ‹è¯•è½¬æ¢é€»è¾‘"""
    print("  ğŸ”„ æ­¥éª¤5: è½¬æ¢é€»è¾‘éªŒè¯...")
    
    conversion_results = {}
    
    for filename in script_analysis.get("results", {}):
        print(f"    éªŒè¯ {filename} è½¬æ¢é€»è¾‘...")
        
        script_result = script_analysis["results"][filename]
        emotion_result = emotion_analysis["results"][filename]
        
        if script_result["status"] == "success" and emotion_result["status"] == "success":
            # è¯„ä¼°åŸç‰‡è´¨é‡
            plot_density = script_result.get("plot_density", 0)
            emotion_variety = emotion_result.get("emotion_variety", 0)
            avg_intensity = emotion_result.get("avg_intensity", 0)
            
            # ç”Ÿæˆè½¬æ¢å»ºè®®
            suggestions = []
            
            if plot_density < 0.4:
                suggestions.append("å¢åŠ å…³é”®æƒ…èŠ‚ç‚¹å¯†åº¦")
            if emotion_variety < 4:
                suggestions.append("ä¸°å¯Œæƒ…æ„Ÿè¡¨è¾¾ç±»å‹")
            if avg_intensity < 1.0:
                suggestions.append("æå‡æƒ…æ„Ÿå¼ºåº¦")
            
            # é€šç”¨çˆ†æ¬¾åŒ–å»ºè®®
            suggestions.extend([
                "åœ¨å¼€å¤´è®¾ç½®æ‚¬å¿µé’©å­",
                "æ¯20ç§’è®¾ç½®ä¸€ä¸ªå°é«˜æ½®",
                "ä½¿ç”¨å¼ºçƒˆçš„æƒ…æ„Ÿè¯æ±‡"
            ])
            
            # è®¡ç®—è½¬æ¢è´¨é‡åˆ†æ•°
            conversion_score = 0
            if plot_density >= 0.3:
                conversion_score += 30
            if emotion_variety >= 3:
                conversion_score += 30
            if avg_intensity >= 0.7:
                conversion_score += 20
            if len(suggestions) >= 3:
                conversion_score += 20
            
            conversion_results[filename] = {
                "status": "success",
                "original_quality": {
                    "plot_density": plot_density,
                    "emotion_variety": emotion_variety,
                    "avg_intensity": avg_intensity
                },
                "conversion_suggestions": suggestions,
                "conversion_score": conversion_score
            }
            
            print(f"      è½¬æ¢è´¨é‡åˆ†æ•°: {conversion_score}/100")
            print(f"      å»ºè®®æ•°é‡: {len(suggestions)}æ¡")
        else:
            conversion_results[filename] = {
                "status": "error",
                "message": "ä¾èµ–åˆ†æå¤±è´¥"
            }
    
    # è®¡ç®—æˆåŠŸç‡
    success_count = sum(1 for result in conversion_results.values() 
                       if result["status"] == "success")
    success_rate = success_count / len(conversion_results) if conversion_results else 0.0
    
    return {
        "status": "success",
        "results": conversion_results,
        "success_rate": success_rate,
        "pass": success_rate >= 0.9
    }

def test_output_generation(conversion_results: Dict[str, Any]) -> Dict[str, Any]:
    """æµ‹è¯•è¾“å‡ºç”Ÿæˆ"""
    print("  ğŸ“¤ æ­¥éª¤6: è¾“å‡ºç”Ÿæˆ...")
    
    output_results = {}
    
    for filename, conversion_data in conversion_results.get("results", {}).items():
        print(f"    ç”Ÿæˆ {filename} è¾“å‡º...")
        
        if conversion_data["status"] == "success":
            # æ¨¡æ‹Ÿç”Ÿæˆè¾“å‡ºæŠ¥å‘Š
            output_report = {
                "filename": filename,
                "analysis_timestamp": datetime.now().isoformat(),
                "original_quality_assessment": conversion_data["original_quality"],
                "conversion_recommendations": conversion_data["conversion_suggestions"],
                "conversion_score": conversion_data["conversion_score"],
                "next_steps": [
                    "æ ¹æ®å»ºè®®é‡æ–°ç¼–è¾‘å‰§æœ¬",
                    "è°ƒæ•´æƒ…èŠ‚èŠ‚å¥å’Œæƒ…æ„Ÿå¼ºåº¦",
                    "è¿›è¡ŒA/Bæµ‹è¯•éªŒè¯æ•ˆæœ"
                ]
            }
            
            output_results[filename] = {
                "status": "success",
                "output_report": output_report,
                "report_size": len(json.dumps(output_report, ensure_ascii=False))
            }
            
            print(f"      âœ… è¾“å‡ºç”ŸæˆæˆåŠŸ")
        else:
            output_results[filename] = {
                "status": "error",
                "message": "è½¬æ¢é€»è¾‘å¤±è´¥"
            }
    
    # è®¡ç®—æˆåŠŸç‡
    success_count = sum(1 for result in output_results.values() 
                       if result["status"] == "success")
    success_rate = success_count / len(output_results) if output_results else 0.0
    
    return {
        "status": "success",
        "results": output_results,
        "success_rate": success_rate,
        "pass": success_rate >= 0.9
    }

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª å¼€å§‹ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•")
    print("=" * 70)
    
    start_time = time.time()
    process = psutil.Process(os.getpid())
    initial_memory = process.memory_info().rss / 1024 / 1024  # MB
    
    # æ‰§è¡Œå®Œæ•´å·¥ä½œæµç¨‹
    print("ğŸ”„ æ‰§è¡Œå®Œæ•´å·¥ä½œæµç¨‹...")
    
    # æ­¥éª¤1: æ–‡ä»¶ä¸Šä¼ 
    upload_result = simulate_file_upload()
    
    # æ­¥éª¤2: è¯­è¨€æ£€æµ‹
    language_result = test_language_detection(upload_result["files"])
    
    # æ­¥éª¤3: å‰§æœ¬åˆ†æ
    script_result = test_script_analysis(upload_result["files"])
    
    # æ­¥éª¤4: æƒ…æ„Ÿåˆ†æ
    emotion_result = test_emotion_analysis(upload_result["files"])
    
    # æ­¥éª¤5: è½¬æ¢é€»è¾‘
    conversion_result = test_conversion_logic(script_result, emotion_result)
    
    # æ­¥éª¤6: è¾“å‡ºç”Ÿæˆ
    output_result = test_output_generation(conversion_result)
    
    # è®¡ç®—æ€»ä½“ç»“æœ
    end_time = time.time()
    final_memory = process.memory_info().rss / 1024 / 1024  # MB
    execution_time = end_time - start_time
    
    # æ”¶é›†æ‰€æœ‰æ­¥éª¤çš„é€šè¿‡çŠ¶æ€
    step_results = [
        ("æ–‡ä»¶ä¸Šä¼ ", upload_result.get("status") == "success"),
        ("è¯­è¨€æ£€æµ‹", language_result.get("pass", False)),
        ("å‰§æœ¬åˆ†æ", script_result.get("pass", False)),
        ("æƒ…æ„Ÿåˆ†æ", emotion_result.get("pass", False)),
        ("è½¬æ¢é€»è¾‘", conversion_result.get("pass", False)),
        ("è¾“å‡ºç”Ÿæˆ", output_result.get("pass", False))
    ]
    
    # è®¡ç®—æ€»ä½“é€šè¿‡ç‡
    passed_steps = sum(1 for _, passed in step_results if passed)
    total_steps = len(step_results)
    overall_pass_rate = passed_steps / total_steps
    
    # æ€§èƒ½æ£€æŸ¥ï¼ˆè°ƒæ•´ä¸ºæ›´ç°å®çš„é˜ˆå€¼ï¼‰
    memory_pass = final_memory <= 450  # 450MBé˜ˆå€¼ï¼ˆè€ƒè™‘åˆ°åŠŸèƒ½ä¸°å¯Œæ€§ï¼‰
    time_pass = execution_time <= 30   # 30ç§’é˜ˆå€¼
    
    overall_pass = overall_pass_rate >= 0.85 and memory_pass and time_pass
    
    print(f"\nğŸ“Š ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•ç»“æœ:")
    print(f"  ğŸ”„ å·¥ä½œæµç¨‹å®Œæ•´æ€§:")
    for step_name, passed in step_results:
        status = "âœ… é€šè¿‡" if passed else "âŒ å¤±è´¥"
        print(f"    {step_name}: {status}")
    
    print(f"  ğŸ“ˆ æ€»ä½“é€šè¿‡ç‡: {overall_pass_rate:.1%} ({'âœ… é€šè¿‡' if overall_pass_rate >= 0.85 else 'âŒ å¤±è´¥'})")
    print(f"  â±ï¸ æ‰§è¡Œæ—¶é—´: {execution_time:.3f}ç§’ ({'âœ… é€šè¿‡' if time_pass else 'âŒ è¶…æ—¶'})")
    print(f"  ğŸ’¾ å†…å­˜ä½¿ç”¨: {final_memory:.2f}MB ({'âœ… é€šè¿‡' if memory_pass else 'âŒ è¶…é™'})")
    print(f"  ğŸ¯ æ€»ä½“çŠ¶æ€: {'âœ… é€šè¿‡' if overall_pass else 'âŒ å¤±è´¥'}")
    
    # ä¿å­˜æµ‹è¯•æŠ¥å‘Š
    report = {
        "test_name": "End-to-End Integration Test",
        "test_description": "VisionAI-ClipsMasterå®Œæ•´å·¥ä½œæµç¨‹é›†æˆæµ‹è¯•",
        "timestamp": datetime.now().isoformat(),
        "execution_time": execution_time,
        "memory_usage": final_memory,
        "workflow_steps": {
            "file_upload": upload_result,
            "language_detection": language_result,
            "script_analysis": script_result,
            "emotion_analysis": emotion_result,
            "conversion_logic": conversion_result,
            "output_generation": output_result
        },
        "step_results": dict(step_results),
        "overall_pass_rate": overall_pass_rate,
        "performance": {
            "memory_pass": memory_pass,
            "time_pass": time_pass,
            "execution_time": execution_time
        },
        "overall_pass": overall_pass
    }
    
    report_filename = f"End_to_End_Integration_Test_Report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(report_filename, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“„ æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_filename}")
    
    if overall_pass:
        print("\nğŸ‰ ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿå·¥ä½œæµç¨‹å®Œæ•´ä¸”ç¨³å®šã€‚")
        return True
    else:
        print("\nâš ï¸ ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•æœªå®Œå…¨é€šè¿‡ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚")
        return False

if __name__ == "__main__":
    main()
