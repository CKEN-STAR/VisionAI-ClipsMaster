#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
VisionAI-ClipsMaster æ‰‹åŠ¨æ¨¡å‹ä¸‹è½½æŒ‡å—
æä¾›å®Œæ•´çš„æ¨¡å‹ä¸‹è½½ã€å®‰è£…å’ŒéªŒè¯æ–¹æ¡ˆ
"""

import os
import sys
import json
import hashlib
import requests
from pathlib import Path
from typing import Dict, List
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ModelDownloadGuide:
    """æ¨¡å‹ä¸‹è½½æŒ‡å—"""
    
    def __init__(self):
        self.models_config = {
            "qwen2.5-7b": {
                "name": "Qwen2.5-7B-Instruct",
                "description": "é€šä¹‰åƒé—®2.5-7BæŒ‡ä»¤æ¨¡å‹ï¼ˆä¸­æ–‡ä¼˜åŒ–ï¼‰",
                "size": "14.4GB",
                "files": [
                    "model-00001-of-00008.safetensors",
                    "model-00002-of-00008.safetensors", 
                    "model-00003-of-00008.safetensors",
                    "model-00004-of-00008.safetensors",
                    "model-00005-of-00008.safetensors",
                    "model-00006-of-00008.safetensors",
                    "model-00007-of-00008.safetensors",
                    "model-00008-of-00008.safetensors",
                    "config.json",
                    "generation_config.json",
                    "tokenizer.json",
                    "tokenizer_config.json"
                ],
                "target_dir": "models/models/qwen/base",
                "download_sources": {
                    "modelscope": "https://modelscope.cn/models/qwen/Qwen2.5-7B-Instruct",
                    "huggingface": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
                    "hf_mirror": "https://hf-mirror.com/Qwen/Qwen2.5-7B-Instruct"
                }
            },
            "mistral-7b": {
                "name": "Mistral-7B-Instruct-v0.1",
                "description": "Mistral-7BæŒ‡ä»¤æ¨¡å‹ï¼ˆè‹±æ–‡ä¼˜åŒ–ï¼‰",
                "size": "13.5GB",
                "files": [
                    "pytorch_model-00001-of-00002.bin",
                    "pytorch_model-00002-of-00002.bin",
                    "config.json",
                    "generation_config.json",
                    "tokenizer.json",
                    "tokenizer_config.json"
                ],
                "target_dir": "models/mistral/base",
                "download_sources": {
                    "huggingface": "https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1",
                    "hf_mirror": "https://hf-mirror.com/mistralai/Mistral-7B-Instruct-v0.1",
                    "modelscope": "https://modelscope.cn/models/AI-ModelScope/Mistral-7B-Instruct-v0.1"
                }
            },
            "qwen2.5-7b-gguf": {
                "name": "Qwen2.5-7B-Instruct-GGUF (é‡åŒ–ç‰ˆ)",
                "description": "Qwen2.5-7B GGUFé‡åŒ–æ¨¡å‹ï¼ˆæ¨èï¼‰",
                "size": "4.1GB",
                "files": [
                    "qwen2.5-7b-instruct-q4_k_m.gguf"
                ],
                "target_dir": "models/models/qwen/quantized",
                "target_filename": "Q4_K_M.gguf",
                "download_sources": {
                    "modelscope": "https://modelscope.cn/models/qwen/Qwen2.5-7B-Instruct-GGUF",
                    "huggingface": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct-GGUF"
                }
            },
            "mistral-7b-gguf": {
                "name": "Mistral-7B-Instruct-GGUF (é‡åŒ–ç‰ˆ)",
                "description": "Mistral-7B GGUFé‡åŒ–æ¨¡å‹ï¼ˆæ¨èï¼‰",
                "size": "4.1GB", 
                "files": [
                    "mistral-7b-instruct-v0.1.q4_k_m.gguf"
                ],
                "target_dir": "models/mistral/quantized",
                "target_filename": "Q4_K_M.gguf",
                "download_sources": {
                    "huggingface": "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF",
                    "hf_mirror": "https://hf-mirror.com/TheBloke/Mistral-7B-Instruct-v0.1-GGUF"
                }
            }
        }
    
    def show_download_options(self):
        """æ˜¾ç¤ºä¸‹è½½é€‰é¡¹"""
        print("ğŸ¤– VisionAI-ClipsMaster æ¨¡å‹ä¸‹è½½æŒ‡å—")
        print("=" * 60)
        print()
        
        print("ğŸ“‹ å¯ç”¨æ¨¡å‹é€‰é¡¹:")
        for i, (key, config) in enumerate(self.models_config.items(), 1):
            print(f"  {i}. {config['name']}")
            print(f"     ğŸ“ {config['description']}")
            print(f"     ğŸ“Š å¤§å°: {config['size']}")
            print(f"     ğŸ“ ç›®æ ‡ç›®å½•: {config['target_dir']}")
            print()
        
        print("ğŸ’¡ æ¨èä¸‹è½½ç­–ç•¥:")
        print("  ğŸ¥‡ é¦–é€‰: GGUFé‡åŒ–ç‰ˆæœ¬ (é€‰é¡¹3å’Œ4) - ä½“ç§¯å°ï¼Œæ€§èƒ½å¥½")
        print("  ğŸ¥ˆ å¤‡é€‰: å®Œæ•´ç‰ˆæœ¬ (é€‰é¡¹1å’Œ2) - æœ€ä½³è´¨é‡ï¼Œä½“ç§¯å¤§")
        print()
        
        print("ğŸŒ ä¸‹è½½æºä¼˜å…ˆçº§:")
        print("  1. ModelScope (å›½å†…) - é€Ÿåº¦å¿«ï¼Œç¨³å®š")
        print("  2. HF-Mirror (å›½å†…é•œåƒ) - å¤‡ç”¨é€‰æ‹©")
        print("  3. HuggingFace (å›½å¤–) - å®˜æ–¹æº")
    
    def generate_download_commands(self, model_key: str):
        """ç”Ÿæˆä¸‹è½½å‘½ä»¤"""
        if model_key not in self.models_config:
            print(f"âŒ æœªçŸ¥æ¨¡å‹: {model_key}")
            return
        
        config = self.models_config[model_key]
        print(f"ğŸ“¥ {config['name']} ä¸‹è½½æ–¹æ¡ˆ")
        print("=" * 50)
        
        # åˆ›å»ºç›®æ ‡ç›®å½•
        target_dir = Path(config['target_dir'])
        target_dir.mkdir(parents=True, exist_ok=True)
        print(f"âœ… ç›®æ ‡ç›®å½•å·²åˆ›å»º: {target_dir}")
        
        print("\nğŸ”§ ä¸‹è½½æ–¹æ³•:")
        
        # æ–¹æ³•1: Git LFS (æ¨è)
        print("\n1ï¸âƒ£ ä½¿ç”¨Git LFSä¸‹è½½ (æ¨è):")
        for source_name, url in config['download_sources'].items():
            print(f"\n   ğŸ“ {source_name.upper()}:")
            print(f"   git lfs install")
            print(f"   git clone {url} temp_{model_key}")
            if 'target_filename' in config:
                original_file = config['files'][0]
                target_file = config['target_filename']
                print(f"   copy temp_{model_key}\\{original_file} {target_dir}\\{target_file}")
            else:
                print(f"   copy temp_{model_key}\\*.* {target_dir}\\")
            print(f"   rmdir /s temp_{model_key}")
        
        # æ–¹æ³•2: HuggingFace Hub
        print(f"\n2ï¸âƒ£ ä½¿ç”¨HuggingFace Hub:")
        print(f"   pip install huggingface_hub")
        print(f"   python -c \"")
        print(f"   from huggingface_hub import snapshot_download")
        if 'huggingface' in config['download_sources']:
            repo_id = config['download_sources']['huggingface'].split('/')[-2:]
            repo_id = '/'.join(repo_id)
            print(f"   snapshot_download(repo_id='{repo_id}', local_dir='{target_dir}')\"")
        
        # æ–¹æ³•3: ç›´æ¥ä¸‹è½½é“¾æ¥
        print(f"\n3ï¸âƒ£ ç›´æ¥ä¸‹è½½ (é€‚ç”¨äºå•æ–‡ä»¶):")
        if len(config['files']) == 1 and 'gguf' in model_key:
            for source_name, base_url in config['download_sources'].items():
                file_name = config['files'][0]
                if 'target_filename' in config:
                    target_name = config['target_filename']
                else:
                    target_name = file_name
                
                print(f"\n   ğŸ“ {source_name.upper()}:")
                if source_name == 'modelscope':
                    download_url = f"{base_url}/resolve/main/{file_name}"
                else:
                    download_url = f"{base_url}/resolve/main/{file_name}"
                
                print(f"   curl -L \"{download_url}\" -o \"{target_dir}\\{target_name}\"")
    
    def verify_installation(self, model_key: str):
        """éªŒè¯æ¨¡å‹å®‰è£…"""
        if model_key not in self.models_config:
            return False
        
        config = self.models_config[model_key]
        target_dir = Path(config['target_dir'])
        
        print(f"ğŸ” éªŒè¯ {config['name']} å®‰è£…...")
        
        missing_files = []
        total_size = 0
        
        for file_name in config['files']:
            if 'target_filename' in config and file_name == config['files'][0]:
                file_path = target_dir / config['target_filename']
            else:
                file_path = target_dir / file_name
            
            if file_path.exists():
                size = file_path.stat().st_size
                total_size += size
                size_mb = size / (1024 * 1024)
                print(f"  âœ… {file_path.name} ({size_mb:.1f}MB)")
            else:
                missing_files.append(file_name)
                print(f"  âŒ {file_name} (ç¼ºå¤±)")
        
        if missing_files:
            print(f"âš ï¸ ç¼ºå¤±æ–‡ä»¶: {len(missing_files)} ä¸ª")
            return False
        else:
            total_gb = total_size / (1024 * 1024 * 1024)
            print(f"âœ… å®‰è£…å®Œæˆ! æ€»å¤§å°: {total_gb:.1f}GB")
            return True
    
    def create_download_script(self, model_keys: List[str]):
        """åˆ›å»ºä¸‹è½½è„šæœ¬"""
        script_content = """@echo off
echo VisionAI-ClipsMaster æ¨¡å‹ä¸‹è½½è„šæœ¬
echo =====================================

"""
        
        for model_key in model_keys:
            if model_key in self.models_config:
                config = self.models_config[model_key]
                script_content += f"""
echo.
echo ä¸‹è½½ {config['name']}...
mkdir "{config['target_dir']}" 2>nul

"""
                # æ·»åŠ Git LFSä¸‹è½½å‘½ä»¤
                if 'modelscope' in config['download_sources']:
                    url = config['download_sources']['modelscope']
                    script_content += f"""git lfs install
git clone {url} temp_{model_key}
"""
                    if 'target_filename' in config:
                        original_file = config['files'][0]
                        target_file = config['target_filename']
                        script_content += f"""copy "temp_{model_key}\\{original_file}" "{config['target_dir']}\\{target_file}"
"""
                    else:
                        script_content += f"""xcopy "temp_{model_key}\\*.*" "{config['target_dir']}\\" /E /Y
"""
                    script_content += f"""rmdir /s /q temp_{model_key}
"""
        
        script_content += """
echo.
echo ä¸‹è½½å®Œæˆ! è¯·è¿è¡ŒéªŒè¯è„šæœ¬æ£€æŸ¥å®‰è£…ç»“æœã€‚
pause
"""
        
        script_file = Path("download_models.bat")
        with open(script_file, 'w', encoding='utf-8') as f:
            f.write(script_content)
        
        print(f"âœ… ä¸‹è½½è„šæœ¬å·²åˆ›å»º: {script_file}")
        print("ğŸ’¡ è¿è¡Œæ–¹æ³•: åŒå‡» download_models.bat")

def main():
    """ä¸»å‡½æ•°"""
    guide = ModelDownloadGuide()
    
    while True:
        guide.show_download_options()
        
        print("\nğŸ¯ è¯·é€‰æ‹©æ“ä½œ:")
        print("  1-4: æŸ¥çœ‹å…·ä½“æ¨¡å‹ä¸‹è½½æ–¹æ¡ˆ")
        print("  5: åˆ›å»ºè‡ªåŠ¨ä¸‹è½½è„šæœ¬")
        print("  6: éªŒè¯å·²å®‰è£…æ¨¡å‹")
        print("  0: é€€å‡º")
        
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (0-6): ").strip()
        
        if choice == "0":
            break
        elif choice in ["1", "2", "3", "4"]:
            model_keys = list(guide.models_config.keys())
            model_key = model_keys[int(choice) - 1]
            guide.generate_download_commands(model_key)
            input("\næŒ‰å›è½¦ç»§ç»­...")
        elif choice == "5":
            print("\né€‰æ‹©è¦ä¸‹è½½çš„æ¨¡å‹ (å¤šé€‰ç”¨é€—å·åˆ†éš”ï¼Œå¦‚: 3,4):")
            selections = input("è¾“å…¥é€‰æ‹©: ").strip().split(',')
            model_keys = []
            for sel in selections:
                try:
                    idx = int(sel.strip()) - 1
                    if 0 <= idx < len(guide.models_config):
                        model_keys.append(list(guide.models_config.keys())[idx])
                except:
                    continue
            
            if model_keys:
                guide.create_download_script(model_keys)
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©")
            input("\næŒ‰å›è½¦ç»§ç»­...")
        elif choice == "6":
            print("\nğŸ” éªŒè¯æ¨¡å‹å®‰è£…çŠ¶æ€:")
            for model_key in guide.models_config:
                guide.verify_installation(model_key)
            input("\næŒ‰å›è½¦ç»§ç»­...")
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
        
        print("\n" + "="*60 + "\n")

if __name__ == "__main__":
    main()
