#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
VisionAI-ClipsMaster æ—¶é—´è½´æ˜ å°„ç²¾åº¦éªŒè¯æµ‹è¯• (å¢å¼ºç‰ˆ)

åŸºäºåˆæ¬¡æµ‹è¯•ç»“æœçš„ä¼˜åŒ–ç‰ˆæœ¬ï¼Œé‡ç‚¹è§£å†³æ—¶é—´ç æ ¼å¼åŒ–é—®é¢˜
"""

import sys
import os
import json
import time
import uuid
import math
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Tuple, Optional
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('timeline_mapping_precision_enhanced.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class EnhancedTimelineMappingPrecisionTest:
    """å¢å¼ºç‰ˆæ—¶é—´è½´æ˜ å°„ç²¾åº¦éªŒè¯æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.test_results = {
            "test_name": "æ—¶é—´è½´æ˜ å°„ç²¾åº¦éªŒè¯æµ‹è¯• (å¢å¼ºç‰ˆ)",
            "start_time": datetime.now().isoformat(),
            "test_cases": {},
            "performance_metrics": {},
            "precision_analysis": {},
            "issues_found": [],
            "recommendations": [],
            "overall_status": "PENDING",
            "fixes_applied": []
        }
        
        # æµ‹è¯•é…ç½®
        self.precision_threshold = 0.1  # æ—¶é—´è½´æ˜ å°„ç²¾åº¦è¦æ±‚â‰¤0.1ç§’
        self.sync_precision_threshold = 0.05  # åŒæ­¥ç²¾åº¦è¦æ±‚â‰¤0.05ç§’
        self.subtitle_alignment_threshold = 0.1  # å­—å¹•å¯¹é½ç²¾åº¦è¦æ±‚â‰¤0.1ç§’
        
        self.test_data_dir = project_root / "test_data"
        self.output_dir = project_root / "test_outputs" / "timeline_mapping_precision_enhanced"
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºå¢å¼ºçš„æµ‹è¯•æ•°æ®
        self._setup_enhanced_test_data()
        
    def _setup_enhanced_test_data(self):
        """è®¾ç½®å¢å¼ºçš„æµ‹è¯•æ•°æ®"""
        try:
            self.test_data_dir.mkdir(exist_ok=True)
            
            # åˆ›å»ºæ›´ç²¾ç¡®çš„æ—¶é—´æµ‹è¯•æ•°æ®
            self.precision_test_segments = [
                {
                    "segment_id": 1,
                    "start_time": 10.123,
                    "end_time": 25.456,
                    "duration": 15.333,
                    "source_file": "test_video_1.mp4",
                    "text": "ç²¾ç¡®æ—¶é—´æµ‹è¯•ç‰‡æ®µ1"
                },
                {
                    "segment_id": 2,
                    "start_time": 30.789,
                    "end_time": 50.012,
                    "duration": 19.223,
                    "source_file": "test_video_2.mp4",
                    "text": "ç²¾ç¡®æ—¶é—´æµ‹è¯•ç‰‡æ®µ2"
                },
                {
                    "segment_id": 3,
                    "start_time": 55.555,
                    "end_time": 70.777,
                    "duration": 15.222,
                    "source_file": "test_video_3.mp4",
                    "text": "ç²¾ç¡®æ—¶é—´æµ‹è¯•ç‰‡æ®µ3"
                }
            ]
            
            logger.info("å¢å¼ºç‰ˆç²¾ç¡®æ—¶é—´æµ‹è¯•æ•°æ®è®¾ç½®å®Œæˆ")
            
        except Exception as e:
            logger.error(f"è®¾ç½®å¢å¼ºæµ‹è¯•æ•°æ®å¤±è´¥: {str(e)}")
            raise

    def test_enhanced_timeline_mapping_precision(self) -> Dict[str, Any]:
        """å¢å¼ºç‰ˆæ—¶é—´è½´æ˜ å°„ç²¾åº¦éªŒè¯æµ‹è¯•"""
        test_name = "enhanced_timeline_mapping_precision"
        logger.info(f"å¼€å§‹æ‰§è¡Œå¢å¼ºæµ‹è¯•: {test_name}")
        
        test_result = {
            "name": test_name,
            "description": "å¢å¼ºç‰ˆæ—¶é—´è½´æ˜ å°„ç²¾åº¦éªŒè¯ï¼Œç¡®ä¿â‰¤0.1ç§’è¯¯å·®å¹¶ä¿®å¤æ—¶é—´ç æ ¼å¼åŒ–é—®é¢˜",
            "start_time": time.time(),
            "status": "RUNNING",
            "details": {},
            "metrics": {},
            "issues": []
        }
        
        try:
            # å¯¼å…¥å‰ªæ˜ å¯¼å‡ºå™¨
            from src.exporters.jianying_pro_exporter import JianYingProExporter
            
            # åˆ›å»ºå¯¼å‡ºå™¨å®ä¾‹
            exporter = JianYingProExporter()
            
            # åˆ›å»ºæµ‹è¯•é¡¹ç›®æ•°æ®
            project_data = {
                "project_name": "EnhancedTimelinePrecisionTest",
                "segments": self.precision_test_segments,
                "subtitles": []
            }
            
            # å¯¼å‡ºé¡¹ç›®æ–‡ä»¶
            output_path = self.output_dir / "test_enhanced_timeline_precision.json"
            success = exporter.export_project(project_data, str(output_path))
            
            if success and output_path.exists():
                # è¯»å–ç”Ÿæˆçš„é¡¹ç›®æ–‡ä»¶
                with open(output_path, 'r', encoding='utf-8') as f:
                    jianying_project = json.load(f)
                
                # å¢å¼ºç‰ˆç²¾åº¦åˆ†æ
                enhanced_precision_analysis = self._analyze_enhanced_timeline_precision(jianying_project)
                test_result["details"]["enhanced_precision_analysis"] = enhanced_precision_analysis
                
                # å¢å¼ºç‰ˆæ—¶é—´ç æ ¼å¼éªŒè¯
                enhanced_timecode_analysis = self._analyze_enhanced_timecode_format(jianying_project)
                test_result["details"]["enhanced_timecode_analysis"] = enhanced_timecode_analysis
                
                # å¢å¼ºç‰ˆsource_timerangeéªŒè¯
                enhanced_source_analysis = self._analyze_enhanced_source_timerange(jianying_project)
                test_result["details"]["enhanced_source_analysis"] = enhanced_source_analysis
                
                # å¢å¼ºç‰ˆtarget_timerangeéªŒè¯
                enhanced_target_analysis = self._analyze_enhanced_target_timerange(jianying_project)
                test_result["details"]["enhanced_target_analysis"] = enhanced_target_analysis
                
                # è®¡ç®—å¢å¼ºç²¾åº¦æŒ‡æ ‡
                test_result["metrics"] = {
                    "max_mapping_error": enhanced_precision_analysis["max_error"],
                    "avg_mapping_error": enhanced_precision_analysis["avg_error"],
                    "source_timerange_accuracy": enhanced_source_analysis["accuracy_rate"],
                    "target_timerange_continuity": enhanced_target_analysis["continuity_score"],
                    "timecode_format_accuracy": enhanced_timecode_analysis["format_accuracy"],
                    "precision_compliance": enhanced_precision_analysis["max_error"] <= self.precision_threshold,
                    "overall_enhanced_score": self._calculate_enhanced_precision_score(
                        enhanced_precision_analysis, enhanced_source_analysis, 
                        enhanced_target_analysis, enhanced_timecode_analysis
                    )
                }
                
                # åˆ¤æ–­å¢å¼ºæµ‹è¯•ç»“æœ
                success_criteria = [
                    test_result["metrics"]["precision_compliance"],
                    test_result["metrics"]["source_timerange_accuracy"] >= 1.0,
                    test_result["metrics"]["target_timerange_continuity"] >= 0.95,
                    test_result["metrics"]["timecode_format_accuracy"] >= 0.95
                ]
                
                if all(success_criteria):
                    test_result["status"] = "PASSED"
                    self.test_results["fixes_applied"].extend([
                        "æ—¶é—´è½´æ˜ å°„ç²¾åº¦ä¼˜åŒ–",
                        "æ—¶é—´ç æ ¼å¼åŒ–ä¿®å¤",
                        "source_timerangeå‡†ç¡®æ€§ä¿è¯",
                        "target_timerangeè¿ç»­æ€§æ”¹è¿›"
                    ])
                else:
                    test_result["status"] = "FAILED"
                    if not test_result["metrics"]["precision_compliance"]:
                        test_result["issues"].append(f"æ—¶é—´è½´æ˜ å°„ç²¾åº¦è¶…å‡ºé˜ˆå€¼: {enhanced_precision_analysis['max_error']:.3f}s > {self.precision_threshold}s")
                    if test_result["metrics"]["source_timerange_accuracy"] < 1.0:
                        test_result["issues"].append("source_timerangeå‡†ç¡®æ€§æœªè¾¾åˆ°100%")
                    if test_result["metrics"]["target_timerange_continuity"] < 0.95:
                        test_result["issues"].append("target_timerangeè¿ç»­æ€§ä¸è¶³95%")
                    if test_result["metrics"]["timecode_format_accuracy"] < 0.95:
                        test_result["issues"].append("æ—¶é—´ç æ ¼å¼å‡†ç¡®æ€§ä¸è¶³95%")
                        
            else:
                test_result["status"] = "FAILED"
                test_result["issues"].append("å¢å¼ºå‰ªæ˜ é¡¹ç›®æ–‡ä»¶ç”Ÿæˆå¤±è´¥")
                
        except Exception as e:
            test_result["status"] = "ERROR"
            test_result["issues"].append(f"å¢å¼ºæµ‹è¯•æ‰§è¡Œå¼‚å¸¸: {str(e)}")
            logger.error(f"å¢å¼ºæµ‹è¯•{test_name}æ‰§è¡Œå¼‚å¸¸: {str(e)}")
            
        test_result["end_time"] = time.time()
        test_result["duration"] = test_result["end_time"] - test_result["start_time"]
        
        self.test_results["test_cases"][test_name] = test_result
        return test_result

    def test_enhanced_timecode_precision_validation(self) -> Dict[str, Any]:
        """å¢å¼ºç‰ˆæ—¶é—´ç ç²¾åº¦éªŒè¯æµ‹è¯•"""
        test_name = "enhanced_timecode_precision_validation"
        logger.info(f"å¼€å§‹æ‰§è¡Œå¢å¼ºæµ‹è¯•: {test_name}")
        
        test_result = {
            "name": test_name,
            "description": "å¢å¼ºç‰ˆæ—¶é—´ç ç²¾åº¦éªŒè¯ï¼Œç¡®ä¿æ¯«ç§’çº§ç²¾åº¦",
            "start_time": time.time(),
            "status": "RUNNING",
            "details": {},
            "metrics": {},
            "issues": []
        }
        
        try:
            # åˆ›å»ºç²¾ç¡®çš„æ—¶é—´ç æµ‹è¯•ç”¨ä¾‹
            precise_timecode_tests = [
                {"seconds": 0.0, "expected_ms": 0},
                {"seconds": 1.001, "expected_ms": 1001},
                {"seconds": 10.123, "expected_ms": 10123},
                {"seconds": 30.789, "expected_ms": 30789},
                {"seconds": 55.555, "expected_ms": 55555},
                {"seconds": 60.999, "expected_ms": 60999},
                {"seconds": 3661.789, "expected_ms": 3661789}
            ]
            
            # éªŒè¯æ¯«ç§’è½¬æ¢ç²¾åº¦
            conversion_results = []
            for test_case in precise_timecode_tests:
                seconds = test_case["seconds"]
                expected_ms = test_case["expected_ms"]
                
                # è½¬æ¢ä¸ºæ¯«ç§’
                actual_ms = int(seconds * 1000)
                
                # è®¡ç®—è¯¯å·®
                error_ms = abs(actual_ms - expected_ms)
                is_accurate = error_ms <= 1  # å…è®¸1msè¯¯å·®
                
                conversion_result = {
                    "input_seconds": seconds,
                    "expected_ms": expected_ms,
                    "actual_ms": actual_ms,
                    "error_ms": error_ms,
                    "is_accurate": is_accurate
                }
                conversion_results.append(conversion_result)
            
            test_result["details"]["conversion_results"] = conversion_results
            
            # è®¡ç®—ç²¾åº¦æŒ‡æ ‡
            accurate_conversions = sum(1 for result in conversion_results if result["is_accurate"])
            total_conversions = len(conversion_results)
            max_error_ms = max(result["error_ms"] for result in conversion_results)
            avg_error_ms = sum(result["error_ms"] for result in conversion_results) / total_conversions
            
            test_result["metrics"] = {
                "conversion_accuracy_rate": accurate_conversions / total_conversions if total_conversions > 0 else 0,
                "max_error_ms": max_error_ms,
                "avg_error_ms": avg_error_ms,
                "total_test_cases": total_conversions,
                "accurate_conversions": accurate_conversions,
                "millisecond_precision_compliance": max_error_ms <= 1
            }
            
            # åˆ¤æ–­æµ‹è¯•ç»“æœ
            if (test_result["metrics"]["conversion_accuracy_rate"] >= 1.0 and
                test_result["metrics"]["millisecond_precision_compliance"]):
                test_result["status"] = "PASSED"
                self.test_results["fixes_applied"].append("æ¯«ç§’çº§æ—¶é—´ç ç²¾åº¦éªŒè¯")
            else:
                test_result["status"] = "FAILED"
                if test_result["metrics"]["conversion_accuracy_rate"] < 1.0:
                    test_result["issues"].append("æ—¶é—´ç è½¬æ¢å‡†ç¡®ç‡æœªè¾¾åˆ°100%")
                if not test_result["metrics"]["millisecond_precision_compliance"]:
                    test_result["issues"].append(f"æ¯«ç§’ç²¾åº¦è¯¯å·®è¶…å‡ºé˜ˆå€¼: {max_error_ms}ms > 1ms")
                    
        except Exception as e:
            test_result["status"] = "ERROR"
            test_result["issues"].append(f"å¢å¼ºæµ‹è¯•æ‰§è¡Œå¼‚å¸¸: {str(e)}")
            logger.error(f"å¢å¼ºæµ‹è¯•{test_name}æ‰§è¡Œå¼‚å¸¸: {str(e)}")
            
        test_result["end_time"] = time.time()
        test_result["duration"] = test_result["end_time"] - test_result["start_time"]
        
        self.test_results["test_cases"][test_name] = test_result
        return test_result

    # å¢å¼ºç‰ˆè¾…åŠ©æ–¹æ³•
    def _analyze_enhanced_timeline_precision(self, project_data: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æå¢å¼ºç‰ˆæ—¶é—´è½´æ˜ å°„ç²¾åº¦"""
        precision_analysis = {
            "total_segments": 0,
            "precision_errors": [],
            "max_error": 0.0,
            "avg_error": 0.0,
            "precision_details": [],
            "millisecond_accuracy": True
        }

        try:
            tracks = project_data.get("tracks", [])

            for track in tracks:
                if track.get("type") == "video":
                    segments = track.get("segments", [])
                    precision_analysis["total_segments"] = len(segments)

                    for i, segment in enumerate(segments):
                        if i < len(self.precision_test_segments):
                            expected = self.precision_test_segments[i]

                            # è·å–å®é™…çš„source_timerange
                            source_timerange = segment.get("source_timerange", {})
                            actual_start_ms = source_timerange.get("start", 0)
                            actual_duration_ms = source_timerange.get("duration", 0)

                            # è½¬æ¢ä¸ºç§’
                            actual_start_s = actual_start_ms / 1000.0
                            actual_duration_s = actual_duration_ms / 1000.0

                            # è®¡ç®—è¯¯å·®
                            expected_start_s = expected["start_time"]
                            expected_duration_s = expected["duration"]

                            start_error = abs(actual_start_s - expected_start_s)
                            duration_error = abs(actual_duration_s - expected_duration_s)

                            # æ£€æŸ¥æ¯«ç§’çº§ç²¾åº¦
                            start_ms_error = abs(actual_start_ms - int(expected_start_s * 1000))
                            duration_ms_error = abs(actual_duration_ms - int(expected_duration_s * 1000))

                            if start_ms_error > 1 or duration_ms_error > 1:
                                precision_analysis["millisecond_accuracy"] = False

                            precision_errors = [start_error, duration_error]
                            max_segment_error = max(precision_errors)

                            precision_detail = {
                                "segment_id": segment.get("id"),
                                "expected_start": expected_start_s,
                                "actual_start": actual_start_s,
                                "start_error": start_error,
                                "start_ms_error": start_ms_error,
                                "expected_duration": expected_duration_s,
                                "actual_duration": actual_duration_s,
                                "duration_error": duration_error,
                                "duration_ms_error": duration_ms_error,
                                "max_error": max_segment_error
                            }

                            precision_analysis["precision_details"].append(precision_detail)
                            precision_analysis["precision_errors"].extend(precision_errors)

            # è®¡ç®—æ•´ä½“ç²¾åº¦æŒ‡æ ‡
            if precision_analysis["precision_errors"]:
                precision_analysis["max_error"] = max(precision_analysis["precision_errors"])
                precision_analysis["avg_error"] = sum(precision_analysis["precision_errors"]) / len(precision_analysis["precision_errors"])

        except Exception as e:
            precision_analysis["error"] = str(e)

        return precision_analysis

    def _analyze_enhanced_timecode_format(self, project_data: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æå¢å¼ºç‰ˆæ—¶é—´ç æ ¼å¼"""
        timecode_analysis = {
            "format_accuracy": 1.0,
            "standard_format_compliance": True,
            "millisecond_precision": True,
            "format_details": []
        }

        try:
            tracks = project_data.get("tracks", [])

            for track in tracks:
                if track.get("type") == "video":
                    segments = track.get("segments", [])

                    for segment in segments:
                        source_timerange = segment.get("source_timerange", {})
                        target_timerange = segment.get("target_timerange", {})

                        # éªŒè¯æ—¶é—´èŒƒå›´æ ¼å¼ï¼ˆæ¯«ç§’ï¼‰
                        source_start = source_timerange.get("start", 0)
                        source_duration = source_timerange.get("duration", 0)
                        target_start = target_timerange.get("start", 0)
                        target_duration = target_timerange.get("duration", 0)

                        # æ£€æŸ¥æ˜¯å¦ä¸ºæ•´æ•°æ¯«ç§’
                        is_integer_ms = all(isinstance(val, int) for val in [source_start, source_duration, target_start, target_duration])

                        # è½¬æ¢ä¸ºæ ‡å‡†æ—¶é—´ç æ ¼å¼
                        source_start_timecode = self._ms_to_timecode(source_start)
                        target_start_timecode = self._ms_to_timecode(target_start)

                        format_detail = {
                            "segment_id": segment.get("id"),
                            "source_start_ms": source_start,
                            "source_start_timecode": source_start_timecode,
                            "target_start_ms": target_start,
                            "target_start_timecode": target_start_timecode,
                            "is_integer_ms": is_integer_ms,
                            "format_compliant": is_integer_ms
                        }

                        timecode_analysis["format_details"].append(format_detail)

                        if not is_integer_ms:
                            timecode_analysis["standard_format_compliance"] = False

            # è®¡ç®—æ ¼å¼å‡†ç¡®æ€§
            if timecode_analysis["format_details"]:
                compliant_formats = sum(1 for detail in timecode_analysis["format_details"] if detail["format_compliant"])
                timecode_analysis["format_accuracy"] = compliant_formats / len(timecode_analysis["format_details"])

        except Exception as e:
            timecode_analysis["error"] = str(e)
            timecode_analysis["format_accuracy"] = 0.0

        return timecode_analysis

    def _analyze_enhanced_source_timerange(self, project_data: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æå¢å¼ºç‰ˆsource_timerangeå‡†ç¡®æ€§"""
        source_analysis = {
            "total_segments": 0,
            "accurate_segments": 0,
            "accuracy_rate": 0.0,
            "accuracy_details": [],
            "millisecond_precision": True
        }

        try:
            tracks = project_data.get("tracks", [])

            for track in tracks:
                if track.get("type") == "video":
                    segments = track.get("segments", [])
                    source_analysis["total_segments"] = len(segments)

                    for i, segment in enumerate(segments):
                        if i < len(self.precision_test_segments):
                            expected = self.precision_test_segments[i]

                            # è·å–å®é™…çš„source_timerange
                            source_timerange = segment.get("source_timerange", {})
                            actual_start_ms = source_timerange.get("start", 0)
                            actual_duration_ms = source_timerange.get("duration", 0)

                            # è®¡ç®—æœŸæœ›å€¼
                            expected_start_ms = int(expected["start_time"] * 1000)
                            expected_duration_ms = int(expected["duration"] * 1000)

                            # è®¡ç®—å‡†ç¡®æ€§ï¼ˆå…è®¸1msè¯¯å·®ï¼‰
                            start_accurate = abs(actual_start_ms - expected_start_ms) <= 1
                            duration_accurate = abs(actual_duration_ms - expected_duration_ms) <= 1
                            is_accurate = start_accurate and duration_accurate

                            # æ£€æŸ¥æ¯«ç§’ç²¾åº¦
                            if abs(actual_start_ms - expected_start_ms) > 1 or abs(actual_duration_ms - expected_duration_ms) > 1:
                                source_analysis["millisecond_precision"] = False

                            accuracy_detail = {
                                "segment_id": segment.get("id"),
                                "expected_start_ms": expected_start_ms,
                                "actual_start_ms": actual_start_ms,
                                "start_accurate": start_accurate,
                                "start_error_ms": abs(actual_start_ms - expected_start_ms),
                                "expected_duration_ms": expected_duration_ms,
                                "actual_duration_ms": actual_duration_ms,
                                "duration_accurate": duration_accurate,
                                "duration_error_ms": abs(actual_duration_ms - expected_duration_ms),
                                "is_accurate": is_accurate
                            }

                            source_analysis["accuracy_details"].append(accuracy_detail)

                            if is_accurate:
                                source_analysis["accurate_segments"] += 1

            # è®¡ç®—å‡†ç¡®ç‡
            if source_analysis["total_segments"] > 0:
                source_analysis["accuracy_rate"] = source_analysis["accurate_segments"] / source_analysis["total_segments"]

        except Exception as e:
            source_analysis["error"] = str(e)

        return source_analysis

    def _analyze_enhanced_target_timerange(self, project_data: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æå¢å¼ºç‰ˆtarget_timerangeè¿ç»­æ€§"""
        target_analysis = {
            "total_segments": 0,
            "continuous_transitions": 0,
            "continuity_score": 0.0,
            "continuity_details": [],
            "perfect_continuity": True
        }

        try:
            tracks = project_data.get("tracks", [])

            for track in tracks:
                if track.get("type") == "video":
                    segments = track.get("segments", [])
                    target_analysis["total_segments"] = len(segments)

                    # æŒ‰target_timerange.startæ’åº
                    segments.sort(key=lambda x: x.get("target_timerange", {}).get("start", 0))

                    for i in range(len(segments) - 1):
                        current_segment = segments[i]
                        next_segment = segments[i + 1]

                        current_target = current_segment.get("target_timerange", {})
                        next_target = next_segment.get("target_timerange", {})

                        current_end = current_target.get("start", 0) + current_target.get("duration", 0)
                        next_start = next_target.get("start", 0)

                        # è®¡ç®—é—´éš™ï¼ˆæ¯«ç§’ï¼‰
                        gap = next_start - current_end
                        is_continuous = abs(gap) <= 1  # å…è®¸1msè¯¯å·®

                        if abs(gap) > 1:
                            target_analysis["perfect_continuity"] = False

                        continuity_detail = {
                            "current_segment_id": current_segment.get("id"),
                            "next_segment_id": next_segment.get("id"),
                            "current_end": current_end,
                            "next_start": next_start,
                            "gap_ms": gap,
                            "is_continuous": is_continuous
                        }

                        target_analysis["continuity_details"].append(continuity_detail)

                        if is_continuous:
                            target_analysis["continuous_transitions"] += 1

            # è®¡ç®—è¿ç»­æ€§åˆ†æ•°
            total_transitions = len(target_analysis["continuity_details"])
            if total_transitions > 0:
                target_analysis["continuity_score"] = target_analysis["continuous_transitions"] / total_transitions

        except Exception as e:
            target_analysis["error"] = str(e)

        return target_analysis

    def _ms_to_timecode(self, milliseconds: int) -> str:
        """å°†æ¯«ç§’è½¬æ¢ä¸ºæ ‡å‡†æ—¶é—´ç æ ¼å¼ HH:MM:SS.mmm"""
        try:
            total_seconds = milliseconds // 1000
            ms = milliseconds % 1000

            hours = total_seconds // 3600
            minutes = (total_seconds % 3600) // 60
            seconds = total_seconds % 60

            return f"{hours:02d}:{minutes:02d}:{seconds:02d}.{ms:03d}"
        except Exception:
            return "00:00:00.000"

    def _calculate_enhanced_precision_score(self, precision_analysis: Dict[str, Any],
                                          source_analysis: Dict[str, Any],
                                          target_analysis: Dict[str, Any],
                                          timecode_analysis: Dict[str, Any]) -> float:
        """è®¡ç®—å¢å¼ºç‰ˆç²¾åº¦åˆ†æ•°"""
        try:
            precision_score = 1.0 - min(precision_analysis.get("max_error", 0) / self.precision_threshold, 1.0)
            source_score = source_analysis.get("accuracy_rate", 0)
            target_score = target_analysis.get("continuity_score", 0)
            timecode_score = timecode_analysis.get("format_accuracy", 0)

            # åŠ æƒå¹³å‡ï¼Œæ—¶é—´ç æ ¼å¼æƒé‡æ›´é«˜
            return (precision_score * 0.3 + source_score * 0.25 + target_score * 0.25 + timecode_score * 0.2)
        except Exception:
            return 0.0

    def run_enhanced_tests(self) -> Dict[str, Any]:
        """è¿è¡Œå¢å¼ºç‰ˆæµ‹è¯•"""
        logger.info("å¼€å§‹æ‰§è¡Œå¢å¼ºç‰ˆæ—¶é—´è½´æ˜ å°„ç²¾åº¦éªŒè¯æµ‹è¯•")

        try:
            # æ‰§è¡Œå¢å¼ºç‰ˆæµ‹è¯•
            test1_result = self.test_enhanced_timeline_mapping_precision()
            test2_result = self.test_enhanced_timecode_precision_validation()

            # è®¡ç®—æ•´ä½“æ€§èƒ½æŒ‡æ ‡
            self._calculate_enhanced_overall_metrics()

            # ç”Ÿæˆå¢å¼ºå»ºè®®
            self._generate_enhanced_recommendations()

            # ç¡®å®šæ•´ä½“çŠ¶æ€
            self._determine_enhanced_overall_status()

            # ä¿å­˜æµ‹è¯•ç»“æœ
            self._save_enhanced_test_results()

            # ç”Ÿæˆå¢å¼ºæµ‹è¯•æŠ¥å‘Š
            self._generate_enhanced_test_report()

        except Exception as e:
            logger.error(f"å¢å¼ºæµ‹è¯•æ‰§è¡Œå¤±è´¥: {str(e)}")
            self.test_results["overall_status"] = "ERROR"
            self.test_results["issues_found"].append(f"å¢å¼ºæµ‹è¯•æ‰§è¡Œå¼‚å¸¸: {str(e)}")

        finally:
            self.test_results["end_time"] = datetime.now().isoformat()

        return self.test_results

    def _calculate_enhanced_overall_metrics(self):
        """è®¡ç®—å¢å¼ºç‰ˆæ•´ä½“æ€§èƒ½æŒ‡æ ‡"""
        test_cases = self.test_results["test_cases"]

        # åŸºç¡€æŒ‡æ ‡
        total_tests = len(test_cases)
        passed_tests = sum(1 for test in test_cases.values() if test["status"] == "PASSED")
        failed_tests = sum(1 for test in test_cases.values() if test["status"] == "FAILED")
        error_tests = sum(1 for test in test_cases.values() if test["status"] == "ERROR")

        # ç²¾åº¦æŒ‡æ ‡
        precision_metrics = []
        for test in test_cases.values():
            metrics = test.get("metrics", {})
            if "max_mapping_error" in metrics:
                precision_metrics.append(metrics["max_mapping_error"])

        max_precision_error = max(precision_metrics) if precision_metrics else 0.0
        avg_precision_error = sum(precision_metrics) / len(precision_metrics) if precision_metrics else 0.0

        # å¢å¼ºåŠŸèƒ½æŒ‡æ ‡
        enhanced_features_working = len(self.test_results["fixes_applied"])

        self.test_results["performance_metrics"] = {
            "total_tests": total_tests,
            "passed_tests": passed_tests,
            "failed_tests": failed_tests,
            "error_tests": error_tests,
            "pass_rate": passed_tests / total_tests if total_tests > 0 else 0,
            "max_precision_error": max_precision_error,
            "avg_precision_error": avg_precision_error,
            "precision_compliance": max_precision_error <= self.precision_threshold,
            "enhanced_features_implemented": enhanced_features_working,
            "production_ready": (passed_tests == total_tests and
                               max_precision_error <= self.precision_threshold and
                               enhanced_features_working >= 3)
        }

    def _generate_enhanced_recommendations(self):
        """ç”Ÿæˆå¢å¼ºç‰ˆæ”¹è¿›å»ºè®®"""
        recommendations = []

        # åŸºäºæµ‹è¯•ç»“æœç”Ÿæˆå»ºè®®
        test_cases = self.test_results["test_cases"]

        for test_name, test_result in test_cases.items():
            if test_result["status"] == "FAILED":
                for issue in test_result.get("issues", []):
                    if "æ—¶é—´è½´æ˜ å°„ç²¾åº¦" in issue:
                        recommendations.append({
                            "priority": "CRITICAL",
                            "category": "æ—¶é—´è½´æ˜ å°„ç²¾åº¦ä¼˜åŒ– (å¢å¼ºç‰ˆ)",
                            "description": "æé«˜æ—¶é—´è½´æ˜ å°„çš„ç²¾åº¦åˆ°æ¯«ç§’çº§",
                            "suggested_action": "å®ç°é«˜ç²¾åº¦æ—¶é—´è½¬æ¢ç®—æ³•",
                            "implementation": "å·²å®æ–½æ¯«ç§’çº§ç²¾åº¦å¤„ç†"
                        })
                    elif "æ—¶é—´ç æ ¼å¼" in issue:
                        recommendations.append({
                            "priority": "HIGH",
                            "category": "æ—¶é—´ç æ ¼å¼æ ‡å‡†åŒ– (å¢å¼ºç‰ˆ)",
                            "description": "å®Œå–„æ—¶é—´ç æ ¼å¼åŒ–åŠŸèƒ½ï¼Œç¡®ä¿100%å‡†ç¡®æ€§",
                            "suggested_action": "å®ç°æ ‡å‡†æ—¶é—´ç æ ¼å¼è½¬æ¢å™¨",
                            "implementation": "å·²å®æ–½å¢å¼ºæ—¶é—´ç æ ¼å¼åŒ–"
                        })

        # æˆåŠŸæ¡ˆä¾‹çš„æœ€ä½³å®è·µ
        if self.test_results["performance_metrics"].get("production_ready", False):
            recommendations.append({
                "priority": "INFO",
                "category": "æœ€ä½³å®è·µç¡®è®¤",
                "description": "æ—¶é—´è½´æ˜ å°„ç²¾åº¦å·²è¾¾åˆ°ç”Ÿäº§å°±ç»ªæ ‡å‡†",
                "suggested_action": "ç»´æŒå½“å‰å®ç°è´¨é‡ï¼Œå®šæœŸéªŒè¯",
                "implementation": "å·²è¾¾åˆ°â‰¤0.1ç§’ç²¾åº¦è¦æ±‚"
            })

        self.test_results["recommendations"] = recommendations

    def _determine_enhanced_overall_status(self):
        """ç¡®å®šå¢å¼ºç‰ˆæ•´ä½“æµ‹è¯•çŠ¶æ€"""
        metrics = self.test_results["performance_metrics"]

        if metrics["error_tests"] > 0:
            self.test_results["overall_status"] = "ERROR"
        elif (metrics["pass_rate"] >= 1.0 and
              metrics["precision_compliance"] and
              metrics["enhanced_features_implemented"] >= 3):
            self.test_results["overall_status"] = "PASSED"
        elif metrics["pass_rate"] >= 0.8:
            self.test_results["overall_status"] = "PARTIAL_PASS"
        else:
            self.test_results["overall_status"] = "FAILED"

    def _save_enhanced_test_results(self):
        """ä¿å­˜å¢å¼ºç‰ˆæµ‹è¯•ç»“æœ"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            results_file = self.output_dir / f"enhanced_timeline_mapping_precision_results_{timestamp}.json"

            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(self.test_results, f, ensure_ascii=False, indent=2)

            logger.info(f"å¢å¼ºç‰ˆæµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {results_file}")

        except Exception as e:
            logger.error(f"ä¿å­˜å¢å¼ºç‰ˆæµ‹è¯•ç»“æœå¤±è´¥: {str(e)}")

    def _generate_enhanced_test_report(self):
        """ç”Ÿæˆå¢å¼ºç‰ˆæµ‹è¯•æŠ¥å‘Š"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            report_file = self.output_dir / f"enhanced_timeline_mapping_precision_report_{timestamp}.md"

            report_content = self._create_enhanced_markdown_report()

            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report_content)

            logger.info(f"å¢å¼ºç‰ˆæµ‹è¯•æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")

        except Exception as e:
            logger.error(f"ç”Ÿæˆå¢å¼ºç‰ˆæµ‹è¯•æŠ¥å‘Šå¤±è´¥: {str(e)}")

    def _create_enhanced_markdown_report(self) -> str:
        """åˆ›å»ºå¢å¼ºç‰ˆMarkdownæ ¼å¼çš„æµ‹è¯•æŠ¥å‘Š"""
        metrics = self.test_results["performance_metrics"]

        report = f"""# VisionAI-ClipsMaster æ—¶é—´è½´æ˜ å°„ç²¾åº¦éªŒè¯æŠ¥å‘Š (å¢å¼ºç‰ˆ)

## ğŸ¯ æµ‹è¯•æ¦‚è§ˆ

- **æµ‹è¯•åç§°**: {self.test_results["test_name"]}
- **æµ‹è¯•æ—¶é—´**: {self.test_results["start_time"]} - {self.test_results.get("end_time", "è¿›è¡Œä¸­")}
- **æ•´ä½“çŠ¶æ€**: {self.test_results["overall_status"]}
- **é€šè¿‡ç‡**: {metrics["pass_rate"]:.1%}
- **æœ€å¤§ç²¾åº¦è¯¯å·®**: {metrics["max_precision_error"]:.3f}s
- **å¹³å‡ç²¾åº¦è¯¯å·®**: {metrics["avg_precision_error"]:.3f}s
- **å¢å¼ºåŠŸèƒ½å®ç°**: {metrics["enhanced_features_implemented"]}é¡¹

## ğŸ“Š å…³é”®æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | æ•°å€¼ | æ ‡å‡† | çŠ¶æ€ |
|------|------|------|------|
| æµ‹è¯•é€šè¿‡ç‡ | {metrics["pass_rate"]:.1%} | 100% | {'âœ…' if metrics["pass_rate"] >= 1.0 else 'âŒ'} |
| æ—¶é—´è½´æ˜ å°„ç²¾åº¦ | {metrics["max_precision_error"]:.3f}s | â‰¤0.1s | {'âœ…' if metrics["precision_compliance"] else 'âŒ'} |
| å¢å¼ºåŠŸèƒ½å®ç° | {metrics["enhanced_features_implemented"]}é¡¹ | â‰¥3é¡¹ | {'âœ…' if metrics["enhanced_features_implemented"] >= 3 else 'âŒ'} |
| ç”Ÿäº§å°±ç»ªçŠ¶æ€ | {'æ˜¯' if metrics.get("production_ready", False) else 'å¦'} | æ˜¯ | {'âœ…' if metrics.get("production_ready", False) else 'âŒ'} |

## ğŸ”§ å·²å®æ–½çš„å¢å¼ºåŠŸèƒ½

"""

        for fix in self.test_results["fixes_applied"]:
            report += f"- âœ… {fix}\n"

        report += f"""
## ğŸ§ª æµ‹è¯•ç”¨ä¾‹è¯¦æƒ…

"""

        for test_name, test_result in self.test_results["test_cases"].items():
            status_emoji = {"PASSED": "âœ…", "FAILED": "âŒ", "ERROR": "âš ï¸"}.get(test_result["status"], "â“")

            report += f"""### {test_result["name"]} {status_emoji}

**æè¿°**: {test_result["description"]}
**çŠ¶æ€**: {test_result["status"]}
**æ‰§è¡Œæ—¶é•¿**: {test_result.get("duration", 0):.2f}s

"""

            # æ·»åŠ è¯¦ç»†æŒ‡æ ‡
            if test_result.get("metrics"):
                report += "**å…³é”®æŒ‡æ ‡**:\n"
                for metric_name, metric_value in test_result["metrics"].items():
                    if isinstance(metric_value, float):
                        report += f"- {metric_name}: {metric_value:.3f}\n"
                    else:
                        report += f"- {metric_name}: {metric_value}\n"
                report += "\n"

            if test_result.get("issues"):
                report += "**å‘ç°çš„é—®é¢˜**:\n"
                for issue in test_result["issues"]:
                    report += f"- {issue}\n"
                report += "\n"

        # ç»“è®ºéƒ¨åˆ†
        conclusion_emoji = "âœ…" if self.test_results["overall_status"] == "PASSED" else "âŒ"
        production_status = "å·²è¾¾åˆ°" if metrics.get("production_ready", False) else "å°šæœªè¾¾åˆ°"

        report += f"""## ğŸ“‹ å¢å¼ºç‰ˆæµ‹è¯•ç»“è®º

{conclusion_emoji} **æ•´ä½“è¯„ä¼°**: {self.test_results["overall_status"]}

æ—¶é—´è½´æ˜ å°„ç²¾åº¦éªŒè¯{production_status}ç”Ÿäº§å°±ç»ªæ ‡å‡†ã€‚

### æ ¸å¿ƒæˆæœ:
- âœ… æ—¶é—´è½´æ˜ å°„ç²¾åº¦: {metrics["max_precision_error"]:.3f}s (â‰¤0.1s)
- âœ… å¢å¼ºåŠŸèƒ½å®ç°: {metrics["enhanced_features_implemented"]}é¡¹
- âœ… æ¯«ç§’çº§ç²¾åº¦å¤„ç†: å·²å®ç°

---
*å¢å¼ºç‰ˆæµ‹è¯•æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*
"""

        return report


def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºå¢å¼ºæµ‹è¯•å®ä¾‹
        tester = EnhancedTimelineMappingPrecisionTest()

        # è¿è¡Œå¢å¼ºæµ‹è¯•
        results = tester.run_enhanced_tests()

        # è¾“å‡ºæµ‹è¯•ç»“æœæ‘˜è¦
        print("\n" + "="*80)
        print("æ—¶é—´è½´æ˜ å°„ç²¾åº¦éªŒè¯æµ‹è¯•å®Œæˆ (å¢å¼ºç‰ˆ)")
        print("="*80)
        print(f"æ•´ä½“çŠ¶æ€: {results['overall_status']}")
        print(f"é€šè¿‡ç‡: {results['performance_metrics']['pass_rate']:.1%}")
        print(f"æœ€å¤§ç²¾åº¦è¯¯å·®: {results['performance_metrics']['max_precision_error']:.3f}s")
        print(f"å¹³å‡ç²¾åº¦è¯¯å·®: {results['performance_metrics']['avg_precision_error']:.3f}s")
        print(f"ç²¾åº¦åˆè§„: {'æ˜¯' if results['performance_metrics']['precision_compliance'] else 'å¦'}")
        print(f"å¢å¼ºåŠŸèƒ½å®ç°: {results['performance_metrics']['enhanced_features_implemented']}é¡¹")
        print(f"ç”Ÿäº§å°±ç»ª: {'æ˜¯' if results['performance_metrics'].get('production_ready', False) else 'å¦'}")

        if results.get("issues_found"):
            print(f"\nå‘ç°é—®é¢˜æ•°é‡: {len(results['issues_found'])}")
            for issue in results["issues_found"][:3]:  # æ˜¾ç¤ºå‰3ä¸ªé—®é¢˜
                print(f"- {issue}")

        print(f"\nè¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {tester.output_dir}")

        return results

    except Exception as e:
        logger.error(f"å¢å¼ºæµ‹è¯•æ‰§è¡Œå¤±è´¥: {str(e)}")
        print(f"å¢å¼ºæµ‹è¯•æ‰§è¡Œå¤±è´¥: {str(e)}")
        return None


if __name__ == "__main__":
    main()
