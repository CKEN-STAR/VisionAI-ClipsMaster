#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
VisionAI-ClipsMaster ç«¯åˆ°ç«¯æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨

æ­¤æ¨¡å—ç”Ÿæˆå®Œæ•´çš„ç«¯åˆ°ç«¯æµ‹è¯•æ•°æ®é›†ï¼ŒåŒ…æ‹¬åŸç‰‡è§†é¢‘ã€çˆ†æ¬¾SRTå­—å¹•ã€é¢„æœŸè¾“å‡ºæ–‡ä»¶ç­‰ã€‚
æ”¯æŒå¤šç§æµ‹è¯•åœºæ™¯ï¼Œç¡®ä¿æµ‹è¯•çš„å…¨é¢æ€§å’ŒçœŸå®æ€§ã€‚
"""

import os
import sys
import json
import time
import logging
import random
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
from dataclasses import dataclass
import uuid

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../../../')))

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
from src.utils.log_handler import LogHandler
from src.utils.file_checker import FileChecker

logger = logging.getLogger(__name__)


@dataclass
class E2ETestDataSet:
    """ç«¯åˆ°ç«¯æµ‹è¯•æ•°æ®é›†"""
    dataset_id: str
    scenario_type: str
    original_video_path: str
    viral_srt_path: str
    expected_segments_dir: str
    expected_draftinfo_path: str
    metadata: Dict[str, Any]
    creation_time: float


class E2EDataGenerator:
    """ç«¯åˆ°ç«¯æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨"""
    
    def __init__(self, config_path: str = None):
        """åˆå§‹åŒ–ç«¯åˆ°ç«¯æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨"""
        self.config = self._load_config(config_path)
        
        # è®¾ç½®æ—¥å¿—
        self.logger = LogHandler.get_logger(
            name=__name__,
            level=self.config.get('test_environment', {}).get('log_level', 'INFO')
        )
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.file_checker = FileChecker()
        
        # æ•°æ®ç”Ÿæˆé…ç½®
        self.data_config = self.config.get('data_generation', {})
        self.generation_seed = self.data_config.get('generation_seed', 42)
        random.seed(self.generation_seed)
        
        # æµ‹è¯•åœºæ™¯é…ç½®
        self.scenarios = self.config.get('test_data', {}).get('test_scenarios', {})
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir = Path(self.config.get('file_paths', {}).get('output', {}).get('reports_dir', 'tests/temp/e2e'))
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ç”Ÿæˆçš„æ•°æ®é›†å­˜å‚¨
        self.generated_datasets = []
    
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """åŠ è½½é…ç½®"""
        if config_path is None:
            config_path = "tests/end_to_end_validation/e2e_config.yaml"
        
        try:
            import yaml
            with open(config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except Exception as e:
            self.logger.warning(f"æ— æ³•åŠ è½½é…ç½®æ–‡ä»¶ {config_path}: {e}")
            return self._get_default_config()
    
    def _get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            'test_environment': {'log_level': 'INFO'},
            'data_generation': {'generation_seed': 42},
            'test_data': {
                'test_scenarios': {
                    'basic': {'segment_count': 8, 'continuous_segments': True},
                    'complex': {'segment_count': 15, 'continuous_segments': False},
                    'boundary': {'segment_count': 3, 'edge_cases': True},
                    'stress': {'segment_count': 50, 'rapid_cuts': True}
                }
            },
            'file_paths': {'output': {'reports_dir': 'tests/temp/e2e'}}
        }
    
    def generate_complete_dataset(self, scenario_type: str = "basic") -> E2ETestDataSet:
        """
        ç”Ÿæˆå®Œæ•´çš„æµ‹è¯•æ•°æ®é›†
        
        Args:
            scenario_type: æµ‹è¯•åœºæ™¯ç±»å‹
            
        Returns:
            E2ETestDataSet: ç”Ÿæˆçš„æµ‹è¯•æ•°æ®é›†
        """
        dataset_id = f"e2e_dataset_{scenario_type}_{int(time.time())}_{uuid.uuid4().hex[:8]}"
        
        self.logger.info(f"å¼€å§‹ç”Ÿæˆç«¯åˆ°ç«¯æµ‹è¯•æ•°æ®é›†: {dataset_id}")
        
        try:
            # åˆ›å»ºæ•°æ®é›†ç›®å½•
            dataset_dir = self.output_dir / dataset_id
            dataset_dir.mkdir(exist_ok=True)
            
            # ç”ŸæˆåŸç‰‡è§†é¢‘
            original_video_path = self._generate_original_video(dataset_dir, scenario_type)
            
            # ç”Ÿæˆçˆ†æ¬¾SRTå­—å¹•
            viral_srt_path = self._generate_viral_srt(dataset_dir, scenario_type, original_video_path)
            
            # ç”ŸæˆæœŸæœ›çš„è§†é¢‘ç‰‡æ®µ
            expected_segments_dir = self._generate_expected_segments(dataset_dir, viral_srt_path, original_video_path)
            
            # ç”ŸæˆæœŸæœ›çš„å‰ªæ˜ å·¥ç¨‹æ–‡ä»¶
            expected_draftinfo_path = self._generate_expected_draftinfo(dataset_dir, expected_segments_dir)
            
            # ç”Ÿæˆå…ƒæ•°æ®
            metadata = self._generate_metadata(scenario_type, dataset_dir)
            
            dataset = E2ETestDataSet(
                dataset_id=dataset_id,
                scenario_type=scenario_type,
                original_video_path=original_video_path,
                viral_srt_path=viral_srt_path,
                expected_segments_dir=expected_segments_dir,
                expected_draftinfo_path=expected_draftinfo_path,
                metadata=metadata,
                creation_time=time.time()
            )
            
            # ä¿å­˜æ•°æ®é›†ä¿¡æ¯
            self._save_dataset_info(dataset_dir, dataset)
            
            self.generated_datasets.append(dataset)
            self.logger.info(f"ç«¯åˆ°ç«¯æµ‹è¯•æ•°æ®é›†ç”Ÿæˆå®Œæˆ: {dataset_id}")
            
            return dataset
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆç«¯åˆ°ç«¯æµ‹è¯•æ•°æ®é›†å¤±è´¥: {str(e)}")
            raise
    
    def _generate_original_video(self, dataset_dir: Path, scenario_type: str) -> str:
        """ç”ŸæˆåŸç‰‡è§†é¢‘"""
        scenario_config = self.scenarios.get(scenario_type, {})
        
        # æ ¹æ®åœºæ™¯ç±»å‹ç¡®å®šè§†é¢‘å‚æ•°
        if scenario_type == "basic":
            duration = 60  # 1åˆ†é’Ÿ
            resolution = "1280x720"
        elif scenario_type == "complex":
            duration = 300  # 5åˆ†é’Ÿ
            resolution = "1920x1080"
        elif scenario_type == "boundary":
            duration = 30  # 30ç§’
            resolution = "640x480"
        elif scenario_type == "stress":
            duration = 600  # 10åˆ†é’Ÿ
            resolution = "1920x1080"
        else:
            duration = 120  # é»˜è®¤2åˆ†é’Ÿ
            resolution = "1280x720"
        
        video_path = dataset_dir / "original_video.mp4"
        
        # ç”Ÿæˆæ¨¡æ‹Ÿè§†é¢‘æ–‡ä»¶
        # åœ¨å®é™…ç¯å¢ƒä¸­ï¼Œè¿™é‡Œåº”è¯¥ç”ŸæˆçœŸå®çš„è§†é¢‘æ–‡ä»¶
        video_metadata = {
            "duration": duration,
            "resolution": resolution,
            "fps": 30,
            "codec": "h264",
            "audio_codec": "aac",
            "file_size": duration * 1024 * 1024,  # ä¼°ç®—æ–‡ä»¶å¤§å°
            "creation_method": "synthetic"
        }
        
        # åˆ›å»ºæ¨¡æ‹Ÿè§†é¢‘æ–‡ä»¶
        with open(video_path, 'wb') as f:
            # å†™å…¥ä¸€äº›æ¨¡æ‹Ÿæ•°æ®
            f.write(b"MOCK_VIDEO_DATA" * 1000)
        
        # ä¿å­˜è§†é¢‘å…ƒæ•°æ®
        metadata_path = dataset_dir / "original_video_metadata.json"
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(video_metadata, f, ensure_ascii=False, indent=2)
        
        self.logger.debug(f"ç”ŸæˆåŸç‰‡è§†é¢‘: {video_path}")
        return str(video_path)
    
    def _generate_viral_srt(self, dataset_dir: Path, scenario_type: str, video_path: str) -> str:
        """ç”Ÿæˆçˆ†æ¬¾SRTå­—å¹•"""
        scenario_config = self.scenarios.get(scenario_type, {})
        segment_count = scenario_config.get('segment_count', 8)
        continuous_segments = scenario_config.get('continuous_segments', True)
        
        # è·å–è§†é¢‘æ—¶é•¿ï¼ˆä»å…ƒæ•°æ®ä¸­è¯»å–ï¼‰
        metadata_path = dataset_dir / "original_video_metadata.json"
        with open(metadata_path, 'r', encoding='utf-8') as f:
            video_metadata = json.load(f)
        
        video_duration = video_metadata.get('duration', 120)
        
        # ç”Ÿæˆæ—¶é—´æ®µ
        segments = self._generate_time_segments(segment_count, video_duration, continuous_segments, scenario_type)
        
        # ç”ŸæˆSRTå†…å®¹
        srt_content = self._create_srt_content(segments, scenario_type)
        
        srt_path = dataset_dir / "viral_subtitles.srt"
        with open(srt_path, 'w', encoding='utf-8') as f:
            f.write(srt_content)
        
        self.logger.debug(f"ç”Ÿæˆçˆ†æ¬¾SRTå­—å¹•: {srt_path}, ç‰‡æ®µæ•°: {len(segments)}")
        return str(srt_path)
    
    def _generate_time_segments(self, segment_count: int, video_duration: float, 
                              continuous: bool, scenario_type: str) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ—¶é—´æ®µ"""
        segments = []
        
        if continuous:
            # è¿ç»­ç‰‡æ®µ
            segment_duration = video_duration / segment_count
            for i in range(segment_count):
                start_time = i * segment_duration
                end_time = (i + 1) * segment_duration
                
                segments.append({
                    'start_seconds': start_time,
                    'end_seconds': end_time,
                    'duration': segment_duration
                })
        else:
            # éè¿ç»­ç‰‡æ®µ
            available_time = video_duration
            used_time = 0
            
            for i in range(segment_count):
                # éšæœºé€‰æ‹©ç‰‡æ®µæ—¶é•¿
                if scenario_type == "boundary":
                    # è¾¹ç•Œåœºæ™¯ï¼šæçŸ­æˆ–æé•¿ç‰‡æ®µ
                    if i % 2 == 0:
                        duration = random.uniform(0.5, 2.0)  # æçŸ­ç‰‡æ®µ
                    else:
                        duration = random.uniform(30, 60)    # è¾ƒé•¿ç‰‡æ®µ
                else:
                    duration = random.uniform(5, 30)  # æ­£å¸¸ç‰‡æ®µ
                
                # éšæœºé€‰æ‹©å¼€å§‹æ—¶é—´
                max_start = video_duration - duration
                if max_start > used_time:
                    start_time = random.uniform(used_time, max_start)
                else:
                    start_time = used_time
                
                end_time = start_time + duration
                used_time = end_time + random.uniform(1, 10)  # æ·»åŠ é—´éš”
                
                if end_time <= video_duration:
                    segments.append({
                        'start_seconds': start_time,
                        'end_seconds': end_time,
                        'duration': duration
                    })
        
        return segments[:segment_count]  # ç¡®ä¿ä¸è¶…è¿‡æŒ‡å®šæ•°é‡
    
    def _create_srt_content(self, segments: List[Dict[str, Any]], scenario_type: str) -> str:
        """åˆ›å»ºSRTå†…å®¹"""
        srt_lines = []
        
        # æ ¹æ®åœºæ™¯ç±»å‹ç”Ÿæˆä¸åŒçš„å­—å¹•æ–‡æœ¬
        text_templates = self._get_text_templates(scenario_type)
        
        for i, segment in enumerate(segments):
            # åºå·
            srt_lines.append(str(i + 1))
            
            # æ—¶é—´ç 
            start_timecode = self._seconds_to_timecode(segment['start_seconds'])
            end_timecode = self._seconds_to_timecode(segment['end_seconds'])
            srt_lines.append(f"{start_timecode} --> {end_timecode}")
            
            # å­—å¹•æ–‡æœ¬
            text = random.choice(text_templates).format(index=i+1)
            srt_lines.append(text)
            
            # ç©ºè¡Œåˆ†éš”
            srt_lines.append("")
        
        return "\n".join(srt_lines)
    
    def _get_text_templates(self, scenario_type: str) -> List[str]:
        """è·å–å­—å¹•æ–‡æœ¬æ¨¡æ¿"""
        if scenario_type == "basic":
            return [
                "è¿™æ˜¯ç¬¬{index}ä¸ªåŸºç¡€æµ‹è¯•ç‰‡æ®µ",
                "åŸºç¡€åœºæ™¯ç‰‡æ®µ{index}ï¼šæ­£å¸¸å†…å®¹",
                "æµ‹è¯•ç‰‡æ®µ{index}ï¼šæ ‡å‡†æ ¼å¼"
            ]
        elif scenario_type == "complex":
            return [
                "å¤æ‚åœºæ™¯ç¬¬{index}æ®µï¼šåŒ…å«ç‰¹æ®Šå­—ç¬¦ï¼@#ï¿¥%",
                "ç‰‡æ®µ{index}ï¼šå¤šè¡Œ\nå­—å¹•å†…å®¹\næµ‹è¯•",
                "Complex segment {index}: Mixed language content",
                "ç¬¬{index}ä¸ªç‰‡æ®µï¼šemojiæµ‹è¯•ğŸ¬ğŸ­ğŸª"
            ]
        elif scenario_type == "boundary":
            return [
                "çŸ­{index}",
                "è¾¹ç•Œæµ‹è¯•ç‰‡æ®µ{index}ï¼šè¿™æ˜¯ä¸€ä¸ªéå¸¸é•¿çš„å­—å¹•æ–‡æœ¬ï¼Œç”¨äºæµ‹è¯•ç³»ç»Ÿå¯¹é•¿æ–‡æœ¬çš„å¤„ç†èƒ½åŠ›å’Œè¾¹ç•Œæ¡ä»¶",
                ""  # ç©ºå­—å¹•æµ‹è¯•
            ]
        elif scenario_type == "stress":
            return [
                "å‹åŠ›æµ‹è¯•ç‰‡æ®µ{index}",
                "é«˜é¢‘åˆ‡æ¢{index}",
                "å¿«é€Ÿå‰ªåˆ‡{index}"
            ]
        else:
            return ["æµ‹è¯•ç‰‡æ®µ{index}"]
    
    def _seconds_to_timecode(self, seconds: float) -> str:
        """å°†ç§’æ•°è½¬æ¢ä¸ºSRTæ—¶é—´ç æ ¼å¼"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        milliseconds = int((seconds % 1) * 1000)
        
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{milliseconds:03d}"
    
    def _generate_expected_segments(self, dataset_dir: Path, srt_path: str, video_path: str) -> str:
        """ç”ŸæˆæœŸæœ›çš„è§†é¢‘ç‰‡æ®µ"""
        segments_dir = dataset_dir / "expected_segments"
        segments_dir.mkdir(exist_ok=True)
        
        # è§£æSRTæ–‡ä»¶è·å–ç‰‡æ®µä¿¡æ¯
        with open(srt_path, 'r', encoding='utf-8') as f:
            srt_content = f.read()
        
        segments = self._parse_srt_segments(srt_content)
        
        # ä¸ºæ¯ä¸ªç‰‡æ®µåˆ›å»ºæ¨¡æ‹Ÿæ–‡ä»¶
        for i, segment in enumerate(segments):
            segment_filename = f"segment_{i+1:03d}.mp4"
            segment_path = segments_dir / segment_filename
            
            # åˆ›å»ºæ¨¡æ‹Ÿç‰‡æ®µæ–‡ä»¶
            with open(segment_path, 'wb') as f:
                # å†™å…¥æ¨¡æ‹Ÿæ•°æ®ï¼Œå¤§å°ä¸æ—¶é•¿æˆæ¯”ä¾‹
                duration = segment['end_seconds'] - segment['start_seconds']
                data_size = int(duration * 100 * 1024)  # æ¯ç§’100KB
                f.write(b"MOCK_SEGMENT_DATA" * (data_size // 17))
        
        self.logger.debug(f"ç”ŸæˆæœŸæœ›è§†é¢‘ç‰‡æ®µ: {segments_dir}, ç‰‡æ®µæ•°: {len(segments)}")
        return str(segments_dir)
    
    def _parse_srt_segments(self, srt_content: str) -> List[Dict[str, Any]]:
        """è§£æSRTå†…å®¹è·å–ç‰‡æ®µä¿¡æ¯"""
        segments = []
        blocks = srt_content.strip().split('\n\n')
        
        for block in blocks:
            lines = block.strip().split('\n')
            if len(lines) >= 3:
                # è§£ææ—¶é—´ç 
                timecode_line = lines[1]
                if '-->' in timecode_line:
                    start_str, end_str = timecode_line.split(' --> ')
                    start_seconds = self._timecode_to_seconds(start_str.strip())
                    end_seconds = self._timecode_to_seconds(end_str.strip())
                    
                    segments.append({
                        'start_seconds': start_seconds,
                        'end_seconds': end_seconds,
                        'text': '\n'.join(lines[2:])
                    })
        
        return segments
    
    def _timecode_to_seconds(self, timecode: str) -> float:
        """å°†æ—¶é—´ç è½¬æ¢ä¸ºç§’æ•°"""
        try:
            time_part, ms_part = timecode.split(',')
            hours, minutes, seconds = map(int, time_part.split(':'))
            milliseconds = int(ms_part)
            
            total_seconds = hours * 3600 + minutes * 60 + seconds + milliseconds / 1000.0
            return total_seconds
        except (ValueError, IndexError):
            return 0.0
    
    def _generate_expected_draftinfo(self, dataset_dir: Path, segments_dir: str) -> str:
        """ç”ŸæˆæœŸæœ›çš„å‰ªæ˜ å·¥ç¨‹æ–‡ä»¶"""
        segments_path = Path(segments_dir)
        segment_files = sorted(segments_path.glob("*.mp4"))
        
        # åˆ›å»ºå‰ªæ˜ å·¥ç¨‹æ–‡ä»¶ç»“æ„
        project_data = {
            "version": "3.0.0",
            "tracks": [
                {
                    "type": "video",
                    "segments": []
                }
            ],
            "materials": {},
            "canvas_config": {
                "width": 1920,
                "height": 1080,
                "fps": 30
            },
            "duration": 0
        }
        
        current_time = 0
        
        # ä¸ºæ¯ä¸ªç‰‡æ®µåˆ›å»ºè½¨é“æ¡ç›®å’Œç´ ææ¡ç›®
        for i, segment_file in enumerate(segment_files):
            material_id = f"material_{i+1}"
            
            # ä¼°ç®—ç‰‡æ®µæ—¶é•¿ï¼ˆåŸºäºæ–‡ä»¶å¤§å°ï¼‰
            file_size = segment_file.stat().st_size
            estimated_duration = max(1.0, file_size / (100 * 1024))  # å‡è®¾æ¯ç§’100KB
            
            # æ·»åŠ è½¨é“ç‰‡æ®µ
            project_data["tracks"][0]["segments"].append({
                "start": current_time,
                "end": current_time + estimated_duration,
                "material_id": material_id
            })
            
            # æ·»åŠ ç´ æ
            project_data["materials"][material_id] = {
                "type": "video",
                "path": str(segment_file.absolute()),
                "duration": estimated_duration
            }
            
            current_time += estimated_duration
        
        project_data["duration"] = current_time
        
        # ä¿å­˜å·¥ç¨‹æ–‡ä»¶
        draftinfo_path = dataset_dir / "expected_project.draftinfo"
        with open(draftinfo_path, 'w', encoding='utf-8') as f:
            json.dump(project_data, f, ensure_ascii=False, indent=2)
        
        self.logger.debug(f"ç”ŸæˆæœŸæœ›å‰ªæ˜ å·¥ç¨‹æ–‡ä»¶: {draftinfo_path}")
        return str(draftinfo_path)
    
    def _generate_metadata(self, scenario_type: str, dataset_dir: Path) -> Dict[str, Any]:
        """ç”Ÿæˆæ•°æ®é›†å…ƒæ•°æ®"""
        return {
            "scenario_type": scenario_type,
            "generation_time": time.time(),
            "generator_version": "1.0.0",
            "dataset_dir": str(dataset_dir),
            "scenario_config": self.scenarios.get(scenario_type, {}),
            "generation_seed": self.generation_seed,
            "files": {
                "original_video": "original_video.mp4",
                "viral_srt": "viral_subtitles.srt",
                "expected_segments_dir": "expected_segments",
                "expected_draftinfo": "expected_project.draftinfo"
            }
        }
    
    def _save_dataset_info(self, dataset_dir: Path, dataset: E2ETestDataSet):
        """ä¿å­˜æ•°æ®é›†ä¿¡æ¯"""
        dataset_info = {
            "dataset_id": dataset.dataset_id,
            "scenario_type": dataset.scenario_type,
            "creation_time": dataset.creation_time,
            "files": {
                "original_video_path": dataset.original_video_path,
                "viral_srt_path": dataset.viral_srt_path,
                "expected_segments_dir": dataset.expected_segments_dir,
                "expected_draftinfo_path": dataset.expected_draftinfo_path
            },
            "metadata": dataset.metadata
        }
        
        info_path = dataset_dir / "dataset_info.json"
        with open(info_path, 'w', encoding='utf-8') as f:
            json.dump(dataset_info, f, ensure_ascii=False, indent=2)
    
    def generate_all_scenarios(self) -> List[E2ETestDataSet]:
        """ç”Ÿæˆæ‰€æœ‰æµ‹è¯•åœºæ™¯çš„æ•°æ®é›†"""
        datasets = []
        
        for scenario_type in self.scenarios.keys():
            try:
                dataset = self.generate_complete_dataset(scenario_type)
                datasets.append(dataset)
            except Exception as e:
                self.logger.error(f"ç”Ÿæˆåœºæ™¯ {scenario_type} çš„æ•°æ®é›†å¤±è´¥: {str(e)}")
        
        self.logger.info(f"ç”Ÿæˆäº† {len(datasets)} ä¸ªæµ‹è¯•æ•°æ®é›†")
        return datasets


if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    generator = E2EDataGenerator()
    
    # ç”Ÿæˆå•ä¸ªåœºæ™¯çš„æ•°æ®é›†
    basic_dataset = generator.generate_complete_dataset("basic")
    print(f"ç”ŸæˆåŸºç¡€åœºæ™¯æ•°æ®é›†: {basic_dataset.dataset_id}")
    
    # ç”Ÿæˆæ‰€æœ‰åœºæ™¯çš„æ•°æ®é›†
    all_datasets = generator.generate_all_scenarios()
    print(f"ç”Ÿæˆäº† {len(all_datasets)} ä¸ªæ•°æ®é›†")
