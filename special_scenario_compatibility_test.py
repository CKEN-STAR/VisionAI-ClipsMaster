#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
VisionAI-ClipsMaster ç‰¹æ®Šåœºæ™¯å…¼å®¹æ€§æµ‹è¯•
æµ‹è¯•ç³»ç»Ÿåœ¨å„ç§è¾¹ç•Œæ¡ä»¶ã€å¼‚å¸¸è¾“å…¥å’Œæžé™æƒ…å†µä¸‹çš„è¡¨çŽ°
"""

import sys
import os
import json
import time
import tempfile
import traceback
import threading
import gc
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "src"))

class SpecialScenarioCompatibilityTester:
    def __init__(self):
        self.results = {
            "test_time": datetime.now().isoformat(),
            "total_tests": 0,
            "successful_tests": 0,
            "failed_tests": 0,
            "test_results": {},
            "performance_metrics": {},
            "errors": []
        }
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºŽæµ‹è¯•
        self.temp_dir = Path(tempfile.mkdtemp(prefix="special_scenario_test_"))

    def test_empty_input_handling(self):
        """æµ‹è¯•ç©ºè¾“å…¥å¤„ç†"""
        print("æµ‹è¯•ç©ºè¾“å…¥å¤„ç†...")
        
        try:
            from src.core.srt_parser import SRTParser
            from src.core.narrative_analyzer import NarrativeAnalyzer
            
            test_result = {
                "status": "success",
                "empty_input_tests": {},
                "handling_time": 0.0
            }
            
            start_time = time.time()
            
            # æµ‹è¯•ç©ºSRTæ–‡ä»¶
            empty_srt_file = self.temp_dir / "empty.srt"
            empty_srt_file.write_text("", encoding='utf-8')
            
            parser = SRTParser()
            empty_result = parser.parse(str(empty_srt_file))
            test_result["empty_input_tests"]["empty_srt"] = {
                "result": empty_result,
                "handled_gracefully": isinstance(empty_result, list)
            }
            
            # æµ‹è¯•ç©ºæ–‡æœ¬åˆ†æž
            analyzer = NarrativeAnalyzer()
            empty_analysis = analyzer.analyze_narrative_structure("")
            test_result["empty_input_tests"]["empty_text"] = {
                "result": empty_analysis,
                "handled_gracefully": isinstance(empty_analysis, dict)
            }
            
            # æµ‹è¯•Noneè¾“å…¥
            try:
                none_analysis = analyzer.analyze_narrative_structure(None)
                test_result["empty_input_tests"]["none_input"] = {
                    "result": none_analysis,
                    "handled_gracefully": True
                }
            except Exception as e:
                test_result["empty_input_tests"]["none_input"] = {
                    "error": str(e),
                    "handled_gracefully": False
                }
            
            handling_time = time.time() - start_time
            test_result["handling_time"] = handling_time
            
            print(f"  ç©ºè¾“å…¥å¤„ç†è€—æ—¶: {handling_time:.3f}ç§’")
            print("  âœ“ ç©ºè¾“å…¥å¤„ç†æµ‹è¯•é€šè¿‡")
            return test_result
            
        except Exception as e:
            print(f"  âœ— ç©ºè¾“å…¥å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
            return {
                "status": "failed",
                "error": str(e),
                "traceback": traceback.format_exc()
            }

    def test_large_input_handling(self):
        """æµ‹è¯•å¤§è¾“å…¥å¤„ç†"""
        print("æµ‹è¯•å¤§è¾“å…¥å¤„ç†...")
        
        try:
            from src.core.narrative_analyzer import NarrativeAnalyzer
            
            test_result = {
                "status": "success",
                "large_input_tests": {},
                "processing_time": 0.0
            }
            
            start_time = time.time()
            
            # ç”Ÿæˆå¤§æ–‡æœ¬
            large_text = "è¿™æ˜¯ä¸€ä¸ªå¾ˆé•¿çš„æ•…äº‹ã€‚" * 1000  # çº¦10KBæ–‡æœ¬
            very_large_text = "è¿™æ˜¯ä¸€ä¸ªè¶…é•¿çš„æ•…äº‹ã€‚" * 10000  # çº¦100KBæ–‡æœ¬
            
            analyzer = NarrativeAnalyzer()
            
            # æµ‹è¯•å¤§æ–‡æœ¬å¤„ç†
            large_result = analyzer.analyze_narrative_structure(large_text)
            test_result["large_input_tests"]["large_text"] = {
                "text_length": len(large_text),
                "result_type": type(large_result).__name__,
                "handled_gracefully": isinstance(large_result, dict)
            }
            
            # æµ‹è¯•è¶…å¤§æ–‡æœ¬å¤„ç†
            very_large_result = analyzer.analyze_narrative_structure(very_large_text)
            test_result["large_input_tests"]["very_large_text"] = {
                "text_length": len(very_large_text),
                "result_type": type(very_large_result).__name__,
                "handled_gracefully": isinstance(very_large_result, dict)
            }
            
            processing_time = time.time() - start_time
            test_result["processing_time"] = processing_time
            
            print(f"  å¤§è¾“å…¥å¤„ç†è€—æ—¶: {processing_time:.3f}ç§’")
            print(f"  å¤§æ–‡æœ¬é•¿åº¦: {len(large_text):,} å­—ç¬¦")
            print(f"  è¶…å¤§æ–‡æœ¬é•¿åº¦: {len(very_large_text):,} å­—ç¬¦")
            print("  âœ“ å¤§è¾“å…¥å¤„ç†æµ‹è¯•é€šè¿‡")
            return test_result
            
        except Exception as e:
            print(f"  âœ— å¤§è¾“å…¥å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
            return {
                "status": "failed",
                "error": str(e),
                "traceback": traceback.format_exc()
            }

    def test_malformed_input_handling(self):
        """æµ‹è¯•ç•¸å½¢è¾“å…¥å¤„ç†"""
        print("æµ‹è¯•ç•¸å½¢è¾“å…¥å¤„ç†...")
        
        try:
            from src.core.srt_parser import SRTParser
            
            test_result = {
                "status": "success",
                "malformed_input_tests": {},
                "handling_time": 0.0
            }
            
            start_time = time.time()
            
            # åˆ›å»ºç•¸å½¢SRTæ–‡ä»¶
            malformed_srt_content = """1
            00:00:01,000 --> 00:00:03,000
            è¿™æ˜¯æ­£å¸¸å­—å¹•
            
            INVALID_ENTRY
            è¿™æ˜¯æ— æ•ˆçš„æ—¶é—´ç 
            
            3
            25:99:99,999 --> 26:99:99,999
            è¿™æ˜¯æ— æ•ˆçš„æ—¶é—´æ ¼å¼
            """
            
            malformed_srt_file = self.temp_dir / "malformed.srt"
            malformed_srt_file.write_text(malformed_srt_content, encoding='utf-8')
            
            parser = SRTParser()
            malformed_result = parser.parse(str(malformed_srt_file))
            
            test_result["malformed_input_tests"]["malformed_srt"] = {
                "result_type": type(malformed_result).__name__,
                "result_length": len(malformed_result) if isinstance(malformed_result, list) else 0,
                "handled_gracefully": isinstance(malformed_result, list)
            }
            
            # æµ‹è¯•ç‰¹æ®Šå­—ç¬¦è¾“å…¥
            special_chars_text = "ðŸŽ¬ðŸ“ºðŸŽ­ðŸŽªðŸŽ¨ðŸŽ¯ðŸŽ²ðŸŽ¸ðŸŽºðŸŽ»ðŸŽ¼ðŸŽµðŸŽ¶ðŸŽ¤ðŸŽ§ðŸŽ®"
            from src.core.narrative_analyzer import NarrativeAnalyzer
            analyzer = NarrativeAnalyzer()
            special_result = analyzer.analyze_narrative_structure(special_chars_text)
            
            test_result["malformed_input_tests"]["special_chars"] = {
                "input_text": special_chars_text,
                "result_type": type(special_result).__name__,
                "handled_gracefully": isinstance(special_result, dict)
            }
            
            handling_time = time.time() - start_time
            test_result["handling_time"] = handling_time
            
            print(f"  ç•¸å½¢è¾“å…¥å¤„ç†è€—æ—¶: {handling_time:.3f}ç§’")
            print("  âœ“ ç•¸å½¢è¾“å…¥å¤„ç†æµ‹è¯•é€šè¿‡")
            return test_result
            
        except Exception as e:
            print(f"  âœ— ç•¸å½¢è¾“å…¥å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
            return {
                "status": "failed",
                "error": str(e),
                "traceback": traceback.format_exc()
            }

    def test_memory_pressure_handling(self):
        """æµ‹è¯•å†…å­˜åŽ‹åŠ›å¤„ç†"""
        print("æµ‹è¯•å†…å­˜åŽ‹åŠ›å¤„ç†...")
        
        try:
            from src.utils.memory_guard import MemoryGuard
            
            test_result = {
                "status": "success",
                "memory_tests": {},
                "memory_usage": {}
            }
            
            start_time = time.time()
            
            # èŽ·å–åˆå§‹å†…å­˜çŠ¶æ€
            memory_guard = MemoryGuard()
            initial_memory = memory_guard.get_memory_info()
            test_result["memory_usage"]["initial"] = initial_memory
            
            # æ¨¡æ‹Ÿå†…å­˜åŽ‹åŠ›
            large_data = []
            try:
                for i in range(100):  # åˆ›å»ºä¸€äº›å¤§å¯¹è±¡
                    large_data.append("x" * 10000)  # æ¯ä¸ª10KB
                
                # æ£€æŸ¥å†…å­˜çŠ¶æ€
                pressure_memory = memory_guard.get_memory_info()
                test_result["memory_usage"]["under_pressure"] = pressure_memory
                
                # æµ‹è¯•å†…å­˜ä¼˜åŒ–
                optimization_result = memory_guard.optimize_memory_usage()
                test_result["memory_tests"]["optimization"] = optimization_result
                
                # æ¸…ç†å¤§å¯¹è±¡
                large_data.clear()
                gc.collect()
                
                # æ£€æŸ¥æ¸…ç†åŽå†…å­˜çŠ¶æ€
                final_memory = memory_guard.get_memory_info()
                test_result["memory_usage"]["after_cleanup"] = final_memory
                
            except MemoryError:
                test_result["memory_tests"]["memory_error_handled"] = True
            
            # æµ‹è¯•å†…å­˜å®‰å…¨æ£€æŸ¥
            safety_check = memory_guard.check_memory_safety()
            test_result["memory_tests"]["safety_check"] = safety_check
            
            handling_time = time.time() - start_time
            test_result["handling_time"] = handling_time
            
            print(f"  å†…å­˜åŽ‹åŠ›æµ‹è¯•è€—æ—¶: {handling_time:.3f}ç§’")
            print(f"  å†…å­˜å®‰å…¨çŠ¶æ€: {safety_check}")
            print("  âœ“ å†…å­˜åŽ‹åŠ›å¤„ç†æµ‹è¯•é€šè¿‡")
            return test_result
            
        except Exception as e:
            print(f"  âœ— å†…å­˜åŽ‹åŠ›å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
            return {
                "status": "failed",
                "error": str(e),
                "traceback": traceback.format_exc()
            }

    def test_concurrent_access_handling(self):
        """æµ‹è¯•å¹¶å‘è®¿é—®å¤„ç†"""
        print("æµ‹è¯•å¹¶å‘è®¿é—®å¤„ç†...")
        
        try:
            from src.core.narrative_analyzer import NarrativeAnalyzer
            
            test_result = {
                "status": "success",
                "concurrent_tests": {},
                "thread_results": []
            }
            
            start_time = time.time()
            
            # åˆ›å»ºå¤šä¸ªçº¿ç¨‹åŒæ—¶è®¿é—®åˆ†æžå™¨
            analyzer = NarrativeAnalyzer()
            threads = []
            thread_results = []
            
            def analyze_text(thread_id, text):
                try:
                    result = analyzer.analyze_narrative_structure(f"çº¿ç¨‹{thread_id}: {text}")
                    thread_results.append({
                        "thread_id": thread_id,
                        "success": True,
                        "result_type": type(result).__name__
                    })
                except Exception as e:
                    thread_results.append({
                        "thread_id": thread_id,
                        "success": False,
                        "error": str(e)
                    })
            
            # å¯åŠ¨å¤šä¸ªçº¿ç¨‹
            for i in range(5):
                thread = threading.Thread(
                    target=analyze_text,
                    args=(i, f"è¿™æ˜¯çº¿ç¨‹{i}çš„æµ‹è¯•æ–‡æœ¬ï¼Œç”¨äºŽæµ‹è¯•å¹¶å‘è®¿é—®ã€‚")
                )
                threads.append(thread)
                thread.start()
            
            # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
            for thread in threads:
                thread.join(timeout=10)  # 10ç§’è¶…æ—¶
            
            test_result["thread_results"] = thread_results
            test_result["concurrent_tests"]["total_threads"] = len(threads)
            test_result["concurrent_tests"]["successful_threads"] = sum(
                1 for r in thread_results if r.get("success", False)
            )
            
            handling_time = time.time() - start_time
            test_result["handling_time"] = handling_time
            
            success_rate = test_result["concurrent_tests"]["successful_threads"] / len(threads) * 100
            print(f"  å¹¶å‘è®¿é—®æµ‹è¯•è€—æ—¶: {handling_time:.3f}ç§’")
            print(f"  æˆåŠŸçº¿ç¨‹: {test_result['concurrent_tests']['successful_threads']}/{len(threads)}")
            print(f"  æˆåŠŸçŽ‡: {success_rate:.1f}%")
            print("  âœ“ å¹¶å‘è®¿é—®å¤„ç†æµ‹è¯•é€šè¿‡")
            return test_result
            
        except Exception as e:
            print(f"  âœ— å¹¶å‘è®¿é—®å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
            return {
                "status": "failed",
                "error": str(e),
                "traceback": traceback.format_exc()
            }

    def test_long_running_stability(self):
        """æµ‹è¯•é•¿æ—¶é—´è¿è¡Œç¨³å®šæ€§"""
        print("æµ‹è¯•é•¿æ—¶é—´è¿è¡Œç¨³å®šæ€§...")
        
        try:
            from src.core.narrative_analyzer import NarrativeAnalyzer
            
            test_result = {
                "status": "success",
                "stability_tests": {},
                "iterations_completed": 0
            }
            
            start_time = time.time()
            
            analyzer = NarrativeAnalyzer()
            iterations = 50  # å‡å°‘è¿­ä»£æ¬¡æ•°ä»¥åŠ å¿«æµ‹è¯•
            successful_iterations = 0
            
            for i in range(iterations):
                try:
                    # æ¨¡æ‹Ÿé•¿æ—¶é—´è¿è¡Œçš„æ“ä½œ
                    test_text = f"è¿™æ˜¯ç¬¬{i+1}æ¬¡è¿­ä»£çš„æµ‹è¯•æ–‡æœ¬ï¼Œç”¨äºŽéªŒè¯ç³»ç»Ÿçš„é•¿æœŸç¨³å®šæ€§ã€‚"
                    result = analyzer.analyze_narrative_structure(test_text)
                    
                    if isinstance(result, dict):
                        successful_iterations += 1
                    
                    # æ¯10æ¬¡è¿­ä»£æ£€æŸ¥ä¸€æ¬¡å†…å­˜
                    if (i + 1) % 10 == 0:
                        gc.collect()  # å¼ºåˆ¶åžƒåœ¾å›žæ”¶
                        
                except Exception as e:
                    print(f"    è¿­ä»£ {i+1} å¤±è´¥: {e}")
            
            test_result["iterations_completed"] = successful_iterations
            test_result["stability_tests"]["success_rate"] = successful_iterations / iterations * 100
            test_result["stability_tests"]["total_iterations"] = iterations
            
            handling_time = time.time() - start_time
            test_result["handling_time"] = handling_time
            
            print(f"  é•¿æ—¶é—´è¿è¡Œæµ‹è¯•è€—æ—¶: {handling_time:.3f}ç§’")
            print(f"  å®Œæˆè¿­ä»£: {successful_iterations}/{iterations}")
            print(f"  æˆåŠŸçŽ‡: {test_result['stability_tests']['success_rate']:.1f}%")
            print("  âœ“ é•¿æ—¶é—´è¿è¡Œç¨³å®šæ€§æµ‹è¯•é€šè¿‡")
            return test_result
            
        except Exception as e:
            print(f"  âœ— é•¿æ—¶é—´è¿è¡Œç¨³å®šæ€§æµ‹è¯•å¤±è´¥: {e}")
            return {
                "status": "failed",
                "error": str(e),
                "traceback": traceback.format_exc()
            }

    def run_comprehensive_test(self):
        """è¿è¡Œå…¨é¢çš„ç‰¹æ®Šåœºæ™¯å…¼å®¹æ€§æµ‹è¯•"""
        print("=" * 60)
        print("VisionAI-ClipsMaster ç‰¹æ®Šåœºæ™¯å…¼å®¹æ€§æµ‹è¯•")
        print("=" * 60)
        
        tests = [
            ("ç©ºè¾“å…¥å¤„ç†", self.test_empty_input_handling),
            ("å¤§è¾“å…¥å¤„ç†", self.test_large_input_handling),
            ("ç•¸å½¢è¾“å…¥å¤„ç†", self.test_malformed_input_handling),
            ("å†…å­˜åŽ‹åŠ›å¤„ç†", self.test_memory_pressure_handling),
            ("å¹¶å‘è®¿é—®å¤„ç†", self.test_concurrent_access_handling),
            ("é•¿æ—¶é—´è¿è¡Œç¨³å®šæ€§", self.test_long_running_stability)
        ]
        
        self.results["total_tests"] = len(tests)
        
        for test_name, test_func in tests:
            print(f"\næµ‹è¯•: {test_name}")
            try:
                result = test_func()
                self.results["test_results"][test_name] = result
                
                if result.get("status") == "success":
                    self.results["successful_tests"] += 1
                    print(f"  âœ“ {test_name} æµ‹è¯•é€šè¿‡")
                else:
                    self.results["failed_tests"] += 1
                    print(f"  âœ— {test_name} æµ‹è¯•å¤±è´¥")
                    
            except Exception as e:
                self.results["failed_tests"] += 1
                error_msg = f"æµ‹è¯•å¼‚å¸¸: {e}"
                self.results["test_results"][test_name] = {
                    "status": "error",
                    "error": error_msg
                }
                self.results["errors"].append(f"{test_name}: {error_msg}")
                print(f"  âœ— {error_msg}")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        self.cleanup()
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_report()
        
        return self.results

    def cleanup(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            import shutil
            if self.temp_dir.exists():
                shutil.rmtree(self.temp_dir)
                print(f"\nä¸´æ—¶ç›®å½•å·²æ¸…ç†: {self.temp_dir}")
        except Exception as e:
            print(f"\næ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")

    def generate_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("ç‰¹æ®Šåœºæ™¯å…¼å®¹æ€§æµ‹è¯•ç»“æžœæ±‡æ€»")
        print("=" * 60)
        
        print(f"æ€»æµ‹è¯•æ•°: {self.results['total_tests']}")
        print(f"é€šè¿‡æµ‹è¯•: {self.results['successful_tests']}")
        print(f"å¤±è´¥æµ‹è¯•: {self.results['failed_tests']}")
        print(f"æˆåŠŸçŽ‡: {(self.results['successful_tests']/self.results['total_tests']*100):.1f}%")
        
        if self.results["failed_tests"] > 0:
            print(f"\nå¤±è´¥çš„æµ‹è¯•:")
            for test_name, result in self.results["test_results"].items():
                if result.get("status") != "success":
                    print(f"  - {test_name}: {result.get('error', 'Unknown error')}")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report_file = f"special_scenario_compatibility_test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        
        print(f"\nè¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

if __name__ == "__main__":
    tester = SpecialScenarioCompatibilityTester()
    results = tester.run_comprehensive_test()
    
    # è¿”å›žé€€å‡ºç 
    if results["failed_tests"] > 0:
        sys.exit(1)
    else:
        sys.exit(0)
