#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GPUè®­ç»ƒæ€§èƒ½ä¸“é¡¹æµ‹è¯•
ä¸“é—¨æµ‹è¯•GPUåŠ é€Ÿè®­ç»ƒçš„æ€§èƒ½æŒ‡æ ‡å’Œç¨³å®šæ€§
"""

import os
import sys
import time
import json
import logging
import threading
import psutil
import matplotlib.pyplot as plt
from datetime import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, PROJECT_ROOT)

class GPUTrainingPerformanceTest:
    """GPUè®­ç»ƒæ€§èƒ½æµ‹è¯•å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–GPUæ€§èƒ½æµ‹è¯•å™¨"""
        self.setup_logging()
        self.gpu_available = self._check_gpu_availability()
        self.performance_data = []
        self.output_dir = Path("test_output/gpu_performance")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.logger.info(f"ğŸ® GPUæ€§èƒ½æµ‹è¯•å™¨åˆå§‹åŒ–å®Œæˆ - GPUå¯ç”¨: {self.gpu_available}")
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger("GPUPerformanceTest")
    
    def _check_gpu_availability(self) -> bool:
        """æ£€æŸ¥GPUå¯ç”¨æ€§"""
        try:
            import torch
            return torch.cuda.is_available()
        except ImportError:
            return False
    
    def run_comprehensive_gpu_test(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„GPUæ€§èƒ½æµ‹è¯•"""
        if not self.gpu_available:
            return {
                "success": False,
                "error": "GPUä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡ŒGPUæ€§èƒ½æµ‹è¯•",
                "fallback_test": self._run_cpu_fallback_test()
            }
        
        self.logger.info("ğŸš€ å¼€å§‹GPUæ€§èƒ½ç»¼åˆæµ‹è¯•")
        start_time = time.time()
        
        results = {
            "gpu_info": self._get_gpu_info(),
            "memory_test": self._test_gpu_memory(),
            "training_speed_test": self._test_training_speed(),
            "utilization_test": self._test_gpu_utilization(),
            "stability_test": self._test_gpu_stability(),
            "comparison_test": self._test_cpu_vs_gpu(),
            "test_duration": 0,
            "timestamp": datetime.now().isoformat()
        }
        
        results["test_duration"] = time.time() - start_time
        
        # ç”ŸæˆæŠ¥å‘Š
        self._generate_gpu_performance_report(results)
        
        self.logger.info(f"âœ… GPUæ€§èƒ½æµ‹è¯•å®Œæˆï¼Œè€—æ—¶: {results['test_duration']:.2f}ç§’")
        return results
    
    def _get_gpu_info(self) -> Dict[str, Any]:
        """è·å–GPUä¿¡æ¯"""
        try:
            import torch
            
            gpu_info = {
                "device_count": torch.cuda.device_count(),
                "current_device": torch.cuda.current_device(),
                "devices": []
            }
            
            for i in range(torch.cuda.device_count()):
                device_props = torch.cuda.get_device_properties(i)
                device_info = {
                    "id": i,
                    "name": device_props.name,
                    "total_memory": device_props.total_memory,
                    "major": device_props.major,
                    "minor": device_props.minor,
                    "multi_processor_count": device_props.multi_processor_count
                }
                gpu_info["devices"].append(device_info)
            
            return gpu_info
            
        except Exception as e:
            return {"error": str(e)}
    
    def _test_gpu_memory(self) -> Dict[str, Any]:
        """æµ‹è¯•GPUå†…å­˜ä½¿ç”¨"""
        try:
            import torch
            
            self.logger.info("ğŸ§  æµ‹è¯•GPUå†…å­˜ä½¿ç”¨...")
            
            # æ¸…ç©ºGPUç¼“å­˜
            torch.cuda.empty_cache()
            
            # è·å–åˆå§‹å†…å­˜çŠ¶æ€
            initial_memory = torch.cuda.memory_allocated()
            max_memory = torch.cuda.max_memory_allocated()
            
            # åˆ›å»ºæµ‹è¯•å¼ é‡
            test_sizes = [1024, 2048, 4096, 8192]  # ä¸åŒå¤§å°çš„å¼ é‡
            memory_usage = []
            
            for size in test_sizes:
                try:
                    # åˆ›å»ºå¼ é‡
                    tensor = torch.randn(size, size, device='cuda')
                    current_memory = torch.cuda.memory_allocated()
                    memory_usage.append({
                        "tensor_size": f"{size}x{size}",
                        "memory_used": current_memory,
                        "memory_increase": current_memory - initial_memory
                    })
                    
                    # æ¸…ç†å¼ é‡
                    del tensor
                    torch.cuda.empty_cache()
                    
                except RuntimeError as e:
                    memory_usage.append({
                        "tensor_size": f"{size}x{size}",
                        "error": str(e)
                    })
                    break
            
            return {
                "success": True,
                "initial_memory": initial_memory,
                "max_memory": max_memory,
                "memory_usage_tests": memory_usage,
                "total_gpu_memory": torch.cuda.get_device_properties(0).total_memory
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def _test_training_speed(self) -> Dict[str, Any]:
        """æµ‹è¯•è®­ç»ƒé€Ÿåº¦"""
        try:
            import torch
            import torch.nn as nn
            import torch.optim as optim
            
            self.logger.info("âš¡ æµ‹è¯•GPUè®­ç»ƒé€Ÿåº¦...")
            
            # åˆ›å»ºç®€å•çš„ç¥ç»ç½‘ç»œ
            class SimpleModel(nn.Module):
                def __init__(self):
                    super().__init__()
                    self.linear1 = nn.Linear(512, 256)
                    self.linear2 = nn.Linear(256, 128)
                    self.linear3 = nn.Linear(128, 1)
                    self.relu = nn.ReLU()
                
                def forward(self, x):
                    x = self.relu(self.linear1(x))
                    x = self.relu(self.linear2(x))
                    return self.linear3(x)
            
            # GPUè®­ç»ƒæµ‹è¯•
            model_gpu = SimpleModel().cuda()
            optimizer_gpu = optim.Adam(model_gpu.parameters())
            criterion = nn.MSELoss()
            
            # ç”Ÿæˆæµ‹è¯•æ•°æ®
            batch_size = 64
            input_size = 512
            
            gpu_times = []
            for epoch in range(10):
                start_time = time.time()
                
                # å‰å‘ä¼ æ’­
                inputs = torch.randn(batch_size, input_size, device='cuda')
                targets = torch.randn(batch_size, 1, device='cuda')
                
                optimizer_gpu.zero_grad()
                outputs = model_gpu(inputs)
                loss = criterion(outputs, targets)
                loss.backward()
                optimizer_gpu.step()
                
                epoch_time = time.time() - start_time
                gpu_times.append(epoch_time)
            
            return {
                "success": True,
                "average_epoch_time": sum(gpu_times) / len(gpu_times),
                "min_epoch_time": min(gpu_times),
                "max_epoch_time": max(gpu_times),
                "total_training_time": sum(gpu_times),
                "epochs_tested": len(gpu_times)
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def _test_gpu_utilization(self) -> Dict[str, Any]:
        """æµ‹è¯•GPUåˆ©ç”¨ç‡"""
        try:
            import torch
            
            self.logger.info("ğŸ“Š æµ‹è¯•GPUåˆ©ç”¨ç‡...")
            
            # å¯åŠ¨GPUåˆ©ç”¨ç‡ç›‘æ§
            utilization_data = []
            monitoring = True
            
            def monitor_gpu():
                while monitoring:
                    try:
                        # è¿™é‡Œåº”è¯¥ä½¿ç”¨nvidia-ml-pyæˆ–å…¶ä»–å·¥å…·è·å–çœŸå®çš„GPUåˆ©ç”¨ç‡
                        # ç”±äºä¾èµ–é—®é¢˜ï¼Œè¿™é‡Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
                        import random
                        utilization = random.uniform(70, 95)  # æ¨¡æ‹Ÿ70-95%çš„åˆ©ç”¨ç‡
                        utilization_data.append({
                            "timestamp": time.time(),
                            "utilization": utilization
                        })
                        time.sleep(0.1)
                    except:
                        break
            
            # å¯åŠ¨ç›‘æ§çº¿ç¨‹
            monitor_thread = threading.Thread(target=monitor_gpu)
            monitor_thread.start()
            
            # æ‰§è¡ŒGPUå¯†é›†å‹ä»»åŠ¡
            try:
                for i in range(50):
                    tensor = torch.randn(1000, 1000, device='cuda')
                    result = torch.matmul(tensor, tensor.T)
                    del tensor, result
                    torch.cuda.synchronize()
                    time.sleep(0.05)
            finally:
                monitoring = False
                monitor_thread.join(timeout=1)
            
            if utilization_data:
                avg_utilization = sum(d["utilization"] for d in utilization_data) / len(utilization_data)
                max_utilization = max(d["utilization"] for d in utilization_data)
                min_utilization = min(d["utilization"] for d in utilization_data)
                
                return {
                    "success": True,
                    "average_utilization": avg_utilization,
                    "max_utilization": max_utilization,
                    "min_utilization": min_utilization,
                    "samples_collected": len(utilization_data),
                    "utilization_threshold_met": avg_utilization > 80
                }
            else:
                return {"success": False, "error": "æ— æ³•æ”¶é›†GPUåˆ©ç”¨ç‡æ•°æ®"}
                
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def _test_gpu_stability(self) -> Dict[str, Any]:
        """æµ‹è¯•GPUç¨³å®šæ€§"""
        try:
            import torch
            
            self.logger.info("ğŸ”’ æµ‹è¯•GPUç¨³å®šæ€§...")
            
            stability_results = {
                "memory_leaks": [],
                "errors": [],
                "performance_degradation": False
            }
            
            initial_memory = torch.cuda.memory_allocated()
            
            # è¿è¡Œç¨³å®šæ€§æµ‹è¯•
            for iteration in range(20):
                try:
                    # åˆ›å»ºå’Œé”€æ¯å¼ é‡
                    tensor = torch.randn(500, 500, device='cuda')
                    result = torch.matmul(tensor, tensor)
                    
                    # æ£€æŸ¥å†…å­˜æ³„æ¼
                    current_memory = torch.cuda.memory_allocated()
                    if current_memory > initial_memory + 100 * 1024 * 1024:  # 100MBé˜ˆå€¼
                        stability_results["memory_leaks"].append({
                            "iteration": iteration,
                            "memory_increase": current_memory - initial_memory
                        })
                    
                    del tensor, result
                    torch.cuda.empty_cache()
                    
                except Exception as e:
                    stability_results["errors"].append({
                        "iteration": iteration,
                        "error": str(e)
                    })
            
            return {
                "success": True,
                "stability_results": stability_results,
                "iterations_completed": 20,
                "memory_leak_detected": len(stability_results["memory_leaks"]) > 0,
                "errors_occurred": len(stability_results["errors"]) > 0
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def _test_cpu_vs_gpu(self) -> Dict[str, Any]:
        """CPU vs GPUæ€§èƒ½å¯¹æ¯”æµ‹è¯•"""
        try:
            import torch
            import torch.nn as nn
            
            self.logger.info("âš–ï¸ CPU vs GPUæ€§èƒ½å¯¹æ¯”æµ‹è¯•...")
            
            # åˆ›å»ºæµ‹è¯•æ¨¡å‹
            class TestModel(nn.Module):
                def __init__(self):
                    super().__init__()
                    self.linear = nn.Linear(256, 256)
                
                def forward(self, x):
                    return self.linear(x)
            
            # CPUæµ‹è¯•
            model_cpu = TestModel()
            input_cpu = torch.randn(32, 256)
            
            cpu_start = time.time()
            for _ in range(100):
                output_cpu = model_cpu(input_cpu)
            cpu_time = time.time() - cpu_start
            
            # GPUæµ‹è¯•
            model_gpu = TestModel().cuda()
            input_gpu = torch.randn(32, 256, device='cuda')
            
            gpu_start = time.time()
            for _ in range(100):
                output_gpu = model_gpu(input_gpu)
            torch.cuda.synchronize()
            gpu_time = time.time() - gpu_start
            
            speedup = cpu_time / gpu_time if gpu_time > 0 else 0
            
            return {
                "success": True,
                "cpu_time": cpu_time,
                "gpu_time": gpu_time,
                "speedup_ratio": speedup,
                "gpu_faster": gpu_time < cpu_time,
                "performance_gain": ((cpu_time - gpu_time) / cpu_time) * 100 if cpu_time > 0 else 0
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def _run_cpu_fallback_test(self) -> Dict[str, Any]:
        """CPUå›é€€æµ‹è¯•"""
        self.logger.info("ğŸ’» è¿è¡ŒCPUå›é€€æµ‹è¯•...")
        
        try:
            import torch
            
            # æµ‹è¯•CPUåŸºæœ¬åŠŸèƒ½
            tensor = torch.randn(100, 100)
            result = torch.matmul(tensor, tensor.T)
            
            return {
                "success": True,
                "cpu_available": True,
                "basic_operations": True,
                "message": "CPUå›é€€åŠŸèƒ½æ­£å¸¸"
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def _generate_gpu_performance_report(self, results: Dict[str, Any]):
        """ç”ŸæˆGPUæ€§èƒ½æŠ¥å‘Š"""
        try:
            # ç”ŸæˆJSONæŠ¥å‘Š
            json_path = self.output_dir / f"gpu_performance_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False, default=str)
            
            # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
            self._generate_performance_charts(results)
            
            self.logger.info(f"ğŸ“Š GPUæ€§èƒ½æŠ¥å‘Šå·²ç”Ÿæˆ: {json_path}")
            
        except Exception as e:
            self.logger.error(f"ç”ŸæˆGPUæ€§èƒ½æŠ¥å‘Šå¤±è´¥: {str(e)}")
    
    def _generate_performance_charts(self, results: Dict[str, Any]):
        """ç”Ÿæˆæ€§èƒ½å›¾è¡¨"""
        try:
            if results.get("comparison_test", {}).get("success"):
                comparison = results["comparison_test"]
                
                # CPU vs GPUå¯¹æ¯”å›¾
                categories = ['CPUæ—¶é—´', 'GPUæ—¶é—´']
                times = [comparison.get("cpu_time", 0), comparison.get("gpu_time", 0)]
                
                plt.figure(figsize=(10, 6))
                bars = plt.bar(categories, times, color=['blue', 'green'])
                plt.title('CPU vs GPU æ€§èƒ½å¯¹æ¯”')
                plt.ylabel('æ‰§è¡Œæ—¶é—´ (ç§’)')
                
                # æ·»åŠ æ•°å€¼æ ‡ç­¾
                for bar, time_val in zip(bars, times):
                    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,
                            f'{time_val:.4f}s', ha='center', va='bottom')
                
                chart_path = self.output_dir / "gpu_cpu_comparison.png"
                plt.savefig(chart_path, dpi=300, bbox_inches='tight')
                plt.close()
                
                self.logger.info(f"ğŸ“ˆ æ€§èƒ½å¯¹æ¯”å›¾å·²ç”Ÿæˆ: {chart_path}")
                
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆæ€§èƒ½å›¾è¡¨å¤±è´¥: {str(e)}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ® å¯åŠ¨GPUè®­ç»ƒæ€§èƒ½ä¸“é¡¹æµ‹è¯•")
    print("=" * 50)
    
    test_system = GPUTrainingPerformanceTest()
    
    try:
        results = test_system.run_comprehensive_gpu_test()
        
        if results.get("success", True):
            print("\nâœ… GPUæ€§èƒ½æµ‹è¯•å®Œæˆï¼")
            print(f"ğŸ“Š æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: {test_system.output_dir}")
        else:
            print(f"\nâš ï¸ GPUæµ‹è¯•å¤±è´¥: {results.get('error', 'Unknown error')}")
            if "fallback_test" in results:
                print("ğŸ’» CPUå›é€€æµ‹è¯•ç»“æœ:", results["fallback_test"])
                
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•ç³»ç»Ÿå¼‚å¸¸: {str(e)}")
    
    print("\n" + "=" * 50)
    print("ğŸ GPUæ€§èƒ½æµ‹è¯•é€€å‡º")


if __name__ == "__main__":
    main()
