#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è®­ç»ƒéªŒè¯ç³»ç»Ÿä¸»è¿è¡Œè„šæœ¬
æ•´åˆæ‰€æœ‰è®­ç»ƒéªŒè¯æµ‹è¯•ï¼Œç”Ÿæˆç»¼åˆæŠ¥å‘Š
"""

import os
import sys
import json
import time
import logging
import unittest
import traceback
from typing import Dict, List, Any, Optional
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, PROJECT_ROOT)

# å¯¼å…¥æµ‹è¯•æ¨¡å—
from tests.training_validation.test_training_effectiveness import TrainingEffectivenessTest
from tests.training_validation.test_gpu_acceleration import GPUAccelerationTest
from tests.training_validation.test_quality_metrics import QualityMetricsTest

class TrainingValidationSuite:
    """è®­ç»ƒéªŒè¯ç³»ç»Ÿä¸»ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–éªŒè¯ç³»ç»Ÿ"""
        self.start_time = time.time()
        self.results = {
            "suite_info": {
                "start_time": datetime.now().isoformat(),
                "version": "1.0.0",
                "description": "VisionAI-ClipsMasterè®­ç»ƒæ¨¡å—éªŒè¯ç³»ç»Ÿ"
            },
            "test_results": {},
            "summary": {},
            "recommendations": []
        }
        
        # è®¾ç½®æ—¥å¿—
        self._setup_logging()
        self.logger = logging.getLogger(__name__)
        
        self.logger.info("=" * 60)
        self.logger.info("VisionAI-ClipsMaster è®­ç»ƒéªŒè¯ç³»ç»Ÿå¯åŠ¨")
        self.logger.info("=" * 60)
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        log_dir = os.path.join(PROJECT_ROOT, "logs")
        os.makedirs(log_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = os.path.join(log_dir, f"training_validation_{timestamp}.log")
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler(sys.stdout)
            ]
        )
    
    def run_all_tests(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰è®­ç»ƒéªŒè¯æµ‹è¯•"""
        self.logger.info("å¼€å§‹æ‰§è¡Œå®Œæ•´çš„è®­ç»ƒéªŒè¯æµ‹è¯•å¥—ä»¶...")
        
        test_modules = [
            ("training_effectiveness", TrainingEffectivenessTest),
            ("gpu_acceleration", GPUAccelerationTest),
            ("quality_metrics", QualityMetricsTest)
        ]
        
        for test_name, test_class in test_modules:
            self.logger.info(f"\n{'='*50}")
            self.logger.info(f"æ‰§è¡Œæµ‹è¯•æ¨¡å—: {test_name}")
            self.logger.info(f"{'='*50}")
            
            try:
                result = self._run_test_module(test_class, test_name)
                self.results["test_results"][test_name] = result
                
                if result["success"]:
                    self.logger.info(f"âœ… {test_name} æµ‹è¯•å®Œæˆ")
                else:
                    self.logger.error(f"âŒ {test_name} æµ‹è¯•å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    
            except Exception as e:
                error_msg = f"æµ‹è¯•æ¨¡å— {test_name} æ‰§è¡Œå¼‚å¸¸: {str(e)}"
                self.logger.error(error_msg)
                self.logger.error(traceback.format_exc())
                
                self.results["test_results"][test_name] = {
                    "success": False,
                    "error": error_msg,
                    "traceback": traceback.format_exc()
                }
        
        # ç”Ÿæˆç»¼åˆåˆ†æ
        self._generate_summary()
        
        # ç”Ÿæˆå»ºè®®
        self._generate_recommendations()
        
        # ä¿å­˜ç»“æœ
        self._save_comprehensive_report()
        
        return self.results
    
    def _run_test_module(self, test_class, test_name: str) -> Dict[str, Any]:
        """è¿è¡Œå•ä¸ªæµ‹è¯•æ¨¡å—"""
        try:
            # åˆ›å»ºæµ‹è¯•å¥—ä»¶
            suite = unittest.TestLoader().loadTestsFromTestCase(test_class)
            
            # è¿è¡Œæµ‹è¯•
            runner = unittest.TextTestRunner(verbosity=2, stream=sys.stdout)
            test_result = runner.run(suite)
            
            # æ”¶é›†ç»“æœ
            result = {
                "success": test_result.wasSuccessful(),
                "tests_run": test_result.testsRun,
                "failures": len(test_result.failures),
                "errors": len(test_result.errors),
                "skipped": len(test_result.skipped) if hasattr(test_result, 'skipped') else 0,
                "details": {
                    "failures": [str(failure) for failure in test_result.failures],
                    "errors": [str(error) for error in test_result.errors]
                }
            }
            
            return result
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "traceback": traceback.format_exc()
            }
    
    def _generate_summary(self):
        """ç”Ÿæˆæµ‹è¯•ç»“æœæ‘˜è¦"""
        total_tests = 0
        total_failures = 0
        total_errors = 0
        successful_modules = 0
        
        for module_name, result in self.results["test_results"].items():
            if result.get("success", False):
                successful_modules += 1
            
            total_tests += result.get("tests_run", 0)
            total_failures += result.get("failures", 0)
            total_errors += result.get("errors", 0)
        
        end_time = time.time()
        duration = end_time - self.start_time
        
        self.results["summary"] = {
            "total_modules": len(self.results["test_results"]),
            "successful_modules": successful_modules,
            "total_tests": total_tests,
            "total_failures": total_failures,
            "total_errors": total_errors,
            "success_rate": (total_tests - total_failures - total_errors) / total_tests if total_tests > 0 else 0,
            "duration_seconds": duration,
            "overall_success": total_failures == 0 and total_errors == 0
        }
        
        # è®°å½•æ‘˜è¦
        summary = self.results["summary"]
        self.logger.info(f"\n{'='*60}")
        self.logger.info("æµ‹è¯•ç»“æœæ‘˜è¦")
        self.logger.info(f"{'='*60}")
        self.logger.info(f"æ€»æ¨¡å—æ•°: {summary['total_modules']}")
        self.logger.info(f"æˆåŠŸæ¨¡å—: {summary['successful_modules']}")
        self.logger.info(f"æ€»æµ‹è¯•æ•°: {summary['total_tests']}")
        self.logger.info(f"å¤±è´¥æµ‹è¯•: {summary['total_failures']}")
        self.logger.info(f"é”™è¯¯æµ‹è¯•: {summary['total_errors']}")
        self.logger.info(f"æˆåŠŸç‡: {summary['success_rate']:.1%}")
        self.logger.info(f"æ€»è€—æ—¶: {summary['duration_seconds']:.1f}ç§’")
        self.logger.info(f"æ•´ä½“çŠ¶æ€: {'âœ… æˆåŠŸ' if summary['overall_success'] else 'âŒ å¤±è´¥'}")
    
    def _generate_recommendations(self):
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        # åˆ†ææµ‹è¯•ç»“æœå¹¶ç”Ÿæˆå»ºè®®
        test_results = self.results["test_results"]
        
        # è®­ç»ƒæ•ˆæœå»ºè®®
        if "training_effectiveness" in test_results:
            effectiveness_result = test_results["training_effectiveness"]
            if not effectiveness_result.get("success", False):
                recommendations.append({
                    "category": "è®­ç»ƒæ•ˆæœ",
                    "priority": "é«˜",
                    "issue": "è®­ç»ƒæ•ˆæœéªŒè¯å¤±è´¥",
                    "recommendation": "æ£€æŸ¥è®­ç»ƒæ•°æ®è´¨é‡å’Œæ¨¡å‹é…ç½®ï¼Œç¡®ä¿è®­ç»ƒç¯å¢ƒæ­£ç¡®è®¾ç½®"
                })
        
        # GPUåŠ é€Ÿå»ºè®®
        if "gpu_acceleration" in test_results:
            gpu_result = test_results["gpu_acceleration"]
            if not gpu_result.get("success", False):
                recommendations.append({
                    "category": "GPUåŠ é€Ÿ",
                    "priority": "ä¸­",
                    "issue": "GPUåŠ é€Ÿæµ‹è¯•å¤±è´¥",
                    "recommendation": "æ£€æŸ¥GPUé©±åŠ¨å’ŒCUDAç¯å¢ƒï¼Œç¡®ä¿GPUå¯ç”¨æ€§"
                })
        
        # è´¨é‡æŒ‡æ ‡å»ºè®®
        if "quality_metrics" in test_results:
            quality_result = test_results["quality_metrics"]
            if not quality_result.get("success", False):
                recommendations.append({
                    "category": "è´¨é‡æŒ‡æ ‡",
                    "priority": "ä¸­",
                    "issue": "è´¨é‡æŒ‡æ ‡è®¡ç®—å¤±è´¥",
                    "recommendation": "æ£€æŸ¥è¯„ä¼°ç®—æ³•å®ç°ï¼Œç¡®ä¿æŒ‡æ ‡è®¡ç®—çš„å‡†ç¡®æ€§"
                })
        
        # é€šç”¨å»ºè®®
        summary = self.results["summary"]
        if summary["success_rate"] < 0.8:
            recommendations.append({
                "category": "æ•´ä½“è´¨é‡",
                "priority": "é«˜",
                "issue": f"æµ‹è¯•æˆåŠŸç‡è¿‡ä½: {summary['success_rate']:.1%}",
                "recommendation": "å…¨é¢æ£€æŸ¥è®­ç»ƒæ¨¡å—å®ç°ï¼Œé‡ç‚¹å…³æ³¨å¤±è´¥çš„æµ‹è¯•ç”¨ä¾‹"
            })
        
        if summary["duration_seconds"] > 300:  # 5åˆ†é’Ÿ
            recommendations.append({
                "category": "æ€§èƒ½ä¼˜åŒ–",
                "priority": "ä½",
                "issue": f"æµ‹è¯•æ‰§è¡Œæ—¶é—´è¿‡é•¿: {summary['duration_seconds']:.1f}ç§’",
                "recommendation": "ä¼˜åŒ–æµ‹è¯•ç”¨ä¾‹å’Œè®­ç»ƒç®—æ³•ï¼Œæé«˜æ‰§è¡Œæ•ˆç‡"
            })
        
        # å¦‚æœæ²¡æœ‰é—®é¢˜ï¼Œç»™å‡ºç§¯æå»ºè®®
        if not recommendations:
            recommendations.append({
                "category": "ç³»ç»ŸçŠ¶æ€",
                "priority": "ä¿¡æ¯",
                "issue": "æ‰€æœ‰æµ‹è¯•é€šè¿‡",
                "recommendation": "è®­ç»ƒç³»ç»Ÿè¿è¡Œè‰¯å¥½ï¼Œå¯ä»¥è€ƒè™‘å¢åŠ æ›´å¤šæµ‹è¯•ç”¨ä¾‹ä»¥æé«˜è¦†ç›–ç‡"
            })
        
        self.results["recommendations"] = recommendations
        
        # è®°å½•å»ºè®®
        self.logger.info(f"\n{'='*60}")
        self.logger.info("ä¼˜åŒ–å»ºè®®")
        self.logger.info(f"{'='*60}")
        for i, rec in enumerate(recommendations, 1):
            self.logger.info(f"{i}. [{rec['priority']}] {rec['category']}: {rec['issue']}")
            self.logger.info(f"   å»ºè®®: {rec['recommendation']}")
    
    def _save_comprehensive_report(self):
        """ä¿å­˜ç»¼åˆæµ‹è¯•æŠ¥å‘Š"""
        try:
            # æ›´æ–°ç»“æŸæ—¶é—´
            self.results["suite_info"]["end_time"] = datetime.now().isoformat()
            self.results["suite_info"]["duration_seconds"] = time.time() - self.start_time
            
            # ä¿å­˜JSONæŠ¥å‘Š
            output_dir = os.path.join(PROJECT_ROOT, "test_output")
            os.makedirs(output_dir, exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            json_file = os.path.join(output_dir, f"training_validation_report_{timestamp}.json")
            
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(self.results, f, indent=2, ensure_ascii=False)
            
            # ç”ŸæˆHTMLæŠ¥å‘Š
            html_file = os.path.join(output_dir, f"training_validation_report_{timestamp}.html")
            self._generate_html_report(html_file)
            
            self.logger.info(f"\nğŸ“Š ç»¼åˆæµ‹è¯•æŠ¥å‘Šå·²ç”Ÿæˆ:")
            self.logger.info(f"   JSONæŠ¥å‘Š: {json_file}")
            self.logger.info(f"   HTMLæŠ¥å‘Š: {html_file}")
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜æµ‹è¯•æŠ¥å‘Šå¤±è´¥: {e}")
    
    def _generate_html_report(self, html_file: str):
        """ç”ŸæˆHTMLæ ¼å¼çš„æµ‹è¯•æŠ¥å‘Š"""
        try:
            summary = self.results["summary"]
            
            html_content = f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VisionAI-ClipsMaster è®­ç»ƒéªŒè¯æŠ¥å‘Š</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; }}
        .header {{ background-color: #f0f0f0; padding: 20px; border-radius: 5px; }}
        .summary {{ background-color: #e8f5e8; padding: 15px; margin: 20px 0; border-radius: 5px; }}
        .error {{ background-color: #ffe8e8; }}
        .success {{ color: green; }}
        .failure {{ color: red; }}
        .recommendation {{ background-color: #fff3cd; padding: 10px; margin: 10px 0; border-radius: 3px; }}
        table {{ border-collapse: collapse; width: 100%; }}
        th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
        th {{ background-color: #f2f2f2; }}
    </style>
</head>
<body>
    <div class="header">
        <h1>VisionAI-ClipsMaster è®­ç»ƒéªŒè¯æŠ¥å‘Š</h1>
        <p>ç”Ÿæˆæ—¶é—´: {self.results['suite_info']['end_time']}</p>
        <p>æµ‹è¯•ç‰ˆæœ¬: {self.results['suite_info']['version']}</p>
    </div>
    
    <div class="summary {'success' if summary['overall_success'] else 'error'}">
        <h2>æµ‹è¯•æ‘˜è¦</h2>
        <p><strong>æ•´ä½“çŠ¶æ€:</strong> {'âœ… æˆåŠŸ' if summary['overall_success'] else 'âŒ å¤±è´¥'}</p>
        <p><strong>æˆåŠŸç‡:</strong> {summary['success_rate']:.1%}</p>
        <p><strong>æ€»æµ‹è¯•æ•°:</strong> {summary['total_tests']}</p>
        <p><strong>å¤±è´¥æ•°:</strong> {summary['total_failures']}</p>
        <p><strong>é”™è¯¯æ•°:</strong> {summary['total_errors']}</p>
        <p><strong>æ‰§è¡Œæ—¶é—´:</strong> {summary['duration_seconds']:.1f}ç§’</p>
    </div>
    
    <h2>è¯¦ç»†ç»“æœ</h2>
    <table>
        <tr>
            <th>æµ‹è¯•æ¨¡å—</th>
            <th>çŠ¶æ€</th>
            <th>æµ‹è¯•æ•°</th>
            <th>å¤±è´¥æ•°</th>
            <th>é”™è¯¯æ•°</th>
        </tr>
"""
            
            for module_name, result in self.results["test_results"].items():
                status = "âœ… æˆåŠŸ" if result.get("success", False) else "âŒ å¤±è´¥"
                status_class = "success" if result.get("success", False) else "failure"
                
                html_content += f"""
        <tr>
            <td>{module_name}</td>
            <td class="{status_class}">{status}</td>
            <td>{result.get('tests_run', 0)}</td>
            <td>{result.get('failures', 0)}</td>
            <td>{result.get('errors', 0)}</td>
        </tr>
"""
            
            html_content += """
    </table>
    
    <h2>ä¼˜åŒ–å»ºè®®</h2>
"""
            
            for i, rec in enumerate(self.results["recommendations"], 1):
                html_content += f"""
    <div class="recommendation">
        <h4>{i}. [{rec['priority']}] {rec['category']}</h4>
        <p><strong>é—®é¢˜:</strong> {rec['issue']}</p>
        <p><strong>å»ºè®®:</strong> {rec['recommendation']}</p>
    </div>
"""
            
            html_content += """
</body>
</html>
"""
            
            with open(html_file, 'w', encoding='utf-8') as f:
                f.write(html_content)
                
        except Exception as e:
            self.logger.error(f"ç”ŸæˆHTMLæŠ¥å‘Šå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºå¹¶è¿è¡ŒéªŒè¯ç³»ç»Ÿ
        validation_suite = TrainingValidationSuite()
        results = validation_suite.run_all_tests()
        
        # è¿”å›é€€å‡ºç 
        if results["summary"]["overall_success"]:
            print("\nğŸ‰ æ‰€æœ‰è®­ç»ƒéªŒè¯æµ‹è¯•é€šè¿‡ï¼")
            sys.exit(0)
        else:
            print("\nâš ï¸  éƒ¨åˆ†è®­ç»ƒéªŒè¯æµ‹è¯•å¤±è´¥ï¼Œè¯·æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š")
            sys.exit(1)
            
    except Exception as e:
        print(f"\nğŸ’¥ è®­ç»ƒéªŒè¯ç³»ç»Ÿæ‰§è¡Œå¤±è´¥: {e}")
        traceback.print_exc()
        sys.exit(2)

if __name__ == "__main__":
    main()
