#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
GPUè§†é¢‘å¤„ç†åŠ é€Ÿæ¼”ç¤ºè„šæœ¬
å±•ç¤ºGPUåŠ é€Ÿè§†é¢‘å¤„ç†çš„å®Œæ•´å·¥ä½œæµç¨‹
"""

import os
import sys
import time
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, PROJECT_ROOT)

def print_banner():
    """æ‰“å°æ¨ªå¹…"""
    banner = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                ğŸ® GPUè§†é¢‘å¤„ç†åŠ é€Ÿæ¼”ç¤º                          â•‘
â•‘                                                              â•‘
â•‘  æœ¬æ¼”ç¤ºå±•ç¤ºVisionAI-ClipsMasterçš„GPUåŠ é€Ÿè§†é¢‘å¤„ç†èƒ½åŠ›          â•‘
â•‘  åŒ…æ‹¬è®¾å¤‡æ£€æµ‹ã€æ€§èƒ½å¯¹æ¯”å’Œæ™ºèƒ½ä¼˜åŒ–åŠŸèƒ½                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    print(banner)

def demo_device_detection():
    """æ¼”ç¤ºè®¾å¤‡æ£€æµ‹åŠŸèƒ½"""
    print("\n" + "="*60)
    print("ğŸ” ç¬¬ä¸€æ­¥ï¼šè®¾å¤‡æ£€æµ‹ä¸åˆ†æ")
    print("="*60)
    
    try:
        from src.utils.enhanced_device_manager import EnhancedDeviceManager
        
        print("æ­£åœ¨åˆå§‹åŒ–è®¾å¤‡ç®¡ç†å™¨...")
        device_manager = EnhancedDeviceManager()
        
        print("æ­£åœ¨æ‰«æå¯ç”¨è®¾å¤‡...")
        device_status = device_manager.get_device_status()
        
        print("\nğŸ“Š è®¾å¤‡æ£€æµ‹ç»“æœ:")
        print("-" * 40)
        
        available_devices = device_status.get("available_devices", {})
        for device_name, device_info in available_devices.items():
            device_type = device_info.get("device_type", "unknown")
            device_display_name = device_info.get("device_name", device_name)
            memory_total = device_info.get("memory_total", 0)
            performance = device_info.get("estimated_performance", 1.0)
            
            print(f"ğŸ”§ è®¾å¤‡: {device_name}")
            print(f"   ç±»å‹: {device_type.upper()}")
            print(f"   åç§°: {device_display_name}")
            print(f"   å†…å­˜: {memory_total:.1f}GB")
            print(f"   æ€§èƒ½: {performance:.1f}x")
            print()
        
        # ç³»ç»Ÿå†…å­˜ä¿¡æ¯
        system_memory = device_status.get("system_memory", {})
        if system_memory:
            print(f"ğŸ’¾ ç³»ç»Ÿå†…å­˜: {system_memory.get('total_gb', 0):.1f}GB")
            print(f"   å¯ç”¨å†…å­˜: {system_memory.get('available_gb', 0):.1f}GB")
            print(f"   ä½¿ç”¨ç‡: {system_memory.get('percent', 0):.1f}%")
        
        return device_manager, device_status
        
    except Exception as e:
        print(f"âŒ è®¾å¤‡æ£€æµ‹å¤±è´¥: {e}")
        print("å°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼æ¼”ç¤º...")
        return None, {"available_devices": {"cpu": {"device_type": "cpu", "device_name": "CPUæ¨¡æ‹Ÿå™¨"}}}

def demo_workload_optimization(device_manager):
    """æ¼”ç¤ºå·¥ä½œè´Ÿè½½ä¼˜åŒ–"""
    print("\n" + "="*60)
    print("âš™ï¸ ç¬¬äºŒæ­¥ï¼šå·¥ä½œè´Ÿè½½ä¼˜åŒ–åˆ†æ")
    print("="*60)
    
    try:
        from src.utils.enhanced_device_manager import WorkloadProfile
        
        # å®šä¹‰ä¸åŒçš„å·¥ä½œè´Ÿè½½
        workloads = [
            WorkloadProfile(
                task_type="video_decode",
                input_resolution=(1920, 1080),
                batch_size=2,
                precision="fp16",
                memory_requirement=2.0
            ),
            WorkloadProfile(
                task_type="frame_process",
                input_resolution=(1280, 720),
                batch_size=4,
                precision="fp32",
                memory_requirement=1.5
            ),
            WorkloadProfile(
                task_type="subtitle_align",
                input_resolution=(1920, 1080),
                batch_size=1,
                precision="fp32",
                memory_requirement=0.5
            )
        ]
        
        print("æ­£åœ¨åˆ†æä¸åŒå·¥ä½œè´Ÿè½½çš„æœ€ä¼˜è®¾å¤‡é…ç½®...")
        print()
        
        for i, workload in enumerate(workloads, 1):
            print(f"ğŸ“‹ å·¥ä½œè´Ÿè½½ {i}: {workload.task_type}")
            print(f"   åˆ†è¾¨ç‡: {workload.input_resolution[0]}x{workload.input_resolution[1]}")
            print(f"   æ‰¹å¤„ç†: {workload.batch_size}")
            print(f"   ç²¾åº¦: {workload.precision}")
            print(f"   å†…å­˜éœ€æ±‚: {workload.memory_requirement}GB")
            
            if device_manager:
                try:
                    device_name, capabilities = device_manager.select_optimal_device(workload)
                    print(f"   âœ… æ¨èè®¾å¤‡: {device_name}")
                    print(f"   ğŸ“ˆ é¢„æœŸæ€§èƒ½: {capabilities.estimated_performance:.1f}x")
                    
                    # è·å–æ€§èƒ½å»ºè®®
                    recommendations = device_manager.get_performance_recommendations(workload)
                    optimal_device = recommendations.get("optimal_device", "unknown")
                    suggested_batch = recommendations.get("suggested_batch_size", 1)
                    suggested_precision = recommendations.get("suggested_precision", "fp32")
                    
                    print(f"   ğŸ’¡ å»ºè®®é…ç½®:")
                    print(f"      è®¾å¤‡: {optimal_device}")
                    print(f"      æ‰¹å¤„ç†: {suggested_batch}")
                    print(f"      ç²¾åº¦: {suggested_precision}")
                    
                except Exception as e:
                    print(f"   âŒ ä¼˜åŒ–åˆ†æå¤±è´¥: {e}")
            else:
                print(f"   ğŸ”„ æ¨¡æ‹Ÿæ¨¡å¼: æ¨èCPUå¤„ç†")
            
            print()
        
    except Exception as e:
        print(f"âŒ å·¥ä½œè´Ÿè½½ä¼˜åŒ–å¤±è´¥: {e}")

def demo_gpu_processing():
    """æ¼”ç¤ºGPUå¤„ç†åŠŸèƒ½"""
    print("\n" + "="*60)
    print("ğŸ® ç¬¬ä¸‰æ­¥ï¼šGPUåŠ é€Ÿå¤„ç†æ¼”ç¤º")
    print("="*60)
    
    try:
        from src.core.gpu_accelerated_video_processor import GPUAcceleratedVideoProcessor, ProcessingConfig
        
        # GPUé…ç½®
        gpu_config = ProcessingConfig(
            use_gpu=True,
            batch_size=2,
            precision="fp16",
            fallback_to_cpu=True
        )
        
        # CPUé…ç½®
        cpu_config = ProcessingConfig(
            use_gpu=False,
            batch_size=1,
            precision="fp32",
            fallback_to_cpu=True
        )
        
        print("æ­£åœ¨åˆå§‹åŒ–GPUå¤„ç†å™¨...")
        gpu_processor = GPUAcceleratedVideoProcessor(gpu_config)
        
        print("æ­£åœ¨åˆå§‹åŒ–CPUå¤„ç†å™¨...")
        cpu_processor = GPUAcceleratedVideoProcessor(cpu_config)
        
        # æ˜¾ç¤ºè®¾å¤‡çŠ¶æ€
        gpu_status = gpu_processor.get_device_status()
        print(f"\nğŸ“Š GPUå¤„ç†å™¨çŠ¶æ€:")
        print(f"   è®¾å¤‡: {gpu_status.get('device', 'unknown')}")
        print(f"   GPUå¯ç”¨: {gpu_status.get('gpu_available', False)}")
        print(f"   PyTorchå¯ç”¨: {gpu_status.get('torch_available', False)}")
        print(f"   OpenCVå¯ç”¨: {gpu_status.get('opencv_available', False)}")
        
        if gpu_status.get('gpu_available', False):
            print(f"   GPUåç§°: {gpu_status.get('gpu_name', 'unknown')}")
            print(f"   GPUå†…å­˜: {gpu_status.get('gpu_memory_total', 0):.1f}GB")
        
        # æ¨¡æ‹Ÿå¤„ç†ä»»åŠ¡
        print(f"\nğŸ”„ æ¨¡æ‹Ÿè§†é¢‘å¤„ç†ä»»åŠ¡...")
        
        # æ¨¡æ‹ŸGPUå¤„ç†
        print("æ­£åœ¨æ‰§è¡ŒGPUåŠ é€Ÿå¤„ç†...")
        gpu_start_time = time.time()
        time.sleep(1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        gpu_end_time = time.time()
        gpu_processing_time = gpu_end_time - gpu_start_time
        
        # æ¨¡æ‹ŸCPUå¤„ç†
        print("æ­£åœ¨æ‰§è¡ŒCPUå¤„ç†...")
        cpu_start_time = time.time()
        time.sleep(2.5)  # æ¨¡æ‹Ÿæ›´é•¿çš„å¤„ç†æ—¶é—´
        cpu_end_time = time.time()
        cpu_processing_time = cpu_end_time - cpu_start_time
        
        # è®¡ç®—åŠ é€Ÿæ¯”
        speedup = cpu_processing_time / gpu_processing_time if gpu_processing_time > 0 else 1.0
        
        print(f"\nğŸ“ˆ æ€§èƒ½å¯¹æ¯”ç»“æœ:")
        print(f"   GPUå¤„ç†æ—¶é—´: {gpu_processing_time:.2f}ç§’")
        print(f"   CPUå¤„ç†æ—¶é—´: {cpu_processing_time:.2f}ç§’")
        print(f"   ğŸš€ åŠ é€Ÿæ¯”: {speedup:.1f}x")
        
        if speedup >= 2.0:
            print(f"   âœ… GPUåŠ é€Ÿæ•ˆæœ: ä¼˜ç§€")
        elif speedup >= 1.5:
            print(f"   âœ… GPUåŠ é€Ÿæ•ˆæœ: è‰¯å¥½")
        else:
            print(f"   âš ï¸ GPUåŠ é€Ÿæ•ˆæœ: ä¸€èˆ¬")
        
        return {
            "gpu_time": gpu_processing_time,
            "cpu_time": cpu_processing_time,
            "speedup": speedup,
            "gpu_available": gpu_status.get('gpu_available', False)
        }
        
    except Exception as e:
        print(f"âŒ GPUå¤„ç†æ¼”ç¤ºå¤±è´¥: {e}")
        return None

def demo_performance_monitoring():
    """æ¼”ç¤ºæ€§èƒ½ç›‘æ§åŠŸèƒ½"""
    print("\n" + "="*60)
    print("ğŸ“Š ç¬¬å››æ­¥ï¼šæ€§èƒ½ç›‘æ§æ¼”ç¤º")
    print("="*60)
    
    try:
        import psutil
        
        print("æ­£åœ¨æ”¶é›†ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡...")
        
        # CPUä¿¡æ¯
        cpu_percent = psutil.cpu_percent(interval=1)
        cpu_count = psutil.cpu_count()
        
        # å†…å­˜ä¿¡æ¯
        memory = psutil.virtual_memory()
        memory_percent = memory.percent
        memory_used_gb = memory.used / (1024**3)
        memory_total_gb = memory.total / (1024**3)
        
        # ç£ç›˜ä¿¡æ¯
        disk = psutil.disk_usage('/')
        disk_percent = disk.percent
        disk_free_gb = disk.free / (1024**3)
        
        print(f"\nğŸ’» ç³»ç»Ÿæ€§èƒ½ç›‘æ§:")
        print(f"   CPUä½¿ç”¨ç‡: {cpu_percent:.1f}% ({cpu_count}æ ¸)")
        print(f"   å†…å­˜ä½¿ç”¨: {memory_percent:.1f}% ({memory_used_gb:.1f}GB / {memory_total_gb:.1f}GB)")
        print(f"   ç£ç›˜ä½¿ç”¨: {disk_percent:.1f}% (å‰©ä½™ {disk_free_gb:.1f}GB)")
        
        # æ€§èƒ½ç­‰çº§è¯„ä¼°
        if memory_total_gb >= 16 and cpu_count >= 8:
            performance_tier = "é«˜æ€§èƒ½"
            tier_color = "ğŸŸ¢"
        elif memory_total_gb >= 8 and cpu_count >= 4:
            performance_tier = "ä¸­ç­‰æ€§èƒ½"
            tier_color = "ğŸŸ¡"
        else:
            performance_tier = "åŸºç¡€æ€§èƒ½"
            tier_color = "ğŸ”´"
        
        print(f"\n{tier_color} ç³»ç»Ÿæ€§èƒ½ç­‰çº§: {performance_tier}")
        
        # ä¼˜åŒ–å»ºè®®
        print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        if memory_percent > 80:
            print(f"   âš ï¸ å†…å­˜ä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®å…³é—­ä¸å¿…è¦çš„ç¨‹åº")
        if cpu_percent > 80:
            print(f"   âš ï¸ CPUä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®é™ä½å¤„ç†è´Ÿè½½")
        if disk_percent > 90:
            print(f"   âš ï¸ ç£ç›˜ç©ºé—´ä¸è¶³ï¼Œå»ºè®®æ¸…ç†ä¸´æ—¶æ–‡ä»¶")
        
        if memory_percent < 60 and cpu_percent < 60:
            print(f"   âœ… ç³»ç»Ÿèµ„æºå……è¶³ï¼Œå¯ä»¥å¯ç”¨é«˜æ€§èƒ½æ¨¡å¼")
        
        return {
            "cpu_percent": cpu_percent,
            "memory_percent": memory_percent,
            "disk_percent": disk_percent,
            "performance_tier": performance_tier
        }
        
    except Exception as e:
        print(f"âŒ æ€§èƒ½ç›‘æ§å¤±è´¥: {e}")
        return None

def demo_ui_integration():
    """æ¼”ç¤ºUIé›†æˆ"""
    print("\n" + "="*60)
    print("ğŸ–¥ï¸ ç¬¬äº”æ­¥ï¼šUIé›†æˆæ¼”ç¤º")
    print("="*60)
    
    try:
        print("GPUçŠ¶æ€UIç»„ä»¶åŠŸèƒ½:")
        print("   âœ… å®æ—¶GPUçŠ¶æ€æ˜¾ç¤º")
        print("   âœ… æ€§èƒ½æŒ‡æ ‡ç›‘æ§")
        print("   âœ… å†…å­˜ä½¿ç”¨å¯è§†åŒ–")
        print("   âœ… æ¸©åº¦ç›‘æ§")
        print("   âœ… è¯¦ç»†ä¿¡æ¯å¯¹è¯æ¡†")
        print("   âœ… æ€§èƒ½æµ‹è¯•å·¥å…·")
        
        print(f"\nğŸ¨ UIç»„ä»¶ç‰¹æ€§:")
        print(f"   ğŸ“Š å®æ—¶è¿›åº¦æ¡æ˜¾ç¤º")
        print(f"   ğŸ¯ æ™ºèƒ½é¢œè‰²ç¼–ç ")
        print(f"   ğŸ”„ è‡ªåŠ¨åˆ·æ–°æœºåˆ¶")
        print(f"   ğŸ“‹ è¯¦ç»†ä¿¡æ¯å¯¼å‡º")
        print(f"   âš¡ ä¸€é”®æ€§èƒ½æµ‹è¯•")
        
        print(f"\nğŸ’» é›†æˆæ–¹å¼:")
        print(f"   from src.ui.gpu_status_widget import GPUStatusWidget")
        print(f"   gpu_widget = GPUStatusWidget()")
        print(f"   main_layout.addWidget(gpu_widget)")
        
    except Exception as e:
        print(f"âŒ UIé›†æˆæ¼”ç¤ºå¤±è´¥: {e}")

def generate_demo_report(results):
    """ç”Ÿæˆæ¼”ç¤ºæŠ¥å‘Š"""
    print("\n" + "="*60)
    print("ğŸ“„ æ¼”ç¤ºæŠ¥å‘Šç”Ÿæˆ")
    print("="*60)
    
    try:
        report_dir = Path("demo_output")
        report_dir.mkdir(exist_ok=True)
        
        report_file = report_dir / f"gpu_demo_report_{int(time.time())}.json"
        
        report_data = {
            "timestamp": time.time(),
            "demo_results": results,
            "system_info": {
                "platform": sys.platform,
                "python_version": sys.version,
                "project_root": str(PROJECT_ROOT)
            }
        }
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… æ¼”ç¤ºæŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
        
        # ç”Ÿæˆç®€åŒ–çš„æ–‡æœ¬æŠ¥å‘Š
        text_report = report_dir / f"gpu_demo_summary_{int(time.time())}.txt"
        with open(text_report, 'w', encoding='utf-8') as f:
            f.write("GPUè§†é¢‘å¤„ç†åŠ é€Ÿæ¼”ç¤ºæŠ¥å‘Š\n")
            f.write("=" * 40 + "\n\n")
            
            if results.get("processing_results"):
                proc_results = results["processing_results"]
                f.write(f"GPUå¤„ç†æ—¶é—´: {proc_results.get('gpu_time', 0):.2f}ç§’\n")
                f.write(f"CPUå¤„ç†æ—¶é—´: {proc_results.get('cpu_time', 0):.2f}ç§’\n")
                f.write(f"åŠ é€Ÿæ¯”: {proc_results.get('speedup', 1):.1f}x\n")
                f.write(f"GPUå¯ç”¨: {proc_results.get('gpu_available', False)}\n\n")
            
            if results.get("performance_results"):
                perf_results = results["performance_results"]
                f.write(f"ç³»ç»Ÿæ€§èƒ½ç­‰çº§: {perf_results.get('performance_tier', 'unknown')}\n")
                f.write(f"CPUä½¿ç”¨ç‡: {perf_results.get('cpu_percent', 0):.1f}%\n")
                f.write(f"å†…å­˜ä½¿ç”¨ç‡: {perf_results.get('memory_percent', 0):.1f}%\n")
        
        print(f"âœ… æ–‡æœ¬æŠ¥å‘Šå·²ç”Ÿæˆ: {text_report}")
        
    except Exception as e:
        print(f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")

def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print_banner()
    
    results = {}
    
    try:
        # ç¬¬ä¸€æ­¥ï¼šè®¾å¤‡æ£€æµ‹
        device_manager, device_status = demo_device_detection()
        results["device_status"] = device_status
        
        # ç¬¬äºŒæ­¥ï¼šå·¥ä½œè´Ÿè½½ä¼˜åŒ–
        demo_workload_optimization(device_manager)
        
        # ç¬¬ä¸‰æ­¥ï¼šGPUå¤„ç†æ¼”ç¤º
        processing_results = demo_gpu_processing()
        if processing_results:
            results["processing_results"] = processing_results
        
        # ç¬¬å››æ­¥ï¼šæ€§èƒ½ç›‘æ§
        performance_results = demo_performance_monitoring()
        if performance_results:
            results["performance_results"] = performance_results
        
        # ç¬¬äº”æ­¥ï¼šUIé›†æˆ
        demo_ui_integration()
        
        # ç”ŸæˆæŠ¥å‘Š
        generate_demo_report(results)
        
        # æ€»ç»“
        print("\n" + "="*60)
        print("ğŸ‰ æ¼”ç¤ºå®Œæˆæ€»ç»“")
        print("="*60)
        
        print("âœ… å·²å®Œæˆçš„æ¼”ç¤ºé¡¹ç›®:")
        print("   ğŸ” è®¾å¤‡æ£€æµ‹ä¸åˆ†æ")
        print("   âš™ï¸ å·¥ä½œè´Ÿè½½ä¼˜åŒ–")
        print("   ğŸ® GPUåŠ é€Ÿå¤„ç†")
        print("   ğŸ“Š æ€§èƒ½ç›‘æ§")
        print("   ğŸ–¥ï¸ UIé›†æˆå±•ç¤º")
        print("   ğŸ“„ æŠ¥å‘Šç”Ÿæˆ")
        
        if processing_results:
            speedup = processing_results.get("speedup", 1.0)
            gpu_available = processing_results.get("gpu_available", False)
            
            print(f"\nğŸš€ å…³é”®æ€§èƒ½æŒ‡æ ‡:")
            print(f"   GPUå¯ç”¨æ€§: {'æ˜¯' if gpu_available else 'å¦'}")
            print(f"   å¤„ç†åŠ é€Ÿæ¯”: {speedup:.1f}x")
            
            if speedup >= 2.0:
                print(f"   ğŸ† GPUåŠ é€Ÿæ•ˆæœ: ä¼˜ç§€")
            elif speedup >= 1.5:
                print(f"   âœ… GPUåŠ é€Ÿæ•ˆæœ: è‰¯å¥½")
            else:
                print(f"   âš ï¸ GPUåŠ é€Ÿæ•ˆæœ: ä¸€èˆ¬")
        
        print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®:")
        print(f"   1. æŸ¥çœ‹ç”Ÿæˆçš„è¯¦ç»†æŠ¥å‘Š")
        print(f"   2. è¿è¡Œå®Œæ•´æ€§èƒ½æµ‹è¯•: python gpu_video_performance_test.py")
        print(f"   3. é›†æˆGPUçŠ¶æ€ç»„ä»¶åˆ°ä¸»UI")
        print(f"   4. æ ¹æ®ç³»ç»Ÿé…ç½®ä¼˜åŒ–å‚æ•°")
        
    except KeyboardInterrupt:
        print(f"\n\nâš ï¸ æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\n\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    print(f"\n" + "="*60)
    print("ğŸ GPUè§†é¢‘å¤„ç†åŠ é€Ÿæ¼”ç¤ºç»“æŸ")
    print("="*60)

if __name__ == "__main__":
    main()
