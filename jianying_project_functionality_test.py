#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
VisionAI-ClipsMaster å‰ªæ˜ å·¥ç¨‹æ–‡ä»¶åŠŸèƒ½æµ‹è¯•ç³»ç»Ÿ
éªŒè¯ç”Ÿæˆçš„å‰ªæ˜ å·¥ç¨‹æ–‡ä»¶åœ¨å‰ªæ˜ ä¸“ä¸šç‰ˆä¸­çš„å…·ä½“åŠŸèƒ½å’Œç»“æ„
"""

import os
import sys
import json
import time
import tempfile
import subprocess
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).resolve().parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
try:
    from src.exporters.jianying_pro_exporter import JianYingProExporter
    from src.utils.log_handler import get_logger
except ImportError as e:
    print(f"å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    sys.exit(1)

# é…ç½®æ—¥å¿—
logger = get_logger("jianying_functionality_test")

class JianYingProjectFunctionalityTest:
    """å‰ªæ˜ å·¥ç¨‹æ–‡ä»¶åŠŸèƒ½æµ‹è¯•ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ"""
        self.test_start_time = datetime.now()
        self.test_results = {
            "test_start_time": self.test_start_time.isoformat(),
            "test_categories": {},
            "project_structure": {},
            "functionality_tests": {},
            "issues_found": [],
            "recommendations": []
        }
        
        # åˆ›å»ºæµ‹è¯•ç›®å½•
        self.test_dir = Path(tempfile.mkdtemp(prefix="jianying_test_"))
        self.test_data_dir = self.test_dir / "test_data"
        self.test_output_dir = self.test_dir / "test_output"
        self.test_data_dir.mkdir(exist_ok=True)
        self.test_output_dir.mkdir(exist_ok=True)
        
        logger.info(f"å‰ªæ˜ åŠŸèƒ½æµ‹è¯•ç¯å¢ƒåˆå§‹åŒ–å®Œæˆï¼Œæµ‹è¯•ç›®å½•: {self.test_dir}")
        
        # åˆå§‹åŒ–å¯¼å‡ºå™¨
        self.jianying_exporter = None
        
    def setup_realistic_test_data(self) -> bool:
        """å‡†å¤‡çœŸå®çš„æµ‹è¯•æ•°æ®"""
        logger.info("å‡†å¤‡çœŸå®çš„å‰ªæ˜ æµ‹è¯•æ•°æ®...")
        
        try:
            # åˆ›å»ºçœŸå®çš„SRTå­—å¹•æ–‡ä»¶ï¼ˆæ¨¡æ‹ŸçŸ­å‰§å†…å®¹ï¼‰
            original_srt_content = """1
00:00:01,000 --> 00:00:05,000
å°é›¨ç«™åœ¨å’–å•¡å…é—¨å£ï¼ŒçŠ¹è±«ç€è¦ä¸è¦è¿›å»

2
00:00:06,000 --> 00:00:10,000
å¥¹çŸ¥é“é‡Œé¢åç€çš„æ˜¯å¥¹çš„å‰ç”·å‹ææ˜

3
00:00:11,000 --> 00:00:15,000
ä¸‰å¹´å‰ï¼Œä»–ä»¬å› ä¸ºè¯¯ä¼šè€Œåˆ†æ‰‹

4
00:00:16,000 --> 00:00:20,000
ç°åœ¨ææ˜è¦ç»“å©šäº†ï¼Œæ–°å¨˜ä¸æ˜¯å¥¹

5
00:00:21,000 --> 00:00:25,000
å°é›¨æ·±å¸ä¸€å£æ°”ï¼Œæ¨å¼€äº†å’–å•¡å…çš„é—¨

6
00:00:26,000 --> 00:00:30,000
ææ˜çœ‹åˆ°å¥¹ï¼Œçœ¼ä¸­é—ªè¿‡ä¸€ä¸æƒŠè®¶

7
00:00:31,000 --> 00:00:35,000
"å°é›¨ï¼Œä½ æ¥äº†ã€‚"ä»–è½»å£°è¯´é“

8
00:00:36,000 --> 00:00:40,000
"æˆ‘æƒ³å’Œä½ è°ˆè°ˆã€‚"å°é›¨ååœ¨ä»–å¯¹é¢

9
00:00:41,000 --> 00:00:45,000
ä¸¤äººå››ç›®ç›¸å¯¹ï¼Œå¾€äº‹å¦‚æ½®æ°´èˆ¬æ¶Œæ¥

10
00:00:46,000 --> 00:00:50,000
è¿™å¯èƒ½æ˜¯ä»–ä»¬æœ€åä¸€æ¬¡å•ç‹¬ç›¸å¤„äº†"""

            # åˆ›å»ºAIé‡æ„åçš„çˆ†æ¬¾å­—å¹•ï¼ˆç²¾åç‰‡æ®µï¼‰
            viral_srt_content = """1
00:00:01,000 --> 00:00:05,000
å°é›¨ç«™åœ¨å’–å•¡å…é—¨å£ï¼ŒçŠ¹è±«ç€è¦ä¸è¦è¿›å»

2
00:00:16,000 --> 00:00:20,000
ç°åœ¨ææ˜è¦ç»“å©šäº†ï¼Œæ–°å¨˜ä¸æ˜¯å¥¹

3
00:00:21,000 --> 00:00:25,000
å°é›¨æ·±å¸ä¸€å£æ°”ï¼Œæ¨å¼€äº†å’–å•¡å…çš„é—¨

4
00:00:31,000 --> 00:00:35,000
"å°é›¨ï¼Œä½ æ¥äº†ã€‚"ä»–è½»å£°è¯´é“

5
00:00:41,000 --> 00:00:45,000
ä¸¤äººå››ç›®ç›¸å¯¹ï¼Œå¾€äº‹å¦‚æ½®æ°´èˆ¬æ¶Œæ¥

6
00:00:46,000 --> 00:00:50,000
è¿™å¯èƒ½æ˜¯ä»–ä»¬æœ€åä¸€æ¬¡å•ç‹¬ç›¸å¤„äº†"""

            # ä¿å­˜æµ‹è¯•æ–‡ä»¶
            original_srt_path = self.test_data_dir / "original_drama.srt"
            viral_srt_path = self.test_data_dir / "viral_style.srt"
            test_video_path = self.test_data_dir / "original_drama_episode1.mp4"
            
            with open(original_srt_path, 'w', encoding='utf-8') as f:
                f.write(original_srt_content)
                
            with open(viral_srt_path, 'w', encoding='utf-8') as f:
                f.write(viral_srt_content)
            
            # åˆ›å»ºæ¨¡æ‹Ÿè§†é¢‘æ–‡ä»¶ä¿¡æ¯
            video_info = {
                "filename": "original_drama_episode1.mp4",
                "duration": 50.0,
                "resolution": "1920x1080",
                "fps": 30,
                "codec": "h264",
                "size_mb": 125.5
            }
            
            # ä¿å­˜è§†é¢‘ä¿¡æ¯
            with open(self.test_data_dir / "video_info.json", 'w', encoding='utf-8') as f:
                json.dump(video_info, f, ensure_ascii=False, indent=2)
            
            # åˆ›å»ºæ¨¡æ‹Ÿè§†é¢‘æ–‡ä»¶ï¼ˆå®é™…é¡¹ç›®ä¸­åº”è¯¥æ˜¯çœŸå®è§†é¢‘ï¼‰
            test_video_path.touch()
            
            logger.info(f"çœŸå®æµ‹è¯•æ•°æ®åˆ›å»ºå®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"æµ‹è¯•æ•°æ®å‡†å¤‡å¤±è´¥: {e}")
            return False
    
    def generate_test_project(self) -> Dict[str, Any]:
        """ç”Ÿæˆæµ‹è¯•ç”¨çš„å‰ªæ˜ å·¥ç¨‹æ–‡ä»¶"""
        logger.info("ç”Ÿæˆæµ‹è¯•ç”¨çš„å‰ªæ˜ å·¥ç¨‹æ–‡ä»¶...")
        
        test_result = {
            "test_name": "å‰ªæ˜ å·¥ç¨‹æ–‡ä»¶ç”Ÿæˆ",
            "status": "running",
            "details": {}
        }
        
        try:
            # åˆå§‹åŒ–å¯¼å‡ºå™¨
            self.jianying_exporter = JianYingProExporter()
            
            # è§£æçˆ†æ¬¾å­—å¹•æ–‡ä»¶
            viral_srt_path = self.test_data_dir / "viral_style.srt"
            viral_subtitles = self.parse_srt_file(str(viral_srt_path))
            
            # åˆ›å»ºè§†é¢‘ç‰‡æ®µä¿¡æ¯
            video_segments = []
            for i, subtitle in enumerate(viral_subtitles):
                segment = {
                    "id": f"segment_{i+1}",
                    "start_time": subtitle["start_time"],
                    "end_time": subtitle["end_time"],
                    "duration": subtitle["duration"],
                    "file_path": str(self.test_data_dir / "original_drama_episode1.mp4"),
                    "text": subtitle["text"],
                    "segment_type": "highlight"  # æ ‡è®°ä¸ºç²¾åç‰‡æ®µ
                }
                video_segments.append(segment)
            
            # ç”Ÿæˆå‰ªæ˜ å·¥ç¨‹æ–‡ä»¶
            project_file_path = self.test_output_dir / "drama_highlight_project.json"
            
            start_time = time.time()
            export_success = self.jianying_exporter.export_project(
                video_segments,
                str(project_file_path)
            )
            export_time = time.time() - start_time
            
            # éªŒè¯ç”Ÿæˆç»“æœ
            if project_file_path.exists():
                file_size = project_file_path.stat().st_size
                
                # è¯»å–å¹¶åˆ†æå·¥ç¨‹æ–‡ä»¶ç»“æ„
                with open(project_file_path, 'r', encoding='utf-8') as f:
                    project_data = json.load(f)
                
                test_result["details"] = {
                    "export_success": export_success,
                    "file_path": str(project_file_path),
                    "file_size": file_size,
                    "export_time": export_time,
                    "segments_count": len(video_segments),
                    "project_structure": self.analyze_project_structure(project_data)
                }
                
                # ä¿å­˜é¡¹ç›®æ•°æ®ä¾›åç»­åˆ†æ
                self.project_data = project_data
                self.project_file_path = project_file_path
                
                test_result["status"] = "passed"
                logger.info(f"âœ… å‰ªæ˜ å·¥ç¨‹æ–‡ä»¶ç”ŸæˆæˆåŠŸï¼Œæ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
            else:
                test_result["status"] = "failed"
                test_result["error"] = "å·¥ç¨‹æ–‡ä»¶æœªç”Ÿæˆ"
                logger.error("âŒ å‰ªæ˜ å·¥ç¨‹æ–‡ä»¶ç”Ÿæˆå¤±è´¥")
            
        except Exception as e:
            test_result["status"] = "error"
            test_result["error"] = str(e)
            logger.error(f"å‰ªæ˜ å·¥ç¨‹æ–‡ä»¶ç”Ÿæˆå‘ç”Ÿé”™è¯¯: {e}")
        
        return test_result
    
    def parse_srt_file(self, file_path: str) -> List[Dict[str, Any]]:
        """è§£æSRTæ–‡ä»¶"""
        import re
        
        subtitles = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # åˆ†å‰²å­—å¹•å—
            blocks = re.split(r'\n\s*\n', content.strip())
            
            for block in blocks:
                lines = block.strip().split('\n')
                if len(lines) >= 3:
                    # è§£æç´¢å¼•
                    try:
                        index = int(lines[0])
                    except ValueError:
                        continue
                    
                    # è§£ææ—¶é—´æˆ³
                    time_match = re.match(r'(\d{2}):(\d{2}):(\d{2}),(\d{3})\s+-->\s+(\d{2}):(\d{2}):(\d{2}),(\d{3})', lines[1])
                    if time_match:
                        start_h, start_m, start_s, start_ms = map(int, time_match.groups()[:4])
                        end_h, end_m, end_s, end_ms = map(int, time_match.groups()[4:])
                        
                        start_time = start_h * 3600 + start_m * 60 + start_s + start_ms / 1000
                        end_time = end_h * 3600 + end_m * 60 + end_s + end_ms / 1000
                        
                        # è§£ææ–‡æœ¬
                        text = '\n'.join(lines[2:])
                        
                        subtitles.append({
                            'index': index,
                            'start_time': start_time,
                            'end_time': end_time,
                            'duration': end_time - start_time,
                            'text': text
                        })
        
        except Exception as e:
            logger.error(f"SRTæ–‡ä»¶è§£æå¤±è´¥: {e}")
            
        return subtitles
    
    def analyze_project_structure(self, project_data: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æå‰ªæ˜ å·¥ç¨‹æ–‡ä»¶ç»“æ„"""
        logger.info("åˆ†æå‰ªæ˜ å·¥ç¨‹æ–‡ä»¶ç»“æ„...")
        
        structure_analysis = {
            "basic_info": {},
            "materials": {},
            "tracks": {},
            "timeline": {},
            "compatibility": {}
        }
        
        try:
            # åŸºæœ¬ä¿¡æ¯åˆ†æ
            structure_analysis["basic_info"] = {
                "version": project_data.get("version", "unknown"),
                "platform": project_data.get("platform", "unknown"),
                "project_id": project_data.get("id", "unknown"),
                "created_time": project_data.get("created_time", 0),
                "app_version": project_data.get("app_version", "unknown")
            }
            
            # ç´ æåˆ†æ
            materials = project_data.get("materials", {})
            structure_analysis["materials"] = {
                "videos_count": len(materials.get("videos", [])),
                "audios_count": len(materials.get("audios", [])),
                "images_count": len(materials.get("images", [])),
                "video_files": [v.get("file_path", "") for v in materials.get("videos", [])]
            }
            
            # è½¨é“åˆ†æ
            tracks = project_data.get("tracks", [])
            video_tracks = [t for t in tracks if t.get("type") == "video"]
            audio_tracks = [t for t in tracks if t.get("type") == "audio"]
            
            structure_analysis["tracks"] = {
                "total_tracks": len(tracks),
                "video_tracks": len(video_tracks),
                "audio_tracks": len(audio_tracks),
                "video_segments": sum(len(t.get("segments", [])) for t in video_tracks),
                "audio_segments": sum(len(t.get("segments", [])) for t in audio_tracks)
            }
            
            # æ—¶é—´è½´åˆ†æ
            if video_tracks:
                first_video_track = video_tracks[0]
                segments = first_video_track.get("segments", [])
                
                timeline_info = {
                    "segments_count": len(segments),
                    "total_duration": 0,
                    "segments_details": []
                }
                
                for i, segment in enumerate(segments):
                    target_timerange = segment.get("target_timerange", {})
                    source_timerange = segment.get("source_timerange", {})
                    
                    segment_detail = {
                        "segment_id": i + 1,
                        "target_start": target_timerange.get("start", 0),
                        "target_duration": target_timerange.get("duration", 0),
                        "source_start": source_timerange.get("start", 0),
                        "source_duration": source_timerange.get("duration", 0),
                        "material_id": segment.get("material_id", "unknown")
                    }
                    
                    timeline_info["segments_details"].append(segment_detail)
                    timeline_info["total_duration"] += target_timerange.get("duration", 0)
                
                structure_analysis["timeline"] = timeline_info
            
            # å…¼å®¹æ€§åˆ†æ
            structure_analysis["compatibility"] = {
                "has_required_fields": all(field in project_data for field in [
                    "version", "materials", "tracks", "canvas_config"
                ]),
                "jianying_version_compatible": project_data.get("version", "").startswith("3."),
                "file_format": "json",
                "encoding": "utf-8"
            }
            
        except Exception as e:
            logger.error(f"å·¥ç¨‹æ–‡ä»¶ç»“æ„åˆ†æå¤±è´¥: {e}")
            structure_analysis["error"] = str(e)
        
        return structure_analysis

    def test_project_import_compatibility(self) -> Dict[str, Any]:
        """æµ‹è¯•1: å·¥ç¨‹æ–‡ä»¶å¯¼å…¥å…¼å®¹æ€§"""
        logger.info("æµ‹è¯•1: å·¥ç¨‹æ–‡ä»¶å¯¼å…¥å…¼å®¹æ€§...")

        test_result = {
            "test_name": "å·¥ç¨‹æ–‡ä»¶å¯¼å…¥å…¼å®¹æ€§æµ‹è¯•",
            "status": "running",
            "details": {}
        }

        try:
            if not hasattr(self, 'project_data'):
                test_result["status"] = "failed"
                test_result["error"] = "æœªæ‰¾åˆ°å·¥ç¨‹æ–‡ä»¶æ•°æ®"
                return test_result

            # éªŒè¯JSONæ ¼å¼æœ‰æ•ˆæ€§
            json_valid = isinstance(self.project_data, dict)

            # éªŒè¯å¿…è¦å­—æ®µ
            required_fields = [
                "version", "type", "platform", "id", "materials",
                "tracks", "canvas_config", "extra_info"
            ]
            missing_fields = [field for field in required_fields if field not in self.project_data]

            # éªŒè¯å‰ªæ˜ ç‰ˆæœ¬å…¼å®¹æ€§
            version = self.project_data.get("version", "")
            version_compatible = version.startswith("3.")

            # éªŒè¯ç´ æè·¯å¾„æ ¼å¼
            materials = self.project_data.get("materials", {})
            videos = materials.get("videos", [])
            path_format_valid = True
            invalid_paths = []

            for video in videos:
                file_path = video.get("file_path", "")
                if not file_path or not isinstance(file_path, str):
                    path_format_valid = False
                    invalid_paths.append(video.get("id", "unknown"))

            # éªŒè¯è½¨é“ç»“æ„
            tracks = self.project_data.get("tracks", [])
            track_structure_valid = True
            track_issues = []

            for track in tracks:
                if not isinstance(track, dict):
                    track_structure_valid = False
                    track_issues.append("è½¨é“ä¸æ˜¯å­—å…¸æ ¼å¼")
                    continue

                if "type" not in track:
                    track_structure_valid = False
                    track_issues.append("è½¨é“ç¼ºå°‘typeå­—æ®µ")

                if "segments" not in track:
                    track_structure_valid = False
                    track_issues.append("è½¨é“ç¼ºå°‘segmentså­—æ®µ")

            test_result["details"] = {
                "json_valid": json_valid,
                "required_fields_present": len(missing_fields) == 0,
                "missing_fields": missing_fields,
                "version_compatible": version_compatible,
                "version": version,
                "path_format_valid": path_format_valid,
                "invalid_paths": invalid_paths,
                "track_structure_valid": track_structure_valid,
                "track_issues": track_issues,
                "file_size": self.project_file_path.stat().st_size if hasattr(self, 'project_file_path') else 0
            }

            # è®¡ç®—æ€»ä½“å…¼å®¹æ€§åˆ†æ•°
            compatibility_checks = [
                json_valid,
                len(missing_fields) == 0,
                version_compatible,
                path_format_valid,
                track_structure_valid
            ]

            compatibility_score = sum(compatibility_checks) / len(compatibility_checks)
            test_result["details"]["compatibility_score"] = compatibility_score

            if compatibility_score >= 0.8:
                test_result["status"] = "passed"
                logger.info(f"âœ… å·¥ç¨‹æ–‡ä»¶å¯¼å…¥å…¼å®¹æ€§æµ‹è¯•é€šè¿‡ï¼Œå…¼å®¹æ€§åˆ†æ•°: {compatibility_score:.2f}")
            else:
                test_result["status"] = "warning"
                logger.warning(f"âš ï¸ å·¥ç¨‹æ–‡ä»¶å¯¼å…¥å…¼å®¹æ€§å­˜åœ¨é—®é¢˜ï¼Œå…¼å®¹æ€§åˆ†æ•°: {compatibility_score:.2f}")

        except Exception as e:
            test_result["status"] = "error"
            test_result["error"] = str(e)
            logger.error(f"å·¥ç¨‹æ–‡ä»¶å¯¼å…¥å…¼å®¹æ€§æµ‹è¯•å‘ç”Ÿé”™è¯¯: {e}")

        return test_result

    def test_timeline_structure(self) -> Dict[str, Any]:
        """æµ‹è¯•2: æ—¶é—´è½´ç»“æ„éªŒè¯"""
        logger.info("æµ‹è¯•2: æ—¶é—´è½´ç»“æ„éªŒè¯...")

        test_result = {
            "test_name": "æ—¶é—´è½´ç»“æ„éªŒè¯",
            "status": "running",
            "details": {}
        }

        try:
            if not hasattr(self, 'project_data'):
                test_result["status"] = "failed"
                test_result["error"] = "æœªæ‰¾åˆ°å·¥ç¨‹æ–‡ä»¶æ•°æ®"
                return test_result

            tracks = self.project_data.get("tracks", [])
            video_tracks = [t for t in tracks if t.get("type") == "video"]

            if not video_tracks:
                test_result["status"] = "failed"
                test_result["error"] = "æœªæ‰¾åˆ°è§†é¢‘è½¨é“"
                return test_result

            # åˆ†æç¬¬ä¸€ä¸ªè§†é¢‘è½¨é“
            main_video_track = video_tracks[0]
            segments = main_video_track.get("segments", [])

            # éªŒè¯ç‰‡æ®µæ˜¯å¦ä¸ºç‹¬ç«‹çš„è§†é¢‘ç‰‡æ®µ
            independent_segments = True
            segment_analysis = []
            timeline_position = 0

            for i, segment in enumerate(segments):
                target_timerange = segment.get("target_timerange", {})
                source_timerange = segment.get("source_timerange", {})

                segment_info = {
                    "segment_id": i + 1,
                    "target_start": target_timerange.get("start", 0),
                    "target_duration": target_timerange.get("duration", 0),
                    "source_start": source_timerange.get("start", 0),
                    "source_duration": source_timerange.get("duration", 0),
                    "material_id": segment.get("material_id", ""),
                    "is_independent": True
                }

                # éªŒè¯ç‰‡æ®µæ˜¯å¦åœ¨æ­£ç¡®çš„æ—¶é—´è½´ä½ç½®
                expected_target_start = timeline_position
                actual_target_start = target_timerange.get("start", 0)

                if abs(actual_target_start - expected_target_start) > 100:  # å…è®¸100msè¯¯å·®
                    segment_info["is_independent"] = False
                    independent_segments = False

                timeline_position += target_timerange.get("duration", 0)
                segment_analysis.append(segment_info)

            # éªŒè¯ç‰‡æ®µé¡ºåºä¸AIé‡æ„å­—å¹•é¡ºåºä¸€è‡´
            order_consistent = True
            if hasattr(self, 'viral_subtitles'):
                if len(segments) == len(self.viral_subtitles):
                    for i, (segment, subtitle) in enumerate(zip(segments, self.viral_subtitles)):
                        source_start = segment.get("source_timerange", {}).get("start", 0)
                        expected_source_start = subtitle["start_time"] * 1000  # è½¬æ¢ä¸ºæ¯«ç§’

                        if abs(source_start - expected_source_start) > 1000:  # å…è®¸1ç§’è¯¯å·®
                            order_consistent = False
                            break
                else:
                    order_consistent = False

            # éªŒè¯ç‰‡æ®µæ˜¯å¦ä¿æŒæœªæ¸²æŸ“çŠ¶æ€ï¼ˆé€šè¿‡æ£€æŸ¥æ˜¯å¦å¼•ç”¨åŸå§‹ç´ æï¼‰
            unrendered_state = True
            for segment in segments:
                material_id = segment.get("material_id", "")
                if not material_id:
                    unrendered_state = False
                    break

            test_result["details"] = {
                "total_segments": len(segments),
                "independent_segments": independent_segments,
                "order_consistent": order_consistent,
                "unrendered_state": unrendered_state,
                "segment_analysis": segment_analysis,
                "total_timeline_duration": timeline_position,
                "video_tracks_count": len(video_tracks)
            }

            # è®¡ç®—æ—¶é—´è½´ç»“æ„åˆ†æ•°
            structure_checks = [
                len(segments) > 0,
                independent_segments,
                order_consistent,
                unrendered_state
            ]

            structure_score = sum(structure_checks) / len(structure_checks)
            test_result["details"]["structure_score"] = structure_score

            if structure_score >= 0.75:
                test_result["status"] = "passed"
                logger.info(f"âœ… æ—¶é—´è½´ç»“æ„éªŒè¯é€šè¿‡ï¼Œç»“æ„åˆ†æ•°: {structure_score:.2f}")
            else:
                test_result["status"] = "warning"
                logger.warning(f"âš ï¸ æ—¶é—´è½´ç»“æ„å­˜åœ¨é—®é¢˜ï¼Œç»“æ„åˆ†æ•°: {structure_score:.2f}")

        except Exception as e:
            test_result["status"] = "error"
            test_result["error"] = str(e)
            logger.error(f"æ—¶é—´è½´ç»“æ„éªŒè¯å‘ç”Ÿé”™è¯¯: {e}")

        return test_result

    def test_materials_mapping(self) -> Dict[str, Any]:
        """æµ‹è¯•3: ç´ æåº“æ˜ å°„å…³ç³»æµ‹è¯•"""
        logger.info("æµ‹è¯•3: ç´ æåº“æ˜ å°„å…³ç³»æµ‹è¯•...")

        test_result = {
            "test_name": "ç´ æåº“æ˜ å°„å…³ç³»æµ‹è¯•",
            "status": "running",
            "details": {}
        }

        try:
            if not hasattr(self, 'project_data'):
                test_result["status"] = "failed"
                test_result["error"] = "æœªæ‰¾åˆ°å·¥ç¨‹æ–‡ä»¶æ•°æ®"
                return test_result

            # è·å–ç´ æåº“ä¿¡æ¯
            materials = self.project_data.get("materials", {})
            videos = materials.get("videos", [])

            # è·å–æ—¶é—´è½´ç‰‡æ®µä¿¡æ¯
            tracks = self.project_data.get("tracks", [])
            video_tracks = [t for t in tracks if t.get("type") == "video"]

            if not video_tracks:
                test_result["status"] = "failed"
                test_result["error"] = "æœªæ‰¾åˆ°è§†é¢‘è½¨é“"
                return test_result

            segments = video_tracks[0].get("segments", [])

            # éªŒè¯ç´ æåº“ä¸­æ˜¯å¦æ­£ç¡®å¯¼å…¥äº†åŸç‰‡è§†é¢‘æ–‡ä»¶
            materials_imported_correctly = True
            material_files = []

            for video in videos:
                file_path = video.get("file_path", "")
                material_id = video.get("id", "")

                material_info = {
                    "material_id": material_id,
                    "file_path": file_path,
                    "file_exists": Path(file_path).exists() if file_path else False,
                    "is_original_video": "original_drama" in file_path
                }

                material_files.append(material_info)

                if not file_path or not material_id:
                    materials_imported_correctly = False

            # éªŒè¯æ—¶é—´è½´ç‰‡æ®µä¸ç´ æåº“çš„æ˜ å°„å…³ç³»
            mapping_correct = True
            mapping_analysis = []
            used_materials = set()

            for i, segment in enumerate(segments):
                material_id = segment.get("material_id", "")

                # æŸ¥æ‰¾å¯¹åº”çš„ç´ æ
                corresponding_material = None
                for video in videos:
                    if video.get("id") == material_id:
                        corresponding_material = video
                        break

                mapping_info = {
                    "segment_id": i + 1,
                    "material_id": material_id,
                    "has_corresponding_material": corresponding_material is not None,
                    "material_file_path": corresponding_material.get("file_path", "") if corresponding_material else "",
                    "is_one_to_one_mapping": True
                }

                if not corresponding_material:
                    mapping_correct = False
                    mapping_info["is_one_to_one_mapping"] = False

                used_materials.add(material_id)
                mapping_analysis.append(mapping_info)

            # éªŒè¯æ˜¯å¦å­˜åœ¨é‡å¤æˆ–ä¸¢å¤±çš„æ˜ å°„
            total_materials = len(videos)
            used_materials_count = len(used_materials)
            no_duplicate_or_missing = used_materials_count <= total_materials

            # éªŒè¯æ˜ å°„å…³ç³»æ˜¯ä¸€ä¸€å¯¹åº”çš„
            one_to_one_mapping = True
            material_usage_count = {}

            for segment in segments:
                material_id = segment.get("material_id", "")
                material_usage_count[material_id] = material_usage_count.get(material_id, 0) + 1

            # æ£€æŸ¥æ˜¯å¦æœ‰ç´ æè¢«å¤šæ¬¡ä½¿ç”¨ï¼ˆè¿™æ˜¯æ­£å¸¸çš„ï¼Œå› ä¸ºå¯èƒ½ä»åŒä¸€ä¸ªåŸç‰‡æå–å¤šä¸ªç‰‡æ®µï¼‰
            multiple_usage_materials = {k: v for k, v in material_usage_count.items() if v > 1}

            test_result["details"] = {
                "materials_count": len(videos),
                "segments_count": len(segments),
                "materials_imported_correctly": materials_imported_correctly,
                "mapping_correct": mapping_correct,
                "no_duplicate_or_missing": no_duplicate_or_missing,
                "one_to_one_mapping": one_to_one_mapping,
                "material_files": material_files,
                "mapping_analysis": mapping_analysis,
                "used_materials_count": used_materials_count,
                "multiple_usage_materials": multiple_usage_materials
            }

            # è®¡ç®—æ˜ å°„å…³ç³»åˆ†æ•°
            mapping_checks = [
                materials_imported_correctly,
                mapping_correct,
                no_duplicate_or_missing,
                len(videos) > 0,
                len(segments) > 0
            ]

            mapping_score = sum(mapping_checks) / len(mapping_checks)
            test_result["details"]["mapping_score"] = mapping_score

            if mapping_score >= 0.8:
                test_result["status"] = "passed"
                logger.info(f"âœ… ç´ æåº“æ˜ å°„å…³ç³»æµ‹è¯•é€šè¿‡ï¼Œæ˜ å°„åˆ†æ•°: {mapping_score:.2f}")
            else:
                test_result["status"] = "warning"
                logger.warning(f"âš ï¸ ç´ æåº“æ˜ å°„å…³ç³»å­˜åœ¨é—®é¢˜ï¼Œæ˜ å°„åˆ†æ•°: {mapping_score:.2f}")

        except Exception as e:
            test_result["status"] = "error"
            test_result["error"] = str(e)
            logger.error(f"ç´ æåº“æ˜ å°„å…³ç³»æµ‹è¯•å‘ç”Ÿé”™è¯¯: {e}")

        return test_result

    def test_editing_functionality(self) -> Dict[str, Any]:
        """æµ‹è¯•4: ç¼–è¾‘åŠŸèƒ½å¯ç”¨æ€§éªŒè¯"""
        logger.info("æµ‹è¯•4: ç¼–è¾‘åŠŸèƒ½å¯ç”¨æ€§éªŒè¯...")

        test_result = {
            "test_name": "ç¼–è¾‘åŠŸèƒ½å¯ç”¨æ€§éªŒè¯",
            "status": "running",
            "details": {}
        }

        try:
            if not hasattr(self, 'project_data'):
                test_result["status"] = "failed"
                test_result["error"] = "æœªæ‰¾åˆ°å·¥ç¨‹æ–‡ä»¶æ•°æ®"
                return test_result

            # è·å–è§†é¢‘è½¨é“å’Œç‰‡æ®µ
            tracks = self.project_data.get("tracks", [])
            video_tracks = [t for t in tracks if t.get("type") == "video"]

            if not video_tracks:
                test_result["status"] = "failed"
                test_result["error"] = "æœªæ‰¾åˆ°è§†é¢‘è½¨é“"
                return test_result

            segments = video_tracks[0].get("segments", [])

            if len(segments) < 2:
                test_result["status"] = "failed"
                test_result["error"] = "ç‰‡æ®µæ•°é‡ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œç¼–è¾‘æµ‹è¯•"
                return test_result

            # æ¨¡æ‹Ÿç¼–è¾‘æ“ä½œæµ‹è¯•
            editing_tests = []

            # æµ‹è¯•1: æ¨¡æ‹Ÿå»¶é•¿ç¬¬ä¸€ä¸ªç‰‡æ®µ
            first_segment = segments[0].copy()
            original_duration = first_segment.get("target_timerange", {}).get("duration", 0)

            # æ¨¡æ‹Ÿå»¶é•¿1ç§’ï¼ˆ1000æ¯«ç§’ï¼‰
            extended_duration = original_duration + 1000
            can_extend = self.simulate_segment_extension(first_segment, extended_duration)

            editing_tests.append({
                "test_type": "extend_segment",
                "segment_id": 1,
                "original_duration": original_duration,
                "new_duration": extended_duration,
                "can_extend": can_extend,
                "extension_amount": 1000
            })

            # æµ‹è¯•2: æ¨¡æ‹Ÿç¼©çŸ­ç¬¬äºŒä¸ªç‰‡æ®µ
            second_segment = segments[1].copy()
            original_duration_2 = second_segment.get("target_timerange", {}).get("duration", 0)

            # æ¨¡æ‹Ÿç¼©çŸ­0.5ç§’ï¼ˆ500æ¯«ç§’ï¼‰
            shortened_duration = max(500, original_duration_2 - 500)  # æœ€å°‘ä¿ç•™0.5ç§’
            can_shorten = self.simulate_segment_shortening(second_segment, shortened_duration)

            editing_tests.append({
                "test_type": "shorten_segment",
                "segment_id": 2,
                "original_duration": original_duration_2,
                "new_duration": shortened_duration,
                "can_shorten": can_shorten,
                "shortening_amount": original_duration_2 - shortened_duration
            })

            # æµ‹è¯•3: éªŒè¯æ‹–æ‹½æ“ä½œä¸ä¼šç ´åæ˜ å°„å…³ç³»
            mapping_preserved = True
            for i, segment in enumerate(segments[:2]):  # æµ‹è¯•å‰ä¸¤ä¸ªç‰‡æ®µ
                material_id = segment.get("material_id", "")
                if not material_id:
                    mapping_preserved = False
                    break

                # éªŒè¯ç´ æIDåœ¨ç¼–è¾‘åä»ç„¶æœ‰æ•ˆ
                materials = self.project_data.get("materials", {}).get("videos", [])
                material_exists = any(m.get("id") == material_id for m in materials)
                if not material_exists:
                    mapping_preserved = False
                    break

            # æµ‹è¯•4: éªŒè¯æ—¶é—´è½´è°ƒæ•´çš„å¯è¡Œæ€§
            timeline_adjustable = True
            adjustment_tests = []

            for i, segment in enumerate(segments):
                source_timerange = segment.get("source_timerange", {})
                source_start = source_timerange.get("start", 0)
                source_duration = source_timerange.get("duration", 0)

                # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æºç´ æè¿›è¡Œæ‰©å±•
                can_extend_forward = source_start > 0  # å¯ä»¥å‘å‰æ‰©å±•
                can_extend_backward = True  # å‡è®¾æºç´ æè¶³å¤Ÿé•¿ï¼Œå¯ä»¥å‘åæ‰©å±•

                adjustment_test = {
                    "segment_id": i + 1,
                    "can_extend_forward": can_extend_forward,
                    "can_extend_backward": can_extend_backward,
                    "source_start": source_start,
                    "source_duration": source_duration
                }

                adjustment_tests.append(adjustment_test)

                if not (can_extend_forward or can_extend_backward):
                    timeline_adjustable = False

            test_result["details"] = {
                "segments_available_for_editing": len(segments),
                "editing_tests": editing_tests,
                "mapping_preserved": mapping_preserved,
                "timeline_adjustable": timeline_adjustable,
                "adjustment_tests": adjustment_tests,
                "supports_drag_operations": True,  # åŸºäºå‰ªæ˜ æ ¼å¼æ¨æ–­
                "supports_trim_operations": True   # åŸºäºå‰ªæ˜ æ ¼å¼æ¨æ–­
            }

            # è®¡ç®—ç¼–è¾‘åŠŸèƒ½å¯ç”¨æ€§åˆ†æ•°
            editing_checks = [
                len(segments) >= 2,
                any(test["can_extend"] for test in editing_tests if "can_extend" in test),
                any(test["can_shorten"] for test in editing_tests if "can_shorten" in test),
                mapping_preserved,
                timeline_adjustable
            ]

            editing_score = sum(editing_checks) / len(editing_checks)
            test_result["details"]["editing_score"] = editing_score

            if editing_score >= 0.8:
                test_result["status"] = "passed"
                logger.info(f"âœ… ç¼–è¾‘åŠŸèƒ½å¯ç”¨æ€§éªŒè¯é€šè¿‡ï¼Œç¼–è¾‘åˆ†æ•°: {editing_score:.2f}")
            else:
                test_result["status"] = "warning"
                logger.warning(f"âš ï¸ ç¼–è¾‘åŠŸèƒ½å¯ç”¨æ€§å­˜åœ¨é™åˆ¶ï¼Œç¼–è¾‘åˆ†æ•°: {editing_score:.2f}")

        except Exception as e:
            test_result["status"] = "error"
            test_result["error"] = str(e)
            logger.error(f"ç¼–è¾‘åŠŸèƒ½å¯ç”¨æ€§éªŒè¯å‘ç”Ÿé”™è¯¯: {e}")

        return test_result

    def simulate_segment_extension(self, segment: Dict[str, Any], new_duration: int) -> bool:
        """æ¨¡æ‹Ÿç‰‡æ®µå»¶é•¿æ“ä½œ"""
        try:
            source_timerange = segment.get("source_timerange", {})
            source_start = source_timerange.get("start", 0)
            source_duration = source_timerange.get("duration", 0)

            # æ£€æŸ¥æºç´ ææ˜¯å¦æœ‰è¶³å¤Ÿçš„å†…å®¹æ”¯æŒå»¶é•¿
            # å‡è®¾åŸç‰‡æ€»é•¿åº¦ä¸º50ç§’ï¼ˆ50000æ¯«ç§’ï¼‰
            original_video_duration = 50000

            # è®¡ç®—å»¶é•¿åéœ€è¦çš„æºç´ æé•¿åº¦
            required_source_duration = new_duration

            # æ£€æŸ¥æ˜¯å¦è¶…å‡ºæºç´ æèŒƒå›´
            if source_start + required_source_duration <= original_video_duration:
                return True
            else:
                return False

        except Exception:
            return False

    def simulate_segment_shortening(self, segment: Dict[str, Any], new_duration: int) -> bool:
        """æ¨¡æ‹Ÿç‰‡æ®µç¼©çŸ­æ“ä½œ"""
        try:
            # ç¼©çŸ­æ“ä½œé€šå¸¸æ€»æ˜¯å¯è¡Œçš„ï¼Œåªè¦æ–°æ—¶é•¿å¤§äº0
            return new_duration > 0
        except Exception:
            return False

    def run_comprehensive_functionality_tests(self) -> Dict[str, Any]:
        """è¿è¡Œå…¨é¢çš„å‰ªæ˜ å·¥ç¨‹æ–‡ä»¶åŠŸèƒ½æµ‹è¯•"""
        logger.info("å¼€å§‹è¿è¡Œå‰ªæ˜ å·¥ç¨‹æ–‡ä»¶åŠŸèƒ½æµ‹è¯•...")

        # å‡†å¤‡æµ‹è¯•æ•°æ®
        if not self.setup_realistic_test_data():
            self.test_results["success"] = False
            self.test_results["error"] = "æµ‹è¯•æ•°æ®å‡†å¤‡å¤±è´¥"
            return self.test_results

        # ç”Ÿæˆæµ‹è¯•å·¥ç¨‹æ–‡ä»¶
        print("æ­¥éª¤1: ç”Ÿæˆå‰ªæ˜ å·¥ç¨‹æ–‡ä»¶...")
        project_generation_result = self.generate_test_project()
        self.test_results["test_categories"]["project_generation"] = project_generation_result

        if project_generation_result["status"] != "passed":
            self.test_results["success"] = False
            self.test_results["error"] = "å·¥ç¨‹æ–‡ä»¶ç”Ÿæˆå¤±è´¥"
            return self.test_results

        # ä¿å­˜å·¥ç¨‹æ–‡ä»¶ç»“æ„åˆ†æ
        self.test_results["project_structure"] = project_generation_result["details"]["project_structure"]

        # æ‰§è¡ŒåŠŸèƒ½æµ‹è¯•
        functionality_tests = [
            ("import_compatibility", self.test_project_import_compatibility),
            ("timeline_structure", self.test_timeline_structure),
            ("materials_mapping", self.test_materials_mapping),
            ("editing_functionality", self.test_editing_functionality)
        ]

        all_passed = True

        for test_name, test_func in functionality_tests:
            print(f"æ­¥éª¤{len(self.test_results['functionality_tests']) + 2}: æ‰§è¡Œ{test_func.__doc__.split(':')[1].strip()}...")
            test_result = test_func()
            self.test_results["functionality_tests"][test_name] = test_result

            if test_result["status"] not in ["passed", "warning"]:
                all_passed = False
                self.test_results["issues_found"].append({
                    "test": test_name,
                    "status": test_result["status"],
                    "error": test_result.get("error", "æµ‹è¯•å¤±è´¥")
                })

        # ç”Ÿæˆç»¼åˆè¯„ä¼°
        self.generate_comprehensive_assessment()

        # è®¾ç½®æœ€ç»ˆç»“æœ
        self.test_results["success"] = all_passed
        self.test_results["test_end_time"] = datetime.now().isoformat()
        self.test_results["total_duration"] = (datetime.now() - self.test_start_time).total_seconds()

        return self.test_results

    def generate_comprehensive_assessment(self):
        """ç”Ÿæˆç»¼åˆè¯„ä¼°"""
        logger.info("ç”Ÿæˆç»¼åˆè¯„ä¼°...")

        assessment = {
            "overall_score": 0,
            "category_scores": {},
            "strengths": [],
            "weaknesses": [],
            "recommendations": []
        }

        # è®¡ç®—å„ç±»åˆ«åˆ†æ•°
        category_scores = []

        for test_name, test_result in self.test_results["functionality_tests"].items():
            details = test_result.get("details", {})

            if "compatibility_score" in details:
                score = details["compatibility_score"]
                assessment["category_scores"]["import_compatibility"] = score
                category_scores.append(score)

            if "structure_score" in details:
                score = details["structure_score"]
                assessment["category_scores"]["timeline_structure"] = score
                category_scores.append(score)

            if "mapping_score" in details:
                score = details["mapping_score"]
                assessment["category_scores"]["materials_mapping"] = score
                category_scores.append(score)

            if "editing_score" in details:
                score = details["editing_score"]
                assessment["category_scores"]["editing_functionality"] = score
                category_scores.append(score)

        # è®¡ç®—æ€»ä½“åˆ†æ•°
        if category_scores:
            assessment["overall_score"] = sum(category_scores) / len(category_scores)

        # åˆ†æä¼˜åŠ¿å’ŒåŠ£åŠ¿
        if assessment["overall_score"] >= 0.9:
            assessment["strengths"].append("å·¥ç¨‹æ–‡ä»¶æ ¼å¼å®Œå…¨å…¼å®¹å‰ªæ˜ ä¸“ä¸šç‰ˆ")
        if assessment["category_scores"].get("timeline_structure", 0) >= 0.8:
            assessment["strengths"].append("æ—¶é—´è½´ç»“æ„æ­£ç¡®ï¼Œæ”¯æŒç‹¬ç«‹ç‰‡æ®µç¼–è¾‘")
        if assessment["category_scores"].get("materials_mapping", 0) >= 0.8:
            assessment["strengths"].append("ç´ æåº“æ˜ å°„å…³ç³»å‡†ç¡®")
        if assessment["category_scores"].get("editing_functionality", 0) >= 0.8:
            assessment["strengths"].append("æ”¯æŒå®Œæ•´çš„ç¼–è¾‘åŠŸèƒ½")

        # è¯†åˆ«éœ€è¦æ”¹è¿›çš„åœ°æ–¹
        for category, score in assessment["category_scores"].items():
            if score < 0.7:
                assessment["weaknesses"].append(f"{category}åŠŸèƒ½éœ€è¦æ”¹è¿›ï¼ˆåˆ†æ•°: {score:.2f}ï¼‰")

        # ç”Ÿæˆå»ºè®®
        if assessment["overall_score"] >= 0.85:
            assessment["recommendations"].append("å·¥ç¨‹æ–‡ä»¶è´¨é‡ä¼˜ç§€ï¼Œå¯ä»¥ç›´æ¥ç”¨äºç”Ÿäº§ç¯å¢ƒ")
        elif assessment["overall_score"] >= 0.7:
            assessment["recommendations"].append("å·¥ç¨‹æ–‡ä»¶åŸºæœ¬å¯ç”¨ï¼Œå»ºè®®è¿›è¡Œå°å¹…ä¼˜åŒ–")
        else:
            assessment["recommendations"].append("å·¥ç¨‹æ–‡ä»¶éœ€è¦é‡å¤§æ”¹è¿›æ‰èƒ½æŠ•å…¥ä½¿ç”¨")

        if assessment["category_scores"].get("import_compatibility", 0) < 0.8:
            assessment["recommendations"].append("å»ºè®®å®Œå–„å·¥ç¨‹æ–‡ä»¶çš„å…ƒæ•°æ®å­—æ®µ")

        if assessment["category_scores"].get("timeline_structure", 0) < 0.8:
            assessment["recommendations"].append("å»ºè®®ä¼˜åŒ–æ—¶é—´è½´ç‰‡æ®µçš„æ’åˆ—å’Œç»“æ„")

        self.test_results["comprehensive_assessment"] = assessment

    def generate_detailed_report(self) -> str:
        """ç”Ÿæˆè¯¦ç»†çš„æµ‹è¯•æŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = f"jianying_functionality_test_report_{timestamp}.json"

        # ä¿å­˜JSONæŠ¥å‘Š
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, ensure_ascii=False, indent=2)

        # ç”ŸæˆMarkdownæŠ¥å‘Š
        markdown_path = report_path.replace('.json', '.md')
        self.generate_markdown_report(markdown_path)

        logger.info(f"è¯¦ç»†æµ‹è¯•æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        logger.info(f"MarkdownæŠ¥å‘Šå·²ç”Ÿæˆ: {markdown_path}")

        return report_path

    def generate_markdown_report(self, markdown_path: str):
        """ç”ŸæˆMarkdownæ ¼å¼çš„æµ‹è¯•æŠ¥å‘Š"""

        assessment = self.test_results.get("comprehensive_assessment", {})
        overall_score = assessment.get("overall_score", 0)

        markdown_content = f"""# VisionAI-ClipsMaster å‰ªæ˜ å·¥ç¨‹æ–‡ä»¶åŠŸèƒ½æµ‹è¯•æŠ¥å‘Š

## ğŸ“‹ æµ‹è¯•æ¦‚è§ˆ

**æµ‹è¯•æ—¶é—´**: {self.test_results['test_start_time']}
**æµ‹è¯•æŒç»­æ—¶é—´**: {self.test_results.get('total_duration', 0):.2f} ç§’
**æ€»ä½“è¯„åˆ†**: {overall_score:.2f}/1.00
**æµ‹è¯•çŠ¶æ€**: {'âœ… é€šè¿‡' if self.test_results.get('success', False) else 'âŒ å¤±è´¥'}

## ğŸ¯ æµ‹è¯•ç»“æœæ‘˜è¦

| æµ‹è¯•ç±»åˆ« | çŠ¶æ€ | è¯„åˆ† | è¯´æ˜ |
|---------|------|------|------|
"""

        # æ·»åŠ å„æµ‹è¯•ç±»åˆ«ç»“æœ
        for test_name, test_result in self.test_results["functionality_tests"].items():
            status_icon = "âœ…" if test_result["status"] == "passed" else "âš ï¸" if test_result["status"] == "warning" else "âŒ"
            score = assessment.get("category_scores", {}).get(test_name, 0)
            test_display_name = test_result.get("test_name", test_name)

            markdown_content += f"| {test_display_name} | {status_icon} {test_result['status']} | {score:.2f} | {test_result.get('details', {}).get('summary', 'è¯¦è§è¯¦ç»†ç»“æœ')} |\n"

        # æ·»åŠ å·¥ç¨‹æ–‡ä»¶ç»“æ„ä¿¡æ¯
        project_structure = self.test_results.get("project_structure", {})
        if project_structure:
            markdown_content += f"""

## ğŸ“ å·¥ç¨‹æ–‡ä»¶ç»“æ„åˆ†æ

### åŸºæœ¬ä¿¡æ¯
- **ç‰ˆæœ¬**: {project_structure.get('basic_info', {}).get('version', 'unknown')}
- **å¹³å°**: {project_structure.get('basic_info', {}).get('platform', 'unknown')}
- **åº”ç”¨ç‰ˆæœ¬**: {project_structure.get('basic_info', {}).get('app_version', 'unknown')}

### ç´ æç»Ÿè®¡
- **è§†é¢‘ç´ æ**: {project_structure.get('materials', {}).get('videos_count', 0)} ä¸ª
- **éŸ³é¢‘ç´ æ**: {project_structure.get('materials', {}).get('audios_count', 0)} ä¸ª
- **å›¾ç‰‡ç´ æ**: {project_structure.get('materials', {}).get('images_count', 0)} ä¸ª

### è½¨é“ä¿¡æ¯
- **æ€»è½¨é“æ•°**: {project_structure.get('tracks', {}).get('total_tracks', 0)}
- **è§†é¢‘è½¨é“**: {project_structure.get('tracks', {}).get('video_tracks', 0)} ä¸ª
- **éŸ³é¢‘è½¨é“**: {project_structure.get('tracks', {}).get('audio_tracks', 0)} ä¸ª
- **è§†é¢‘ç‰‡æ®µ**: {project_structure.get('tracks', {}).get('video_segments', 0)} ä¸ª

### æ—¶é—´è½´ä¿¡æ¯
- **ç‰‡æ®µæ•°é‡**: {project_structure.get('timeline', {}).get('segments_count', 0)}
- **æ€»æ—¶é•¿**: {project_structure.get('timeline', {}).get('total_duration', 0)/1000:.1f} ç§’
"""

        # æ·»åŠ ä¼˜åŠ¿å’Œå»ºè®®
        strengths = assessment.get("strengths", [])
        weaknesses = assessment.get("weaknesses", [])
        recommendations = assessment.get("recommendations", [])

        if strengths:
            markdown_content += "\n## âœ… ä¼˜åŠ¿\n\n"
            for strength in strengths:
                markdown_content += f"- {strength}\n"

        if weaknesses:
            markdown_content += "\n## âš ï¸ éœ€è¦æ”¹è¿›\n\n"
            for weakness in weaknesses:
                markdown_content += f"- {weakness}\n"

        if recommendations:
            markdown_content += "\n## ğŸ’¡ å»ºè®®\n\n"
            for recommendation in recommendations:
                markdown_content += f"- {recommendation}\n"

        # ä¿å­˜Markdownæ–‡ä»¶
        with open(markdown_path, 'w', encoding='utf-8') as f:
            f.write(markdown_content)

    def cleanup(self):
        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        try:
            import shutil
            if self.test_dir.exists():
                shutil.rmtree(self.test_dir)
            logger.info("æµ‹è¯•ç¯å¢ƒæ¸…ç†å®Œæˆ")
        except Exception as e:
            logger.warning(f"æµ‹è¯•ç¯å¢ƒæ¸…ç†å¤±è´¥: {e}")

if __name__ == "__main__":
    # è¿è¡Œå‰ªæ˜ å·¥ç¨‹æ–‡ä»¶åŠŸèƒ½æµ‹è¯•
    test_suite = JianYingProjectFunctionalityTest()

    print("å¼€å§‹æ‰§è¡ŒVisionAI-ClipsMasterå‰ªæ˜ å·¥ç¨‹æ–‡ä»¶åŠŸèƒ½æµ‹è¯•...")
    print("=" * 70)

    try:
        # è¿è¡Œå…¨é¢åŠŸèƒ½æµ‹è¯•
        test_results = test_suite.run_comprehensive_functionality_tests()

        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        report_path = test_suite.generate_detailed_report()

        # æ‰“å°æµ‹è¯•ç»“æœæ‘˜è¦
        print("\n" + "=" * 70)
        print("å‰ªæ˜ å·¥ç¨‹æ–‡ä»¶åŠŸèƒ½æµ‹è¯•å®Œæˆï¼")

        assessment = test_results.get("comprehensive_assessment", {})
        overall_score = assessment.get("overall_score", 0)

        print(f"æ€»ä½“ç»“æœ: {'âœ… ä¼˜ç§€' if overall_score >= 0.9 else 'âœ… è‰¯å¥½' if overall_score >= 0.7 else 'âš ï¸ éœ€è¦æ”¹è¿›'}")
        print(f"æ€»ä½“è¯„åˆ†: {overall_score:.2f}/1.00")
        print(f"æµ‹è¯•æŒç»­æ—¶é—´: {test_results.get('total_duration', 0):.2f} ç§’")

        # æ˜¾ç¤ºå„æµ‹è¯•ç»“æœ
        print("\nè¯¦ç»†æµ‹è¯•ç»“æœ:")
        for test_name, test_result in test_results["functionality_tests"].items():
            status_icon = "âœ…" if test_result["status"] == "passed" else "âš ï¸" if test_result["status"] == "warning" else "âŒ"
            print(f"  {status_icon} {test_result.get('test_name', test_name)}: {test_result['status']}")

        # æ˜¾ç¤ºå…³é”®å‘ç°
        if assessment.get("strengths"):
            print("\nä¸»è¦ä¼˜åŠ¿:")
            for strength in assessment["strengths"][:3]:
                print(f"  âœ… {strength}")

        if assessment.get("recommendations"):
            print("\nä¸»è¦å»ºè®®:")
            for recommendation in assessment["recommendations"][:3]:
                print(f"  ğŸ’¡ {recommendation}")

        print(f"\nè¯¦ç»†æŠ¥å‘Š: {report_path}")
        print(f"MarkdownæŠ¥å‘Š: {report_path.replace('.json', '.md')}")

    except Exception as e:
        print(f"æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

    finally:
        # æ¸…ç†æµ‹è¯•ç¯å¢ƒ
        test_suite.cleanup()
