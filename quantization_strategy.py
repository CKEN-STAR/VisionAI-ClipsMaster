#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
VisionAI-ClipsMaster æ¨¡å‹é‡åŒ–ç­–ç•¥
å®ç°å¤šçº§é‡åŒ–å’Œæ™ºèƒ½é€‰æ‹©
"""

import os
import json
import psutil
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass

@dataclass
class QuantizationConfig:
    """é‡åŒ–é…ç½®ç±»"""
    name: str
    level: str
    size_mb: int
    memory_required_mb: int
    quality_score: float
    description: str

class QuantizationManager:
    """é‡åŒ–ç®¡ç†å™¨"""
    
    def __init__(self):
        self.configs = {
            "aggressive": QuantizationConfig(
                name="Q2_K",
                level="aggressive",
                size_mb=1800,
                memory_required_mb=2200,
                quality_score=0.75,
                description="æè‡´å‹ç¼©ï¼Œé€‚åˆ2-3GBå†…å­˜è®¾å¤‡"
            ),
            "balanced": QuantizationConfig(
                name="Q4_K_M",
                level="balanced",
                size_mb=2600,
                memory_required_mb=3200,
                quality_score=0.88,
                description="å¹³è¡¡é…ç½®ï¼Œæ¨è4GBå†…å­˜è®¾å¤‡"
            ),
            "quality": QuantizationConfig(
                name="Q5_K",
                level="quality",
                size_mb=3800,
                memory_required_mb=4500,
                quality_score=0.94,
                description="é«˜è´¨é‡ï¼Œé€‚åˆ6GB+å†…å­˜è®¾å¤‡"
            ),
            "original": QuantizationConfig(
                name="FP16",
                level="original",
                size_mb=14400,
                memory_required_mb=16000,
                quality_score=1.0,
                description="åŸå§‹ç²¾åº¦ï¼Œéœ€è¦16GB+å†…å­˜"
            )
        }
    
    def detect_optimal_config(self) -> str:
        """æ£€æµ‹æœ€ä½³é‡åŒ–é…ç½®"""
        available_memory = psutil.virtual_memory().total // (1024**3)  # GB

        if available_memory >= 16:
            return "quality"
        elif available_memory >= 6:
            return "balanced"
        elif available_memory >= 4:
            return "balanced"
        else:
            return "aggressive"
    
    def get_config(self, level: str) -> QuantizationConfig:
        """è·å–é‡åŒ–é…ç½®"""
        return self.configs.get(level, self.configs["balanced"])
    
    def estimate_download_size(self, models: List[str], level: str) -> int:
        """ä¼°ç®—ä¸‹è½½å¤§å°"""
        config = self.get_config(level)
        return len(models) * config.size_mb
    
    def generate_download_plan(self, 
                             target_languages: List[str],
                             memory_limit_gb: int = None) -> Dict:
        """ç”Ÿæˆä¸‹è½½è®¡åˆ’"""
        if memory_limit_gb is None:
            memory_limit_gb = psutil.virtual_memory().total // (1024**3)
        
        # é€‰æ‹©æœ€ä½³é‡åŒ–çº§åˆ«
        optimal_level = self.detect_optimal_config()
        config = self.get_config(optimal_level)
        
        plan = {
            "quantization_level": optimal_level,
            "config": config.__dict__,
            "models": [],
            "total_size_mb": 0,
            "estimated_memory_mb": 0
        }
        
        # æ·»åŠ æ¨¡å‹åˆ°è®¡åˆ’
        for lang in target_languages:
            model_info = {
                "language": lang,
                "model_name": f"{'qwen' if lang == 'zh' else 'mistral'}-{config.name}",
                "size_mb": config.size_mb,
                "memory_required_mb": config.memory_required_mb,
                "download_url": self._get_download_url(lang, config.name)
            }
            plan["models"].append(model_info)
            plan["total_size_mb"] += config.size_mb
            plan["estimated_memory_mb"] += config.memory_required_mb
        
        return plan
    
    def _get_download_url(self, language: str, quantization: str) -> str:
        """è·å–ä¸‹è½½URL"""
        base_urls = {
            "zh": "https://modelscope.cn/models/qwen/Qwen2.5-7B-Instruct-GGUF/resolve/main",
            "en": "https://huggingface.co/microsoft/DialoGPT-medium/resolve/main"
        }
        
        filename = f"model-{quantization.lower()}.gguf"
        return f"{base_urls[language]}/{filename}"

class CompressionManager:
    """å‹ç¼©ç®¡ç†å™¨"""
    
    @staticmethod
    def compress_directory(source_dir: Path, 
                          target_file: Path,
                          compression_level: int = 6) -> bool:
        """å‹ç¼©ç›®å½•"""
        try:
            import zipfile
            
            with zipfile.ZipFile(target_file, 'w', zipfile.ZIP_DEFLATED, 
                               compresslevel=compression_level) as zipf:
                for file_path in source_dir.rglob('*'):
                    if file_path.is_file():
                        arcname = file_path.relative_to(source_dir)
                        zipf.write(file_path, arcname)
            return True
        except Exception as e:
            print(f"å‹ç¼©å¤±è´¥: {e}")
            return False
    
    @staticmethod
    def estimate_compression_ratio(file_types: List[str]) -> float:
        """ä¼°ç®—å‹ç¼©æ¯”"""
        ratios = {
            '.py': 0.3,      # Pythonä»£ç å‹ç¼©æ¯”å¾ˆé«˜
            '.json': 0.2,    # JSONå‹ç¼©æ¯”å¾ˆé«˜
            '.yaml': 0.25,   # YAMLå‹ç¼©æ¯”é«˜
            '.md': 0.3,      # Markdownå‹ç¼©æ¯”é«˜
            '.txt': 0.3,     # æ–‡æœ¬å‹ç¼©æ¯”é«˜
            '.bin': 0.9,     # äºŒè¿›åˆ¶æ–‡ä»¶å‹ç¼©æ¯”ä½
            '.gguf': 0.95,   # æ¨¡å‹æ–‡ä»¶å‹ç¼©æ¯”å¾ˆä½
            '.mp4': 0.98,    # è§†é¢‘æ–‡ä»¶å‡ ä¹ä¸å‹ç¼©
            '.dll': 0.8,     # åŠ¨æ€åº“ä¸­ç­‰å‹ç¼©æ¯”
            '.exe': 0.7      # å¯æ‰§è¡Œæ–‡ä»¶ä¸­ç­‰å‹ç¼©æ¯”
        }
        
        if not file_types:
            return 0.6  # é»˜è®¤å‹ç¼©æ¯”
        
        avg_ratio = sum(ratios.get(ext, 0.6) for ext in file_types) / len(file_types)
        return avg_ratio

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºé‡åŒ–ç­–ç•¥"""
    manager = QuantizationManager()
    
    print("ğŸ” VisionAI-ClipsMaster é‡åŒ–ç­–ç•¥åˆ†æ")
    print("=" * 60)
    
    # æ£€æµ‹ç³»ç»Ÿé…ç½®
    memory_gb = psutil.virtual_memory().total // (1024**3)
    optimal_level = manager.detect_optimal_config()
    
    print(f"ğŸ’¾ ç³»ç»Ÿå†…å­˜: {memory_gb} GB")
    print(f"ğŸ¯ æ¨èé‡åŒ–çº§åˆ«: {optimal_level}")
    print()
    
    # æ˜¾ç¤ºæ‰€æœ‰é…ç½®é€‰é¡¹
    print("ğŸ“Š å¯ç”¨é‡åŒ–é…ç½®:")
    for level, config in manager.configs.items():
        marker = "ğŸ‘‰" if level == optimal_level else "  "
        print(f"{marker} {level:12} | {config.name:8} | "
              f"{config.size_mb:5}MB | è´¨é‡:{config.quality_score:.2f} | "
              f"{config.description}")
    print()
    
    # ç”Ÿæˆä¸‹è½½è®¡åˆ’
    plan = manager.generate_download_plan(["zh", "en"])
    print("ğŸ“‹ æ¨èä¸‹è½½è®¡åˆ’:")
    print(f"  é‡åŒ–çº§åˆ«: {plan['quantization_level']}")
    print(f"  æ€»å¤§å°: {plan['total_size_mb']} MB")
    print(f"  é¢„ä¼°å†…å­˜: {plan['estimated_memory_mb']} MB")
    print()
    
    for model in plan["models"]:
        print(f"  ğŸ“¦ {model['language'].upper()}æ¨¡å‹: {model['model_name']} "
              f"({model['size_mb']}MB)")

if __name__ == "__main__":
    main()
