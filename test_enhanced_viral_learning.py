#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æµ‹è¯•å¢å¼ºç‰ˆçˆ†æ¬¾è½¬æ¢å­¦ä¹ ç®—æ³•
ä½¿ç”¨æ–°çš„å¤šç»´åº¦è¯„ä¼°å¼•æ“
"""

import time
from src.training.zh_trainer import ZhTrainer
from src.core.viral_evaluation_engine import ViralEvaluationEngine

def test_enhanced_viral_learning():
    """æµ‹è¯•å¢å¼ºç‰ˆçˆ†æ¬¾è½¬æ¢å­¦ä¹ åŠŸèƒ½"""
    
    print('=== å¢å¼ºç‰ˆçˆ†æ¬¾è½¬æ¢å­¦ä¹ ç®—æ³•æµ‹è¯• ===')
    
    # åˆå§‹åŒ–è®­ç»ƒå™¨å’Œè¯„ä¼°å¼•æ“
    trainer = ZhTrainer(use_gpu=False)
    evaluation_engine = ViralEvaluationEngine()
    
    print(f'è®­ç»ƒå™¨è¯„ä¼°å¼•æ“çŠ¶æ€: {"å·²åŠ è½½" if trainer.evaluation_engine else "æœªåŠ è½½"}')
    
    # æµ‹è¯•æ–‡æœ¬é›†åˆ
    test_texts = [
        "å°æ˜åœ¨å…¬å›­é‡Œæ•£æ­¥ï¼Œçœ‹åˆ°äº†ä¸€åªå°çŒ«ã€‚",
        "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé˜³å…‰æ˜åªšã€‚",
        "ä»–é‡åˆ°äº†ä¸€ä¸ªç¥ç§˜çš„è€äººï¼Œè€äººç»™äº†ä»–ä¸€ä¸ªç›’å­ã€‚",
        "è¿™ä¸ªæ•…äº‹å‘ç”Ÿåœ¨ä¸€ä¸ªæ™®é€šçš„ä¸‹åˆã€‚",
        "æœ€ç»ˆï¼Œä¸€åˆ‡éƒ½æ”¹å˜äº†ã€‚"
    ]
    
    print('\n1. å­¦ä¹ å‰è½¬æ¢æ•ˆæœæµ‹è¯•')
    print('-' * 50)
    
    before_results = []
    for i, text in enumerate(test_texts):
        result = trainer.quick_inference_test(text)
        before_results.append(result)
        
        # ä½¿ç”¨è¯„ä¼°å¼•æ“è¯„ä¼°
        if evaluation_engine:
            eval_result = evaluation_engine.evaluate_transformation(text, result)
            print(f'æ–‡æœ¬ {i+1}: {text}')
            print(f'è½¬æ¢å: {result}')
            print(f'è¯„ä¼°å¾—åˆ†: {eval_result.overall_score:.3f}')
            print(f'æ”¹è¿›æ£€æµ‹: {"âœ“" if eval_result.improvement_detected else "âœ—"}')
            print(f'ç½®ä¿¡åº¦: {eval_result.confidence:.3f}')
            print(f'ç»´åº¦å¾—åˆ†: {eval_result.dimension_scores}')
            print()
    
    print('\n2. æ‰§è¡Œæ·±åº¦å­¦ä¹ è¿‡ç¨‹')
    print('-' * 50)
    
    learning_start = time.time()
    learning_success = trainer.quick_training_test('data/training/zh')
    learning_time = time.time() - learning_start
    
    print(f'å­¦ä¹ ç»“æœ: {"æˆåŠŸ" if learning_success else "å¤±è´¥"}')
    print(f'å­¦ä¹ è€—æ—¶: {learning_time:.3f}ç§’')
    print(f'å­¦åˆ°çš„è½¬æ¢è§„åˆ™æ•°: {len(trainer.viral_patterns["transformation_rules"])}')
    print(f'å­¦ä¹ å†å²è®°å½•æ•°: {len(trainer.learning_history)}')
    
    print('\n3. å­¦ä¹ åè½¬æ¢æ•ˆæœæµ‹è¯•')
    print('-' * 50)
    
    after_results = []
    improvement_scores = []
    
    for i, text in enumerate(test_texts):
        result = trainer.quick_inference_test(text)
        after_results.append(result)
        
        # ä½¿ç”¨è¯„ä¼°å¼•æ“è¯„ä¼°
        if evaluation_engine:
            eval_result = evaluation_engine.evaluate_transformation(
                text, result, 
                learning_context={
                    "training_samples": len(trainer.learning_history),
                    "learning_success_rate": 1.0 if learning_success else 0.0
                }
            )
            improvement_scores.append(eval_result.overall_score)
            
            print(f'æ–‡æœ¬ {i+1}: {text}')
            print(f'è½¬æ¢å: {result}')
            print(f'è¯„ä¼°å¾—åˆ†: {eval_result.overall_score:.3f}')
            print(f'æ”¹è¿›æ£€æµ‹: {"âœ“" if eval_result.improvement_detected else "âœ—"}')
            print(f'ç½®ä¿¡åº¦: {eval_result.confidence:.3f}')
            print(f'æœ€å¼ºç»´åº¦: {eval_result.quality_metrics.get("top_dimension", "unknown")}')
            print(f'æ”¹è¿›å¼ºåº¦: {eval_result.quality_metrics.get("improvement_strength", "unknown")}')
            
            if eval_result.recommendations:
                print(f'å»ºè®®: {eval_result.recommendations[0]}')
            print()
    
    print('\n4. å¤šæ ·æ€§å’Œè´¨é‡åˆ†æ')
    print('-' * 50)
    
    # åˆ†æç»“æœå¤šæ ·æ€§
    before_unique = len(set(before_results))
    after_unique = len(set(after_results))
    
    print(f'å­¦ä¹ å‰ç»“æœå¤šæ ·æ€§: {before_unique}/{len(test_texts)} ({before_unique/len(test_texts)*100:.1f}%)')
    print(f'å­¦ä¹ åç»“æœå¤šæ ·æ€§: {after_unique}/{len(test_texts)} ({after_unique/len(test_texts)*100:.1f}%)')
    
    # åˆ†æè´¨é‡æ”¹è¿›
    if improvement_scores:
        avg_score = sum(improvement_scores) / len(improvement_scores)
        high_quality_count = sum(1 for score in improvement_scores if score >= 0.5)
        
        print(f'å¹³å‡è¯„ä¼°å¾—åˆ†: {avg_score:.3f}')
        print(f'é«˜è´¨é‡è½¬æ¢æ•°: {high_quality_count}/{len(improvement_scores)} ({high_quality_count/len(improvement_scores)*100:.1f}%)')
    
    print('\n5. å­¦ä¹ æ•ˆæœç»¼åˆè¯„ä¼°')
    print('-' * 50)
    
    # ç»¼åˆè¯„ä¼°å­¦ä¹ æ•ˆæœ
    learning_effectiveness = {
        "learning_success": learning_success,
        "rules_learned": len(trainer.viral_patterns["transformation_rules"]),
        "diversity_improvement": after_unique > before_unique,
        "quality_score": sum(improvement_scores) / len(improvement_scores) if improvement_scores else 0.0,
        "high_quality_rate": (sum(1 for score in improvement_scores if score >= 0.5) / len(improvement_scores)) if improvement_scores else 0.0
    }
    
    # è®¡ç®—æ€»ä½“æˆåŠŸç‡
    success_indicators = [
        learning_effectiveness["learning_success"],
        learning_effectiveness["rules_learned"] > 0,
        learning_effectiveness["quality_score"] >= 0.4,
        learning_effectiveness["high_quality_rate"] >= 0.6
    ]
    
    overall_success_rate = sum(success_indicators) / len(success_indicators)
    
    print(f'å­¦ä¹ æˆåŠŸ: {"âœ“" if learning_effectiveness["learning_success"] else "âœ—"}')
    print(f'è§„åˆ™å­¦ä¹ : {"âœ“" if learning_effectiveness["rules_learned"] > 0 else "âœ—"} ({learning_effectiveness["rules_learned"]}æ¡)')
    print(f'å¤šæ ·æ€§æ”¹è¿›: {"âœ“" if learning_effectiveness["diversity_improvement"] else "âœ—"}')
    print(f'è´¨é‡å¾—åˆ†: {learning_effectiveness["quality_score"]:.3f} {"âœ“" if learning_effectiveness["quality_score"] >= 0.4 else "âœ—"}')
    print(f'é«˜è´¨é‡ç‡: {learning_effectiveness["high_quality_rate"]:.1%} {"âœ“" if learning_effectiveness["high_quality_rate"] >= 0.6 else "âœ—"}')
    print(f'æ€»ä½“æˆåŠŸç‡: {overall_success_rate:.1%}')
    
    print('\n6. æ€§èƒ½åŸºå‡†æµ‹è¯•')
    print('-' * 50)
    
    # æ€§èƒ½æµ‹è¯•
    performance_results = trainer.benchmark_inference_performance(test_texts[:3])  # ä½¿ç”¨å‰3ä¸ªæ–‡æœ¬
    print(f'æ€§èƒ½åŸºå‡†æµ‹è¯•ç»“æœ:')
    print(f'  CPUå¹³å‡æ—¶é—´: {performance_results.get("avg_cpu_time", 0):.3f}ç§’')
    print(f'  GPUå¹³å‡æ—¶é—´: {performance_results.get("avg_gpu_time", 0):.3f}ç§’')
    print(f'  åŠ é€Ÿæ¯”: {performance_results.get("speedup", 0):.2f}x')
    
    print('\n=== å¢å¼ºç‰ˆçˆ†æ¬¾è½¬æ¢å­¦ä¹ ç®—æ³•æµ‹è¯•å®Œæˆ ===')
    
    return {
        "overall_success_rate": overall_success_rate,
        "learning_effectiveness": learning_effectiveness,
        "performance_results": performance_results,
        "evaluation_available": trainer.evaluation_engine is not None
    }

if __name__ == "__main__":
    result = test_enhanced_viral_learning()
    print(f'\nğŸ¯ æœ€ç»ˆæµ‹è¯•ç»“æœ: {result}')
    
    # åˆ¤æ–­æ˜¯å¦è¾¾åˆ°ç›®æ ‡
    target_success_rate = 0.9  # 90%ç›®æ ‡
    if result["overall_success_rate"] >= target_success_rate:
        print(f'ğŸ‰ æµ‹è¯•é€šè¿‡ï¼æˆåŠŸç‡ {result["overall_success_rate"]:.1%} è¾¾åˆ°ç›®æ ‡ {target_success_rate:.1%}')
    else:
        print(f'âš ï¸  æµ‹è¯•æœªå®Œå…¨é€šè¿‡ï¼ŒæˆåŠŸç‡ {result["overall_success_rate"]:.1%} æœªè¾¾åˆ°ç›®æ ‡ {target_success_rate:.1%}')
