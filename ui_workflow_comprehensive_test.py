#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
VisionAI-ClipsMaster UIå·¥ä½œæµç¨‹ç»¼åˆæµ‹è¯•
å®Œæ•´éªŒè¯è§†é¢‘å¤„ç†ç•Œé¢çš„æ‰€æœ‰åŠŸèƒ½å’Œæ€§èƒ½æŒ‡æ ‡
"""

import os
import sys
import time
import json
import psutil
import threading
from pathlib import Path
from typing import Dict, Any, List, Optional
from datetime import datetime
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ui_workflow_test.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class UIWorkflowTester:
    """UIå·¥ä½œæµç¨‹æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.project_root = Path('.')
        self.test_results = {
            "start_time": datetime.now().isoformat(),
            "test_phases": {},
            "performance_metrics": {},
            "issues_found": [],
            "overall_status": "RUNNING"
        }
        self.memory_monitor = MemoryMonitor()
        self.test_data_dir = self.project_root / 'test_data' / 'ui_workflow'
        self.test_data_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        self._create_test_data()
        
    def _create_test_data(self):
        """åˆ›å»ºæµ‹è¯•ç”¨çš„SRTå’Œè§†é¢‘æ–‡ä»¶"""
        # åˆ›å»ºä¸­æ–‡æµ‹è¯•SRT
        chinese_srt = self.test_data_dir / 'chinese_test.srt'
        with open(chinese_srt, 'w', encoding='utf-8') as f:
            f.write("""1
00:00:00,000 --> 00:00:03,000
ä»Šå¤©æ˜¯ä¸ªå¥½æ—¥å­ï¼Œé˜³å…‰æ˜åªš

2
00:00:03,000 --> 00:00:06,000
å°æ˜èµ°åœ¨å›å®¶çš„è·¯ä¸Š

3
00:00:06,000 --> 00:00:09,000
çªç„¶é‡åˆ°äº†ä»–çš„è€æœ‹å‹

4
00:00:09,000 --> 00:00:12,000
ä¸¤äººå¼€å¿ƒåœ°èŠäº†èµ·æ¥

5
00:00:12,000 --> 00:00:15,000
è¿™çœŸæ˜¯ä¸€ä¸ªç¾å¥½çš„ç›¸é‡
""")
        
        # åˆ›å»ºè‹±æ–‡æµ‹è¯•SRT
        english_srt = self.test_data_dir / 'english_test.srt'
        with open(english_srt, 'w', encoding='utf-8') as f:
            f.write("""1
00:00:00,000 --> 00:00:03,000
It was a beautiful sunny day

2
00:00:03,000 --> 00:00:06,000
John was walking home from work

3
00:00:06,000 --> 00:00:09,000
Suddenly he met his old friend

4
00:00:09,000 --> 00:00:12,000
They had a wonderful conversation

5
00:00:12,000 --> 00:00:15,000
It was truly a great encounter
""")
        
        # åˆ›å»ºæŸåçš„SRTæ–‡ä»¶ç”¨äºé”™è¯¯æµ‹è¯•
        corrupted_srt = self.test_data_dir / 'corrupted_test.srt'
        with open(corrupted_srt, 'w', encoding='utf-8') as f:
            f.write("è¿™æ˜¯ä¸€ä¸ªæŸåçš„SRTæ–‡ä»¶\næ²¡æœ‰æ­£ç¡®çš„æ—¶é—´æ ¼å¼")
        
        logger.info(f"æµ‹è¯•æ•°æ®å·²åˆ›å»ºåœ¨: {self.test_data_dir}")
    
    def test_phase_1_ui_startup_initialization(self) -> Dict[str, Any]:
        """æµ‹è¯•é˜¶æ®µ1: ç•Œé¢å¯åŠ¨ä¸åˆå§‹åŒ–"""
        phase_name = "ui_startup_initialization"
        logger.info(f"å¼€å§‹æµ‹è¯•é˜¶æ®µ1: {phase_name}")
        
        test_result = {
            "phase": phase_name,
            "description": "éªŒè¯UIç•Œé¢å¯åŠ¨æ—¶é—´ã€ç»„ä»¶åŠ è½½å’Œå†…å­˜ä½¿ç”¨",
            "start_time": time.time(),
            "status": "RUNNING",
            "metrics": {},
            "issues": []
        }
        
        try:
            # å¯åŠ¨å†…å­˜ç›‘æ§
            self.memory_monitor.start_monitoring()
            
            # æµ‹è¯•UIå¯åŠ¨æ—¶é—´
            startup_start = time.time()
            
            # æ¨¡æ‹ŸUIå¯åŠ¨è¿‡ç¨‹ï¼ˆä¸å®é™…å¯åŠ¨GUIï¼Œé¿å…é˜»å¡æµ‹è¯•ï¼‰
            startup_result = self._simulate_ui_startup()
            
            startup_duration = time.time() - startup_start
            
            # æ£€æŸ¥å¯åŠ¨æ—¶é—´
            startup_target_met = startup_duration <= 5.0
            if not startup_target_met:
                test_result["issues"].append(f"å¯åŠ¨æ—¶é—´è¶…æ ‡: {startup_duration:.2f}ç§’ > 5ç§’")
            
            # æ£€æŸ¥å†…å­˜ä½¿ç”¨
            current_memory = self.memory_monitor.get_current_memory_usage()
            memory_target_met = current_memory <= 0.4  # 400MB
            if not memory_target_met:
                test_result["issues"].append(f"å†…å­˜ä½¿ç”¨è¶…æ ‡: {current_memory:.3f}GB > 0.4GB")
            
            # è®°å½•æ€§èƒ½æŒ‡æ ‡
            test_result["metrics"] = {
                "startup_time_seconds": startup_duration,
                "startup_target_met": startup_target_met,
                "memory_usage_gb": current_memory,
                "memory_target_met": memory_target_met,
                "components_loaded": startup_result.get("components_loaded", 0),
                "initialization_success": startup_result.get("success", False)
            }
            
            # åˆ¤æ–­æµ‹è¯•çŠ¶æ€
            if startup_target_met and memory_target_met and startup_result.get("success", False):
                test_result["status"] = "PASSED"
            else:
                test_result["status"] = "FAILED"
                
        except Exception as e:
            test_result["status"] = "ERROR"
            test_result["error"] = str(e)
            logger.error(f"æµ‹è¯•é˜¶æ®µ1æ‰§è¡Œå¤±è´¥: {e}")
        
        test_result["end_time"] = time.time()
        test_result["duration"] = test_result["end_time"] - test_result["start_time"]
        
        return test_result
    
    def test_phase_2_file_upload_workflow(self) -> Dict[str, Any]:
        """æµ‹è¯•é˜¶æ®µ2: æ–‡ä»¶ä¸Šä¼ å·¥ä½œæµç¨‹"""
        phase_name = "file_upload_workflow"
        logger.info(f"å¼€å§‹æµ‹è¯•é˜¶æ®µ2: {phase_name}")
        
        test_result = {
            "phase": phase_name,
            "description": "æµ‹è¯•SRTå­—å¹•æ–‡ä»¶å’Œè§†é¢‘æ–‡ä»¶çš„å¯¼å…¥åŠŸèƒ½",
            "start_time": time.time(),
            "status": "RUNNING",
            "upload_tests": [],
            "issues": []
        }
        
        try:
            # æµ‹è¯•ç”¨ä¾‹
            upload_test_cases = [
                {
                    "name": "ä¸­æ–‡SRTæ–‡ä»¶ä¸Šä¼ ",
                    "file_path": self.test_data_dir / "chinese_test.srt",
                    "expected_language": "zh",
                    "expected_segments": 5
                },
                {
                    "name": "è‹±æ–‡SRTæ–‡ä»¶ä¸Šä¼ ",
                    "file_path": self.test_data_dir / "english_test.srt",
                    "expected_language": "en",
                    "expected_segments": 5
                },
                {
                    "name": "æŸåSRTæ–‡ä»¶å¤„ç†",
                    "file_path": self.test_data_dir / "corrupted_test.srt",
                    "expected_language": "unknown",
                    "expected_segments": 0,
                    "should_fail": True
                }
            ]
            
            for test_case in upload_test_cases:
                logger.info(f"æµ‹è¯•æ–‡ä»¶ä¸Šä¼ : {test_case['name']}")
                
                upload_start = time.time()
                upload_result = self._test_file_upload(test_case)
                upload_duration = time.time() - upload_start
                
                upload_result.update({
                    "test_case": test_case["name"],
                    "duration": upload_duration,
                    "response_time_target_met": upload_duration <= 2.0
                })
                
                test_result["upload_tests"].append(upload_result)
                
                # æ£€æŸ¥å“åº”æ—¶é—´
                if upload_duration > 2.0:
                    test_result["issues"].append(f"{test_case['name']}å“åº”æ—¶é—´è¶…æ ‡: {upload_duration:.2f}ç§’")
            
            # è®¡ç®—æ€»ä½“æˆåŠŸç‡
            successful_uploads = sum(1 for test in test_result["upload_tests"] if test.get("success", False))
            total_uploads = len(test_result["upload_tests"])
            success_rate = (successful_uploads / total_uploads) * 100 if total_uploads > 0 else 0
            
            test_result["summary"] = {
                "successful_uploads": successful_uploads,
                "total_uploads": total_uploads,
                "success_rate": success_rate,
                "all_response_times_met": all(test.get("response_time_target_met", False) for test in test_result["upload_tests"])
            }
            
            # åˆ¤æ–­æµ‹è¯•çŠ¶æ€
            if success_rate >= 80 and test_result["summary"]["all_response_times_met"]:
                test_result["status"] = "PASSED"
            else:
                test_result["status"] = "FAILED"
                
        except Exception as e:
            test_result["status"] = "ERROR"
            test_result["error"] = str(e)
            logger.error(f"æµ‹è¯•é˜¶æ®µ2æ‰§è¡Œå¤±è´¥: {e}")
        
        test_result["end_time"] = time.time()
        test_result["duration"] = test_result["end_time"] - test_result["start_time"]
        
        return test_result
    
    def test_phase_3_ai_processing_workflow(self) -> Dict[str, Any]:
        """æµ‹è¯•é˜¶æ®µ3: AIå¤„ç†å·¥ä½œæµç¨‹"""
        phase_name = "ai_processing_workflow"
        logger.info(f"å¼€å§‹æµ‹è¯•é˜¶æ®µ3: {phase_name}")
        
        test_result = {
            "phase": phase_name,
            "description": "æµ‹è¯•è¯­è¨€æ£€æµ‹ã€AIå‰§æœ¬é‡æ„å’Œè¿›åº¦æ˜¾ç¤º",
            "start_time": time.time(),
            "status": "RUNNING",
            "processing_tests": [],
            "issues": []
        }
        
        try:
            # AIå¤„ç†æµ‹è¯•ç”¨ä¾‹
            processing_test_cases = [
                {
                    "name": "ä¸­æ–‡å‰§æœ¬é‡æ„",
                    "input_text": "ä»Šå¤©æ˜¯ä¸ªå¥½æ—¥å­ï¼Œé˜³å…‰æ˜åªšã€‚å°æ˜èµ°åœ¨å›å®¶çš„è·¯ä¸Šã€‚",
                    "expected_language": "zh",
                    "expected_output_segments": 2
                },
                {
                    "name": "è‹±æ–‡å‰§æœ¬é‡æ„",
                    "input_text": "It was a beautiful sunny day. John was walking home from work.",
                    "expected_language": "en",
                    "expected_output_segments": 2
                }
            ]
            
            for test_case in processing_test_cases:
                logger.info(f"æµ‹è¯•AIå¤„ç†: {test_case['name']}")
                
                processing_start = time.time()
                processing_result = self._test_ai_processing(test_case)
                processing_duration = time.time() - processing_start
                
                processing_result.update({
                    "test_case": test_case["name"],
                    "duration": processing_duration,
                    "performance_target_met": processing_duration <= 30.0  # 30ç§’å†…å®Œæˆ
                })
                
                test_result["processing_tests"].append(processing_result)
                
                # æ£€æŸ¥å¤„ç†æ—¶é—´
                if processing_duration > 30.0:
                    test_result["issues"].append(f"{test_case['name']}å¤„ç†æ—¶é—´è¶…æ ‡: {processing_duration:.2f}ç§’")
            
            # è®¡ç®—æ€»ä½“æ€§èƒ½
            successful_processing = sum(1 for test in test_result["processing_tests"] if test.get("success", False))
            total_processing = len(test_result["processing_tests"])
            success_rate = (successful_processing / total_processing) * 100 if total_processing > 0 else 0
            
            test_result["summary"] = {
                "successful_processing": successful_processing,
                "total_processing": total_processing,
                "success_rate": success_rate,
                "all_performance_targets_met": all(test.get("performance_target_met", False) for test in test_result["processing_tests"])
            }
            
            # åˆ¤æ–­æµ‹è¯•çŠ¶æ€
            if success_rate >= 90 and test_result["summary"]["all_performance_targets_met"]:
                test_result["status"] = "PASSED"
            else:
                test_result["status"] = "FAILED"
                
        except Exception as e:
            test_result["status"] = "ERROR"
            test_result["error"] = str(e)
            logger.error(f"æµ‹è¯•é˜¶æ®µ3æ‰§è¡Œå¤±è´¥: {e}")
        
        test_result["end_time"] = time.time()
        test_result["duration"] = test_result["end_time"] - test_result["start_time"]
        
        return test_result
    
    def test_phase_4_export_workflow(self) -> Dict[str, Any]:
        """æµ‹è¯•é˜¶æ®µ4: å¯¼å‡ºå·¥ä½œæµç¨‹"""
        phase_name = "export_workflow"
        logger.info(f"å¼€å§‹æµ‹è¯•é˜¶æ®µ4: {phase_name}")
        
        test_result = {
            "phase": phase_name,
            "description": "æµ‹è¯•å‰ªæ˜ é¡¹ç›®æ–‡ä»¶å¯¼å‡ºçš„å®Œæ•´æ€§å’Œå…¼å®¹æ€§",
            "start_time": time.time(),
            "status": "RUNNING",
            "export_tests": [],
            "issues": []
        }
        
        try:
            # å¯¼å‡ºæµ‹è¯•ç”¨ä¾‹
            export_test_cases = [
                {
                    "name": "æ ‡å‡†å‰ªæ˜ é¡¹ç›®å¯¼å‡º",
                    "project_data": {
                        "project_name": "UIæµ‹è¯•é¡¹ç›®",
                        "segments": [
                            {"start_time": 0.0, "end_time": 3.0, "text": "æµ‹è¯•ç‰‡æ®µ1"},
                            {"start_time": 3.0, "end_time": 6.0, "text": "æµ‹è¯•ç‰‡æ®µ2"}
                        ],
                        "subtitles": []
                    },
                    "expected_file_size_min": 100  # æœ€å°100å­—èŠ‚
                },
                {
                    "name": "ç©ºé¡¹ç›®å¯¼å‡ºå¤„ç†",
                    "project_data": {
                        "project_name": "ç©ºé¡¹ç›®",
                        "segments": [],
                        "subtitles": []
                    },
                    "expected_file_size_min": 50
                }
            ]
            
            for test_case in export_test_cases:
                logger.info(f"æµ‹è¯•å¯¼å‡º: {test_case['name']}")
                
                export_start = time.time()
                export_result = self._test_export_functionality(test_case)
                export_duration = time.time() - export_start
                
                export_result.update({
                    "test_case": test_case["name"],
                    "duration": export_duration,
                    "response_time_target_met": export_duration <= 5.0
                })
                
                test_result["export_tests"].append(export_result)
                
                # æ£€æŸ¥å¯¼å‡ºæ—¶é—´
                if export_duration > 5.0:
                    test_result["issues"].append(f"{test_case['name']}å¯¼å‡ºæ—¶é—´è¶…æ ‡: {export_duration:.2f}ç§’")
            
            # è®¡ç®—å¯¼å‡ºæˆåŠŸç‡
            successful_exports = sum(1 for test in test_result["export_tests"] if test.get("success", False))
            total_exports = len(test_result["export_tests"])
            success_rate = (successful_exports / total_exports) * 100 if total_exports > 0 else 0
            
            test_result["summary"] = {
                "successful_exports": successful_exports,
                "total_exports": total_exports,
                "success_rate": success_rate,
                "all_response_times_met": all(test.get("response_time_target_met", False) for test in test_result["export_tests"])
            }
            
            # åˆ¤æ–­æµ‹è¯•çŠ¶æ€
            if success_rate >= 95 and test_result["summary"]["all_response_times_met"]:
                test_result["status"] = "PASSED"
            else:
                test_result["status"] = "FAILED"
                
        except Exception as e:
            test_result["status"] = "ERROR"
            test_result["error"] = str(e)
            logger.error(f"æµ‹è¯•é˜¶æ®µ4æ‰§è¡Œå¤±è´¥: {e}")
        
        test_result["end_time"] = time.time()
        test_result["duration"] = test_result["end_time"] - test_result["start_time"]
        
        return test_result

    def _simulate_ui_startup(self) -> Dict[str, Any]:
        """æ¨¡æ‹ŸUIå¯åŠ¨è¿‡ç¨‹"""
        try:
            # æµ‹è¯•æ ¸å¿ƒæ¨¡å—å¯¼å…¥
            components_loaded = 0

            # å¯¼å…¥UIç›¸å…³æ¨¡å—
            try:
                import simple_ui_fixed
                components_loaded += 1
            except ImportError as e:
                logger.warning(f"UIæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")

            # å¯¼å…¥æ ¸å¿ƒåŠŸèƒ½æ¨¡å—
            try:
                from src.core.screenplay_engineer import ScreenplayEngineer
                components_loaded += 1
            except ImportError as e:
                logger.warning(f"å‰§æœ¬å·¥ç¨‹å¸ˆæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")

            try:
                from src.core.language_detector import LanguageDetector
                components_loaded += 1
            except ImportError as e:
                logger.warning(f"è¯­è¨€æ£€æµ‹å™¨æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")

            try:
                from src.exporters.jianying_pro_exporter import JianYingProExporter
                components_loaded += 1
            except ImportError as e:
                logger.warning(f"å‰ªæ˜ å¯¼å‡ºå™¨æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")

            return {
                "success": components_loaded >= 3,  # è‡³å°‘3ä¸ªæ ¸å¿ƒç»„ä»¶æˆåŠŸåŠ è½½
                "components_loaded": components_loaded,
                "total_components": 4
            }

        except Exception as e:
            return {
                "success": False,
                "components_loaded": 0,
                "total_components": 4,
                "error": str(e)
            }

    def _test_file_upload(self, test_case: Dict[str, Any]) -> Dict[str, Any]:
        """æµ‹è¯•æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½"""
        try:
            file_path = test_case["file_path"]

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not file_path.exists():
                return {
                    "success": False,
                    "error": f"æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
                }

            # æ¨¡æ‹Ÿæ–‡ä»¶è¯»å–å’Œè§£æ
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                # ç®€å•çš„SRTæ ¼å¼éªŒè¯
                if test_case.get("should_fail", False):
                    # å¯¹äºåº”è¯¥å¤±è´¥çš„æµ‹è¯•ï¼Œæ£€æŸ¥æ˜¯å¦æ­£ç¡®å¤„ç†äº†é”™è¯¯
                    if "00:00:00,000" not in content:
                        return {
                            "success": True,  # æ­£ç¡®è¯†åˆ«äº†æŸåæ–‡ä»¶
                            "file_size": len(content),
                            "content_preview": content[:100],
                            "error_handled": True
                        }
                    else:
                        return {
                            "success": False,
                            "error": "åº”è¯¥å¤±è´¥çš„æµ‹è¯•å´æˆåŠŸäº†"
                        }
                else:
                    # æ­£å¸¸æ–‡ä»¶åº”è¯¥æˆåŠŸè§£æ
                    segments_found = content.count("-->")

                    return {
                        "success": segments_found >= test_case.get("expected_segments", 1),
                        "file_size": len(content),
                        "segments_found": segments_found,
                        "content_preview": content[:100]
                    }

            except Exception as e:
                if test_case.get("should_fail", False):
                    return {
                        "success": True,  # æ­£ç¡®å¤„ç†äº†å¼‚å¸¸
                        "error_handled": True,
                        "error": str(e)
                    }
                else:
                    return {
                        "success": False,
                        "error": str(e)
                    }

        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }

    def _test_ai_processing(self, test_case: Dict[str, Any]) -> Dict[str, Any]:
        """æµ‹è¯•AIå¤„ç†åŠŸèƒ½"""
        try:
            # å¯¼å…¥AIå¤„ç†æ¨¡å—
            from src.core.language_detector import LanguageDetector
            from src.core.screenplay_engineer import ScreenplayEngineer

            # è¯­è¨€æ£€æµ‹æµ‹è¯•
            detector = LanguageDetector()
            detected_language = detector.detect_from_text(test_case["input_text"])

            # AIå‰§æœ¬é‡æ„æµ‹è¯•
            engineer = ScreenplayEngineer()

            # åˆ›å»ºæµ‹è¯•å­—å¹•æ•°æ®
            test_subtitles = [
                {"start_time": 0.0, "end_time": 3.0, "text": test_case["input_text"][:50]},
                {"start_time": 3.0, "end_time": 6.0, "text": test_case["input_text"][50:] if len(test_case["input_text"]) > 50 else "ç»­é›†å†…å®¹"}
            ]

            # æ‰§è¡Œå‰§æœ¬é‡æ„
            result = engineer.generate_screenplay(test_subtitles, language=detected_language)

            return {
                "success": True,
                "detected_language": detected_language,
                "language_correct": detected_language == test_case.get("expected_language", "unknown"),
                "output_segments": len(result.get("screenplay", [])),
                "processing_time": result.get("processing_time", 0),
                "result_preview": str(result)[:200]
            }

        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }

    def _test_export_functionality(self, test_case: Dict[str, Any]) -> Dict[str, Any]:
        """æµ‹è¯•å¯¼å‡ºåŠŸèƒ½"""
        try:
            from src.exporters.jianying_pro_exporter import JianYingProExporter

            exporter = JianYingProExporter()

            # åˆ›å»ºè¾“å‡ºæ–‡ä»¶è·¯å¾„
            output_file = self.test_data_dir / f"export_test_{int(time.time())}.json"

            # æ‰§è¡Œå¯¼å‡º
            success = exporter.export_project(test_case["project_data"], str(output_file))

            # æ£€æŸ¥å¯¼å‡ºç»“æœ
            if success and output_file.exists():
                file_size = output_file.stat().st_size

                # éªŒè¯æ–‡ä»¶å†…å®¹
                with open(output_file, 'r', encoding='utf-8') as f:
                    exported_content = f.read()

                # æ¸…ç†æµ‹è¯•æ–‡ä»¶
                output_file.unlink()

                return {
                    "success": True,
                    "file_size": file_size,
                    "file_size_target_met": file_size >= test_case.get("expected_file_size_min", 50),
                    "content_preview": exported_content[:200],
                    "export_path": str(output_file)
                }
            else:
                return {
                    "success": False,
                    "error": "å¯¼å‡ºå¤±è´¥æˆ–æ–‡ä»¶æœªåˆ›å»º"
                }

        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }

    def run_comprehensive_ui_workflow_test(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„UIå·¥ä½œæµç¨‹æµ‹è¯•"""
        print("=== VisionAI-ClipsMaster UIå·¥ä½œæµç¨‹ç»¼åˆæµ‹è¯• ===")
        print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print()

        # æ‰§è¡Œæ‰€æœ‰æµ‹è¯•é˜¶æ®µ
        test_phases = [
            ("ç•Œé¢å¯åŠ¨ä¸åˆå§‹åŒ–", self.test_phase_1_ui_startup_initialization),
            ("æ–‡ä»¶ä¸Šä¼ å·¥ä½œæµç¨‹", self.test_phase_2_file_upload_workflow),
            ("AIå¤„ç†å·¥ä½œæµç¨‹", self.test_phase_3_ai_processing_workflow),
            ("å¯¼å‡ºå·¥ä½œæµç¨‹", self.test_phase_4_export_workflow)
        ]

        for phase_name, test_func in test_phases:
            print(f"ğŸ§ª æ‰§è¡Œæµ‹è¯•é˜¶æ®µ: {phase_name}")
            result = test_func()
            self.test_results["test_phases"][result["phase"]] = result

            status_icon = "âœ…" if result["status"] == "PASSED" else "âŒ" if result["status"] == "FAILED" else "âš ï¸"
            print(f"   {status_icon} {phase_name}: {result['status']} ({result.get('duration', 0):.2f}ç§’)")

            if result.get("issues"):
                for issue in result["issues"]:
                    print(f"      âš ï¸ {issue}")
            print()

        # åœæ­¢å†…å­˜ç›‘æ§
        self.memory_monitor.stop_monitoring()

        # ç”Ÿæˆæœ€ç»ˆè¯„ä¼°
        self._generate_final_assessment()

        # ä¿å­˜æµ‹è¯•ç»“æœ
        self._save_test_results()

        return self.test_results

    def _generate_final_assessment(self):
        """ç”Ÿæˆæœ€ç»ˆè¯„ä¼°"""
        test_phases = self.test_results["test_phases"]

        # è®¡ç®—é€šè¿‡ç‡
        total_phases = len(test_phases)
        passed_phases = sum(1 for phase in test_phases.values() if phase["status"] == "PASSED")
        pass_rate = (passed_phases / total_phases) * 100 if total_phases > 0 else 0

        # æ€§èƒ½æŒ‡æ ‡æ±‡æ€»
        peak_memory = self.memory_monitor.get_peak_memory_usage()

        self.test_results.update({
            "end_time": datetime.now().isoformat(),
            "total_phases": total_phases,
            "passed_phases": passed_phases,
            "pass_rate": pass_rate,
            "peak_memory_gb": peak_memory,
            "memory_compliant": peak_memory <= 3.8,
            "overall_status": "PASSED" if pass_rate >= 80 and peak_memory <= 3.8 else "FAILED"
        })

        # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
        print("ğŸ“‹ æœ€ç»ˆè¯„ä¼°ç»“æœ:")
        print(f"   æµ‹è¯•é€šè¿‡ç‡: {pass_rate:.1f}%")
        print(f"   å³°å€¼å†…å­˜: {peak_memory:.3f}GB")
        print(f"   å†…å­˜åˆè§„: {'æ˜¯' if peak_memory <= 3.8 else 'å¦'}")
        print(f"   æ€»ä½“çŠ¶æ€: {self.test_results['overall_status']}")

    def _save_test_results(self):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        results_file = self.project_root / "test_outputs" / f"ui_workflow_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        results_file.parent.mkdir(parents=True, exist_ok=True)

        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, indent=2, ensure_ascii=False, default=str)

        logger.info(f"æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {results_file}")


class MemoryMonitor:
    """å†…å­˜ç›‘æ§å™¨"""

    def __init__(self):
        self.monitoring = False
        self.memory_history = []
        self.monitor_thread = None
        self.process = psutil.Process()

    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        self.monitoring = True
        self.memory_history = []
        self.monitor_thread = threading.Thread(target=self._monitor_loop)
        self.monitor_thread.daemon = True
        self.monitor_thread.start()

    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=1)

    def _monitor_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while self.monitoring:
            memory_gb = self.process.memory_info().rss / 1024**3
            self.memory_history.append(memory_gb)
            time.sleep(1)

    def get_current_memory_usage(self) -> float:
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨ï¼ˆGBï¼‰"""
        return self.process.memory_info().rss / 1024**3

    def get_peak_memory_usage(self) -> float:
        """è·å–å³°å€¼å†…å­˜ä½¿ç”¨"""
        if not self.memory_history:
            return self.get_current_memory_usage()
        return max(self.memory_history)


def main():
    """ä¸»å‡½æ•°"""
    tester = UIWorkflowTester()
    return tester.run_comprehensive_ui_workflow_test()


if __name__ == "__main__":
    main()
