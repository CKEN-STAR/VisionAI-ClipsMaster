#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
VisionAI-ClipsMaster ç¬¬ä¸€é˜¶æ®µä½“ç§¯ä¼˜åŒ–è„šæœ¬
å®‰å…¨æ¸…ç†ï¼šåˆ é™¤ç¼“å­˜ã€ä¸´æ—¶æ–‡ä»¶ã€é‡å¤æ•°æ®
é¢„æœŸå‡å°‘ï¼š106MBï¼Œé›¶é£é™©
"""

import os
import shutil
import json
import time
from pathlib import Path

def format_size(size_bytes):
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°æ˜¾ç¤º"""
    if size_bytes == 0:
        return "0B"
    size_names = ["B", "KB", "MB", "GB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024.0
        i += 1
    return f"{size_bytes:.2f}{size_names[i]}"

def get_size(path):
    """è·å–æ–‡ä»¶æˆ–ç›®å½•çš„å¤§å°"""
    if os.path.isfile(path):
        return os.path.getsize(path)
    elif os.path.isdir(path):
        total = 0
        try:
            for dirpath, dirnames, filenames in os.walk(path):
                for filename in filenames:
                    filepath = os.path.join(dirpath, filename)
                    try:
                        total += os.path.getsize(filepath)
                    except (OSError, FileNotFoundError):
                        pass
        except (OSError, PermissionError):
            pass
        return total
    return 0

def safe_remove(path, operation_log):
    """å®‰å…¨åˆ é™¤æ–‡ä»¶æˆ–ç›®å½•"""
    try:
        if os.path.exists(path):
            size_before = get_size(path)
            if os.path.isfile(path):
                os.remove(path)
                operation_log.append({
                    "type": "file",
                    "path": path,
                    "size": size_before,
                    "status": "deleted"
                })
                return size_before
            elif os.path.isdir(path):
                shutil.rmtree(path)
                operation_log.append({
                    "type": "directory", 
                    "path": path,
                    "size": size_before,
                    "status": "deleted"
                })
                return size_before
        return 0
    except Exception as e:
        operation_log.append({
            "type": "error",
            "path": path,
            "error": str(e),
            "status": "failed"
        })
        return 0

def clean_python_cache(root_path, operation_log):
    """æ¸…ç†Pythonç¼“å­˜æ–‡ä»¶"""
    print("ğŸ§¹ æ¸…ç†Pythonç¼“å­˜æ–‡ä»¶...")
    total_cleaned = 0
    
    # æ¸…ç† __pycache__ ç›®å½•
    for root, dirs, files in os.walk(root_path):
        if "__pycache__" in dirs:
            cache_path = os.path.join(root, "__pycache__")
            size = safe_remove(cache_path, operation_log)
            total_cleaned += size
            print(f"  âœ… åˆ é™¤: {cache_path} ({format_size(size)})")
    
    # æ¸…ç† .pyc æ–‡ä»¶
    for root, dirs, files in os.walk(root_path):
        for file in files:
            if file.endswith('.pyc'):
                file_path = os.path.join(root, file)
                size = safe_remove(file_path, operation_log)
                total_cleaned += size
                print(f"  âœ… åˆ é™¤: {file_path} ({format_size(size)})")
    
    return total_cleaned

def clean_temporary_files(root_path, operation_log):
    """æ¸…ç†ä¸´æ—¶æ–‡ä»¶å’Œç›®å½•"""
    print("ğŸ—‘ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å’Œç›®å½•...")
    total_cleaned = 0
    
    temp_targets = [
        "test_outputs",
        "outputs", 
        "results",
        "snapshots",
        "recovery"
    ]
    
    for target in temp_targets:
        target_path = os.path.join(root_path, target)
        if os.path.exists(target_path):
            size = safe_remove(target_path, operation_log)
            total_cleaned += size
            print(f"  âœ… åˆ é™¤ç›®å½•: {target} ({format_size(size)})")
    
    return total_cleaned

def clean_log_files(root_path, operation_log):
    """æ¸…ç†æ—¥å¿—æ–‡ä»¶"""
    print("ğŸ“ æ¸…ç†æ—¥å¿—æ–‡ä»¶...")
    total_cleaned = 0
    
    # æ¸…ç†æ ¹ç›®å½•çš„æ—¥å¿—æ–‡ä»¶
    for file in os.listdir(root_path):
        if file.endswith('.log'):
            file_path = os.path.join(root_path, file)
            size = safe_remove(file_path, operation_log)
            total_cleaned += size
            print(f"  âœ… åˆ é™¤æ—¥å¿—: {file} ({format_size(size)})")
    
    # æ¸…ç†logsç›®å½•
    logs_path = os.path.join(root_path, "logs")
    if os.path.exists(logs_path):
        size = safe_remove(logs_path, operation_log)
        total_cleaned += size
        print(f"  âœ… åˆ é™¤logsç›®å½•: ({format_size(size)})")
    
    return total_cleaned

def remove_duplicate_test_data(root_path, operation_log):
    """åˆ é™¤é‡å¤çš„æµ‹è¯•æ•°æ®æ–‡ä»¶"""
    print("ğŸ”„ åˆ é™¤é‡å¤çš„æµ‹è¯•æ•°æ®æ–‡ä»¶...")
    total_cleaned = 0
    
    # æ£€æŸ¥é‡å¤çš„test_data.binæ–‡ä»¶
    root_test_data = os.path.join(root_path, "test_data.bin")
    examples_test_data = os.path.join(root_path, "examples", "test_data.bin")
    
    if os.path.exists(root_test_data) and os.path.exists(examples_test_data):
        # ä¿ç•™æ ¹ç›®å½•çš„ï¼Œåˆ é™¤examplesä¸­çš„
        size = safe_remove(examples_test_data, operation_log)
        total_cleaned += size
        print(f"  âœ… åˆ é™¤é‡å¤æ–‡ä»¶: examples/test_data.bin ({format_size(size)})")
    
    return total_cleaned

def verify_core_files(root_path):
    """éªŒè¯æ ¸å¿ƒæ–‡ä»¶å®Œæ•´æ€§"""
    print("ğŸ” éªŒè¯æ ¸å¿ƒæ–‡ä»¶å®Œæ•´æ€§...")
    
    critical_files = [
        "simple_ui_fixed.py",
        "VisionAI_ClipsMaster_Comprehensive_Verification_Test.py",
        "requirements.txt"
    ]
    
    critical_dirs = [
        "src",
        "ui", 
        "configs",
        "tools"
    ]
    
    missing_files = []
    
    for file in critical_files:
        file_path = os.path.join(root_path, file)
        if not os.path.exists(file_path):
            missing_files.append(file)
    
    for dir_name in critical_dirs:
        dir_path = os.path.join(root_path, dir_name)
        if not os.path.exists(dir_path):
            missing_files.append(dir_name)
    
    if missing_files:
        print(f"  âŒ è­¦å‘Š: å‘ç°ç¼ºå¤±çš„å…³é”®æ–‡ä»¶/ç›®å½•: {missing_files}")
        return False
    else:
        print("  âœ… æ‰€æœ‰æ ¸å¿ƒæ–‡ä»¶å®Œæ•´")
        return True

def main():
    """ä¸»å‡½æ•°"""
    root_path = r"d:\zancun\VisionAI-ClipsMaster-backup"
    
    print("ğŸ¯ VisionAI-ClipsMaster ç¬¬ä¸€é˜¶æ®µä½“ç§¯ä¼˜åŒ–")
    print("=" * 60)
    print(f"å¼€å§‹æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"é¡¹ç›®è·¯å¾„: {root_path}")
    print("ä¼˜åŒ–å†…å®¹: å®‰å…¨æ¸…ç†ç¼“å­˜ã€ä¸´æ—¶æ–‡ä»¶ã€é‡å¤æ•°æ®")
    print("é¢„æœŸå‡å°‘: 106MB")
    print("é£é™©ç­‰çº§: æä½")
    
    # è·å–åˆå§‹å¤§å°
    initial_size = get_size(root_path)
    print(f"\nğŸ“Š ä¼˜åŒ–å‰æ€»ä½“ç§¯: {format_size(initial_size)}")
    
    # éªŒè¯æ ¸å¿ƒæ–‡ä»¶
    if not verify_core_files(root_path):
        print("âŒ æ ¸å¿ƒæ–‡ä»¶éªŒè¯å¤±è´¥ï¼Œåœæ­¢ä¼˜åŒ–")
        return
    
    # æ“ä½œæ—¥å¿—
    operation_log = []
    total_cleaned = 0
    
    print("\nğŸš€ å¼€å§‹ä¼˜åŒ–...")
    print("-" * 40)
    
    # 1. åˆ é™¤é‡å¤æµ‹è¯•æ•°æ®
    cleaned = remove_duplicate_test_data(root_path, operation_log)
    total_cleaned += cleaned
    print(f"é‡å¤æ•°æ®æ¸…ç†å®Œæˆ: {format_size(cleaned)}")
    
    # 2. æ¸…ç†Pythonç¼“å­˜
    cleaned = clean_python_cache(root_path, operation_log)
    total_cleaned += cleaned
    print(f"Pythonç¼“å­˜æ¸…ç†å®Œæˆ: {format_size(cleaned)}")
    
    # 3. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    cleaned = clean_temporary_files(root_path, operation_log)
    total_cleaned += cleaned
    print(f"ä¸´æ—¶æ–‡ä»¶æ¸…ç†å®Œæˆ: {format_size(cleaned)}")
    
    # 4. æ¸…ç†æ—¥å¿—æ–‡ä»¶
    cleaned = clean_log_files(root_path, operation_log)
    total_cleaned += cleaned
    print(f"æ—¥å¿—æ–‡ä»¶æ¸…ç†å®Œæˆ: {format_size(cleaned)}")
    
    # è·å–æœ€ç»ˆå¤§å°
    final_size = get_size(root_path)
    actual_reduction = initial_size - final_size
    
    print("\n" + "=" * 60)
    print("ğŸ‰ ç¬¬ä¸€é˜¶æ®µä¼˜åŒ–å®Œæˆ!")
    print(f"ğŸ“Š ä¼˜åŒ–å‰ä½“ç§¯: {format_size(initial_size)}")
    print(f"ğŸ“Š ä¼˜åŒ–åä½“ç§¯: {format_size(final_size)}")
    print(f"ğŸ“Š å®é™…å‡å°‘: {format_size(actual_reduction)}")
    print(f"ğŸ“Š ä¼˜åŒ–æ¯”ä¾‹: {(actual_reduction/initial_size*100):.2f}%")
    print(f"ğŸ“Š é¢„æœŸå‡å°‘: 106MB")
    print(f"ğŸ“Š å®Œæˆåº¦: {(actual_reduction/(106*1024*1024)*100):.1f}%")
    
    # ä¿å­˜æ“ä½œæ—¥å¿—
    log_data = {
        "optimization_phase": "Phase 1 - Safe Cleanup",
        "start_time": time.strftime('%Y-%m-%d %H:%M:%S'),
        "initial_size": initial_size,
        "final_size": final_size,
        "actual_reduction": actual_reduction,
        "expected_reduction": 106 * 1024 * 1024,
        "operations": operation_log,
        "summary": {
            "duplicate_data_cleaned": sum(op["size"] for op in operation_log if "test_data.bin" in op.get("path", "")),
            "cache_cleaned": sum(op["size"] for op in operation_log if "__pycache__" in op.get("path", "") or op.get("path", "").endswith(".pyc")),
            "temp_files_cleaned": sum(op["size"] for op in operation_log if any(temp in op.get("path", "") for temp in ["test_outputs", "outputs", "results", "snapshots", "recovery"])),
            "logs_cleaned": sum(op["size"] for op in operation_log if op.get("path", "").endswith(".log") or "logs" in op.get("path", ""))
        }
    }
    
    log_file = "VisionAI_ClipsMaster_Phase1_Optimization_Log.json"
    with open(log_file, 'w', encoding='utf-8') as f:
        json.dump(log_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“‹ è¯¦ç»†æ—¥å¿—å·²ä¿å­˜: {log_file}")
    print("\nğŸ” å»ºè®®ä¸‹ä¸€æ­¥:")
    print("1. è¿è¡ŒåŠŸèƒ½éªŒè¯æµ‹è¯•:")
    print("   python VisionAI_ClipsMaster_Comprehensive_Verification_Test.py")
    print("2. éªŒè¯ç¨‹åºå¯åŠ¨:")
    print("   python simple_ui_fixed.py")
    print("3. å¦‚æœæµ‹è¯•é€šè¿‡ï¼Œå¯ä»¥è€ƒè™‘æ‰§è¡Œç¬¬äºŒé˜¶æ®µä¼˜åŒ–")

if __name__ == "__main__":
    main()
