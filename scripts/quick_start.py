#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
VisionAI-ClipsMaster å¿«é€Ÿå¯åŠ¨è„šæœ¬

æä¾›ä¸€é”®å¯åŠ¨åŠŸèƒ½ï¼Œè‡ªåŠ¨æ£€æµ‹ç¯å¢ƒå¹¶é€‰æ‹©æœ€ä½³é…ç½®
"""

import os
import sys
import platform
import subprocess
import json
import time
from pathlib import Path
from typing import Dict, List, Optional

class QuickStarter:
    """å¿«é€Ÿå¯åŠ¨å™¨"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.system_info = self._detect_system()
        
    def _detect_system(self) -> Dict:
        """æ£€æµ‹ç³»ç»Ÿä¿¡æ¯"""
        try:
            import psutil
            
            return {
                "platform": platform.system(),
                "memory_gb": round(psutil.virtual_memory().total / (1024**3), 1),
                "cpu_count": psutil.cpu_count(),
                "python_version": f"{sys.version_info.major}.{sys.version_info.minor}",
                "has_gpu": self._check_gpu(),
                "has_docker": self._check_docker(),
                "has_conda": self._check_conda()
            }
        except ImportError:
            return {
                "platform": platform.system(),
                "memory_gb": 8.0,  # é»˜è®¤å‡è®¾
                "cpu_count": 4,
                "python_version": f"{sys.version_info.major}.{sys.version_info.minor}",
                "has_gpu": False,
                "has_docker": False,
                "has_conda": False
            }
    
    def _check_gpu(self) -> bool:
        """æ£€æŸ¥GPUå¯ç”¨æ€§"""
        try:
            import torch
            return torch.cuda.is_available()
        except ImportError:
            return False
    
    def _check_docker(self) -> bool:
        """æ£€æŸ¥Dockerå¯ç”¨æ€§"""
        try:
            result = subprocess.run(["docker", "--version"], 
                                  capture_output=True, text=True)
            return result.returncode == 0
        except FileNotFoundError:
            return False
    
    def _check_conda(self) -> bool:
        """æ£€æŸ¥Condaå¯ç”¨æ€§"""
        try:
            result = subprocess.run(["conda", "--version"], 
                                  capture_output=True, text=True)
            return result.returncode == 0
        except FileNotFoundError:
            return False
    
    def recommend_configuration(self) -> Dict:
        """æ¨èé…ç½®"""
        config = {
            "mode": "full",
            "quantization": "Q4_K_M",
            "max_memory": 7000,
            "deployment": "local",
            "install_method": "pip"
        }
        
        # æ ¹æ®å†…å­˜è°ƒæ•´é…ç½®
        if self.system_info["memory_gb"] <= 4:
            config.update({
                "mode": "lite",
                "quantization": "Q2_K",
                "max_memory": 3800
            })
        elif self.system_info["memory_gb"] <= 6:
            config.update({
                "quantization": "Q4_K_M",
                "max_memory": 5000
            })
        else:
            config.update({
                "quantization": "Q5_K",
                "max_memory": 7000
            })
        
        # æ ¹æ®å¯ç”¨å·¥å…·è°ƒæ•´å®‰è£…æ–¹æ³•
        if self.system_info["has_docker"]:
            config["deployment"] = "docker"
        elif self.system_info["has_conda"]:
            config["install_method"] = "conda"
        
        return config
    
    def show_system_info(self):
        """æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯"""
        print("ğŸ–¥ï¸  ç³»ç»Ÿä¿¡æ¯")
        print("=" * 40)
        print(f"æ“ä½œç³»ç»Ÿ: {self.system_info['platform']}")
        print(f"å†…å­˜: {self.system_info['memory_gb']:.1f}GB")
        print(f"CPUæ ¸å¿ƒ: {self.system_info['cpu_count']}")
        print(f"Pythonç‰ˆæœ¬: {self.system_info['python_version']}")
        print(f"GPUæ”¯æŒ: {'æ˜¯' if self.system_info['has_gpu'] else 'å¦'}")
        print(f"Dockerå¯ç”¨: {'æ˜¯' if self.system_info['has_docker'] else 'å¦'}")
        print(f"Condaå¯ç”¨: {'æ˜¯' if self.system_info['has_conda'] else 'å¦'}")
        print()
    
    def show_recommended_config(self, config: Dict):
        """æ˜¾ç¤ºæ¨èé…ç½®"""
        print("ğŸ’¡ æ¨èé…ç½®")
        print("=" * 40)
        print(f"è¿è¡Œæ¨¡å¼: {config['mode']}")
        print(f"é‡åŒ–çº§åˆ«: {config['quantization']}")
        print(f"å†…å­˜é™åˆ¶: {config['max_memory']}MB")
        print(f"éƒ¨ç½²æ–¹å¼: {config['deployment']}")
        print(f"å®‰è£…æ–¹æ³•: {config['install_method']}")
        print()
    
    def quick_install(self, config: Dict) -> bool:
        """å¿«é€Ÿå®‰è£…"""
        print("ğŸ“¦ å¼€å§‹å¿«é€Ÿå®‰è£…...")
        
        try:
            if config["deployment"] == "docker":
                return self._install_docker(config)
            else:
                return self._install_local(config)
        except Exception as e:
            print(f"âŒ å®‰è£…å¤±è´¥: {e}")
            return False
    
    def _install_docker(self, config: Dict) -> bool:
        """Dockerå®‰è£…"""
        print("ğŸ³ ä½¿ç”¨Dockerå®‰è£…...")
        
        # æ„å»ºDockeré•œåƒ
        target = "lite" if config["mode"] == "lite" else "production"
        cmd = [
            "docker", "build",
            "-f", "docker/Dockerfile",
            "--target", target,
            "-t", f"visionai-clipsmaster:{config['mode']}",
            "."
        ]
        
        print("æ„å»ºDockeré•œåƒ...")
        result = subprocess.run(cmd, cwd=self.project_root)
        
        if result.returncode != 0:
            print("âŒ Dockeré•œåƒæ„å»ºå¤±è´¥")
            return False
        
        print("âœ… Dockeré•œåƒæ„å»ºæˆåŠŸ")
        
        # åˆ›å»ºå¯åŠ¨è„šæœ¬
        self._create_docker_start_script(config)
        
        return True
    
    def _install_local(self, config: Dict) -> bool:
        """æœ¬åœ°å®‰è£…"""
        print("ğŸ  ä½¿ç”¨æœ¬åœ°å®‰è£…...")
        
        # åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
        venv_path = self.project_root / "venv"
        if not venv_path.exists():
            print("åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ...")
            result = subprocess.run([sys.executable, "-m", "venv", str(venv_path)])
            if result.returncode != 0:
                print("âŒ è™šæ‹Ÿç¯å¢ƒåˆ›å»ºå¤±è´¥")
                return False
        
        # ç¡®å®špipè·¯å¾„
        if platform.system() == "Windows":
            pip_path = venv_path / "Scripts" / "pip.exe"
            python_path = venv_path / "Scripts" / "python.exe"
        else:
            pip_path = venv_path / "bin" / "pip"
            python_path = venv_path / "bin" / "python"
        
        # å®‰è£…ä¾èµ–
        print("å®‰è£…Pythonä¾èµ–...")
        if config["mode"] == "lite":
            requirements_file = "requirements/requirements-lite.txt"
        else:
            requirements_file = "requirements/requirements.txt"
        
        result = subprocess.run([
            str(pip_path), "install", "-r", requirements_file
        ], cwd=self.project_root)
        
        if result.returncode != 0:
            print("âŒ ä¾èµ–å®‰è£…å¤±è´¥")
            return False
        
        print("âœ… ä¾èµ–å®‰è£…æˆåŠŸ")
        
        # åˆ›å»ºå¯åŠ¨è„šæœ¬
        self._create_local_start_script(config, python_path)
        
        return True
    
    def _create_docker_start_script(self, config: Dict):
        """åˆ›å»ºDockerå¯åŠ¨è„šæœ¬"""
        if platform.system() == "Windows":
            script_content = f"""@echo off
echo å¯åŠ¨VisionAI-ClipsMaster (Dockeræ¨¡å¼)
docker run -it --rm ^
    -p 8080:8080 ^
    -v "%cd%\\data:/home/visionai/data" ^
    -v "%cd%\\models:/home/visionai/models" ^
    -e VISIONAI_MODE={config['mode']} ^
    -e VISIONAI_MAX_MEMORY={config['max_memory']} ^
    visionai-clipsmaster:{config['mode']} web
"""
            script_path = self.project_root / "start_docker.bat"
        else:
            script_content = f"""#!/bin/bash
echo "å¯åŠ¨VisionAI-ClipsMaster (Dockeræ¨¡å¼)"
docker run -it --rm \\
    -p 8080:8080 \\
    -v "$(pwd)/data:/home/visionai/data" \\
    -v "$(pwd)/models:/home/visionai/models" \\
    -e VISIONAI_MODE={config['mode']} \\
    -e VISIONAI_MAX_MEMORY={config['max_memory']} \\
    visionai-clipsmaster:{config['mode']} web
"""
            script_path = self.project_root / "start_docker.sh"
        
        with open(script_path, 'w', encoding='utf-8') as f:
            f.write(script_content)
        
        if platform.system() != "Windows":
            os.chmod(script_path, 0o755)
        
        print(f"âœ… å¯åŠ¨è„šæœ¬å·²åˆ›å»º: {script_path}")
    
    def _create_local_start_script(self, config: Dict, python_path: Path):
        """åˆ›å»ºæœ¬åœ°å¯åŠ¨è„šæœ¬"""
        if platform.system() == "Windows":
            script_content = f"""@echo off
echo å¯åŠ¨VisionAI-ClipsMaster (æœ¬åœ°æ¨¡å¼)
set VISIONAI_MODE={config['mode']}
set VISIONAI_MAX_MEMORY={config['max_memory']}
"{python_path}" src\\visionai_clipsmaster\\ui\\main_window.py
pause
"""
            script_path = self.project_root / "start_local.bat"
        else:
            script_content = f"""#!/bin/bash
echo "å¯åŠ¨VisionAI-ClipsMaster (æœ¬åœ°æ¨¡å¼)"
export VISIONAI_MODE={config['mode']}
export VISIONAI_MAX_MEMORY={config['max_memory']}
"{python_path}" src/visionai_clipsmaster/ui/main_window.py
"""
            script_path = self.project_root / "start_local.sh"
        
        with open(script_path, 'w', encoding='utf-8') as f:
            f.write(script_content)
        
        if platform.system() != "Windows":
            os.chmod(script_path, 0o755)
        
        print(f"âœ… å¯åŠ¨è„šæœ¬å·²åˆ›å»º: {script_path}")
    
    def download_models(self, config: Dict) -> bool:
        """ä¸‹è½½æ¨¡å‹"""
        print("ğŸ¤– ä¸‹è½½AIæ¨¡å‹...")
        
        try:
            # è¿è¡Œæ¨¡å‹ä¸‹è½½è„šæœ¬
            if config["deployment"] == "docker":
                cmd = [
                    "docker", "run", "--rm",
                    "-v", f"{self.project_root}/models:/home/visionai/models",
                    f"visionai-clipsmaster:{config['mode']}",
                    "download-models"
                ]
            else:
                # ä½¿ç”¨æœ¬åœ°Python
                if platform.system() == "Windows":
                    python_path = self.project_root / "venv" / "Scripts" / "python.exe"
                else:
                    python_path = self.project_root / "venv" / "bin" / "python"
                
                cmd = [
                    str(python_path),
                    "scripts/setup_models.py",
                    "--setup"
                ]
            
            result = subprocess.run(cmd, cwd=self.project_root)
            
            if result.returncode == 0:
                print("âœ… æ¨¡å‹ä¸‹è½½æˆåŠŸ")
                return True
            else:
                print("âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥")
                return False
                
        except Exception as e:
            print(f"âŒ æ¨¡å‹ä¸‹è½½å‡ºé”™: {e}")
            return False
    
    def run_quick_start(self):
        """è¿è¡Œå¿«é€Ÿå¯åŠ¨æµç¨‹"""
        print("ğŸš€ VisionAI-ClipsMaster å¿«é€Ÿå¯åŠ¨")
        print("=" * 50)
        print()
        
        # æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
        self.show_system_info()
        
        # è·å–æ¨èé…ç½®
        config = self.recommend_configuration()
        self.show_recommended_config(config)
        
        # è¯¢é—®ç”¨æˆ·æ˜¯å¦ç»§ç»­
        response = input("æ˜¯å¦ä½¿ç”¨æ¨èé…ç½®è¿›è¡Œå®‰è£…? (Y/n): ").strip().lower()
        if response in ['n', 'no']:
            print("å®‰è£…å·²å–æ¶ˆ")
            return False
        
        # å¼€å§‹å®‰è£…
        print("\nğŸ”§ å¼€å§‹å®‰è£…è¿‡ç¨‹...")
        
        # 1. å¿«é€Ÿå®‰è£…
        if not self.quick_install(config):
            print("âŒ å®‰è£…å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
            return False
        
        # 2. ä¸‹è½½æ¨¡å‹
        print("\nğŸ“¥ ä¸‹è½½æ¨¡å‹æ–‡ä»¶...")
        download_response = input("æ˜¯å¦ç°åœ¨ä¸‹è½½AIæ¨¡å‹? (Y/n): ").strip().lower()
        if download_response not in ['n', 'no']:
            if not self.download_models(config):
                print("âš ï¸  æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼Œå¯ä»¥ç¨åæ‰‹åŠ¨ä¸‹è½½")
        
        # 3. å®Œæˆå®‰è£…
        print("\nğŸ‰ å®‰è£…å®Œæˆ!")
        print("=" * 50)
        
        if config["deployment"] == "docker":
            print("å¯åŠ¨æ–¹å¼:")
            if platform.system() == "Windows":
                print("  åŒå‡»è¿è¡Œ: start_docker.bat")
            else:
                print("  è¿è¡Œå‘½ä»¤: ./start_docker.sh")
            print("  æˆ–æ‰‹åŠ¨è¿è¡Œ: docker run -p 8080:8080 visionai-clipsmaster")
        else:
            print("å¯åŠ¨æ–¹å¼:")
            if platform.system() == "Windows":
                print("  åŒå‡»è¿è¡Œ: start_local.bat")
            else:
                print("  è¿è¡Œå‘½ä»¤: ./start_local.sh")
            print("  æˆ–æ‰‹åŠ¨æ¿€æ´»ç¯å¢ƒåè¿è¡Œç¨‹åº")
        
        print("\nè®¿é—®åœ°å€: http://localhost:8080")
        print("æ–‡æ¡£åœ°å€: https://github.com/CKEN/VisionAI-ClipsMaster")
        
        return True

def main():
    """ä¸»å‡½æ•°"""
    try:
        starter = QuickStarter()
        success = starter.run_quick_start()
        return 0 if success else 1
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·å–æ¶ˆå®‰è£…")
        return 1
    except Exception as e:
        print(f"\nâŒ å¿«é€Ÿå¯åŠ¨å¤±è´¥: {e}")
        return 1

if __name__ == "__main__":
    sys.exit(main())
