#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
VisionAI-ClipsMaster ç»¼åˆé—®é¢˜åˆ†æå’Œä¿®å¤å·¥å…·
åˆ†ææ’­æ”¾é¢„è§ˆæµ‹è¯•å¤±è´¥åŸå› å¹¶éªŒè¯UIåŠŸèƒ½å®Œæ•´æ€§
"""

import os
import sys
import json
import time
import tempfile
import shutil
import logging
import subprocess
from pathlib import Path
from typing import Dict, List, Any, Tuple
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).resolve().parent
sys.path.insert(0, str(project_root))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('issue_analysis.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class ComprehensiveIssueAnalyzer:
    """ç»¼åˆé—®é¢˜åˆ†æå™¨"""
    
    def __init__(self):
        self.test_dir = Path(tempfile.mkdtemp(prefix="issue_analysis_"))
        self.analysis_results = []
        self.created_files = []
        
        logger.info(f"åˆ†æç›®å½•: {self.test_dir}")
    
    def analyze_playback_preview_issue(self) -> Dict[str, Any]:
        """åˆ†ææ’­æ”¾é¢„è§ˆæµ‹è¯•å¤±è´¥çš„å…·ä½“åŸå› """
        logger.info("=" * 60)
        logger.info("é—®é¢˜åˆ†æ1: æ’­æ”¾é¢„è§ˆæµ‹è¯•å¤±è´¥åŸå› åˆ†æ")
        logger.info("=" * 60)
        
        analysis_result = {
            "analysis_name": "æ’­æ”¾é¢„è§ˆæµ‹è¯•å¤±è´¥åŸå› åˆ†æ",
            "start_time": time.time(),
            "status": "è¿›è¡Œä¸­",
            "findings": {},
            "root_causes": [],
            "recommendations": []
        }
        
        try:
            # 1. åˆ†æç´ ææ–‡ä»¶è·¯å¾„å¤„ç†æœºåˆ¶
            logger.info("åˆ†æç´ ææ–‡ä»¶è·¯å¾„å¤„ç†æœºåˆ¶...")
            path_analysis = self._analyze_material_path_handling()
            analysis_result["findings"]["path_handling"] = path_analysis
            
            if not path_analysis["correct"]:
                analysis_result["root_causes"].append("ç´ ææ–‡ä»¶è·¯å¾„å¤„ç†æœºåˆ¶å­˜åœ¨é—®é¢˜")
                analysis_result["recommendations"].append("ä¿®å¤ç´ ææ–‡ä»¶è·¯å¾„æ˜ å°„é€»è¾‘")
            
            # 2. æ£€æŸ¥æµ‹è¯•ç¯å¢ƒvsç”Ÿäº§ç¯å¢ƒå·®å¼‚
            logger.info("æ£€æŸ¥æµ‹è¯•ç¯å¢ƒä¸ç”Ÿäº§ç¯å¢ƒå·®å¼‚...")
            env_analysis = self._analyze_environment_differences()
            analysis_result["findings"]["environment"] = env_analysis
            
            if env_analysis["has_differences"]:
                analysis_result["root_causes"].append("æµ‹è¯•ç¯å¢ƒä¸ç”Ÿäº§ç¯å¢ƒå­˜åœ¨å·®å¼‚")
                analysis_result["recommendations"].append("ç»Ÿä¸€æµ‹è¯•å’Œç”Ÿäº§ç¯å¢ƒçš„æ–‡ä»¶å¤„ç†é€»è¾‘")
            
            # 3. éªŒè¯å‰ªæ˜ å·¥ç¨‹æ–‡ä»¶ä¸­çš„ç´ æå¼•ç”¨
            logger.info("éªŒè¯å‰ªæ˜ å·¥ç¨‹æ–‡ä»¶ä¸­çš„ç´ æå¼•ç”¨...")
            reference_analysis = self._analyze_material_references()
            analysis_result["findings"]["material_references"] = reference_analysis
            
            if not reference_analysis["valid"]:
                analysis_result["root_causes"].append("å‰ªæ˜ å·¥ç¨‹æ–‡ä»¶ä¸­çš„ç´ æå¼•ç”¨ä¸æ­£ç¡®")
                analysis_result["recommendations"].append("ä¿®å¤ç´ æå¼•ç”¨ç”Ÿæˆé€»è¾‘")
            
            # 4. æ£€æŸ¥æ–‡ä»¶ç”Ÿå‘½å‘¨æœŸç®¡ç†
            logger.info("æ£€æŸ¥æ–‡ä»¶ç”Ÿå‘½å‘¨æœŸç®¡ç†...")
            lifecycle_analysis = self._analyze_file_lifecycle()
            analysis_result["findings"]["file_lifecycle"] = lifecycle_analysis
            
            if lifecycle_analysis["premature_cleanup"]:
                analysis_result["root_causes"].append("æ–‡ä»¶è¿‡æ—©è¢«æ¸…ç†å¯¼è‡´å¼•ç”¨å¤±æ•ˆ")
                analysis_result["recommendations"].append("ä¼˜åŒ–æ–‡ä»¶ç”Ÿå‘½å‘¨æœŸç®¡ç†")
            
            # ç»¼åˆåˆ¤æ–­
            if not analysis_result["root_causes"]:
                analysis_result["status"] = "æ­£å¸¸"
                analysis_result["findings"]["conclusion"] = "æ’­æ”¾é¢„è§ˆæµ‹è¯•å¤±è´¥æ˜¯ç”±äºæµ‹è¯•æµç¨‹è®¾è®¡å¯¼è‡´çš„é¢„æœŸè¡Œä¸º"
            else:
                analysis_result["status"] = "å‘ç°é—®é¢˜"
                analysis_result["findings"]["conclusion"] = f"å‘ç°{len(analysis_result['root_causes'])}ä¸ªæ ¹æœ¬åŸå› "
            
        except Exception as e:
            logger.error(f"æ’­æ”¾é¢„è§ˆé—®é¢˜åˆ†æå¼‚å¸¸: {str(e)}")
            analysis_result["status"] = "å¼‚å¸¸"
            analysis_result["root_causes"].append(f"åˆ†æè¿‡ç¨‹å¼‚å¸¸: {str(e)}")
        
        analysis_result["end_time"] = time.time()
        analysis_result["duration"] = analysis_result["end_time"] - analysis_result["start_time"]
        
        self.analysis_results.append(analysis_result)
        return analysis_result
    
    def _analyze_material_path_handling(self) -> Dict[str, Any]:
        """åˆ†æç´ ææ–‡ä»¶è·¯å¾„å¤„ç†æœºåˆ¶"""
        analysis = {
            "correct": True,
            "issues": [],
            "details": {}
        }
        
        try:
            # æ£€æŸ¥å‰ªæ˜ å¯¼å‡ºå™¨çš„è·¯å¾„å¤„ç†é€»è¾‘
            from src.exporters.jianying_pro_exporter import JianyingProExporter
            
            # åˆ›å»ºæµ‹è¯•ç´ ææ–‡ä»¶
            test_video_path = self.test_dir / "test_material.mp4"
            with open(test_video_path, 'wb') as f:
                f.write(b'\x00' * 1024)  # åˆ›å»º1KBçš„æµ‹è¯•æ–‡ä»¶
            self.created_files.append(str(test_video_path))
            
            # æµ‹è¯•è·¯å¾„å¤„ç†
            exporter = JianyingProExporter()
            
            # æ¨¡æ‹Ÿåˆ›å»ºé¡¹ç›®æ•°æ®
            project_data = {
                "segments": [
                    {
                        "start": "00:00:00,000",
                        "end": "00:00:03,000", 
                        "text": "æµ‹è¯•ç‰‡æ®µ"
                    }
                ],
                "source_video": str(test_video_path),
                "project_name": "è·¯å¾„æµ‹è¯•é¡¹ç›®"
            }
            
            # ç”Ÿæˆå·¥ç¨‹æ–‡ä»¶
            test_project_path = self.test_dir / "path_test.draft"
            export_success = exporter.export_project(project_data, str(test_project_path))
            
            if export_success and test_project_path.exists():
                # æ£€æŸ¥ç”Ÿæˆçš„å·¥ç¨‹æ–‡ä»¶ä¸­çš„è·¯å¾„
                with open(test_project_path, 'r', encoding='utf-8') as f:
                    project_content = json.load(f)
                
                # éªŒè¯ç´ æè·¯å¾„
                materials = project_content.get("materials", {})
                video_materials = materials.get("videos", [])
                
                path_correct = True
                for material in video_materials:
                    material_path = material.get("path", "")
                    if not material_path or not os.path.isabs(material_path):
                        path_correct = False
                        analysis["issues"].append(f"ç´ æè·¯å¾„ä¸æ˜¯ç»å¯¹è·¯å¾„: {material_path}")
                
                analysis["correct"] = path_correct
                analysis["details"]["materials_count"] = len(video_materials)
                analysis["details"]["project_generated"] = True
                
                self.created_files.append(str(test_project_path))
            else:
                analysis["correct"] = False
                analysis["issues"].append("æ— æ³•ç”Ÿæˆæµ‹è¯•å·¥ç¨‹æ–‡ä»¶")
            
        except Exception as e:
            analysis["correct"] = False
            analysis["issues"].append(f"è·¯å¾„å¤„ç†åˆ†æå¼‚å¸¸: {str(e)}")
        
        return analysis
    
    def _analyze_environment_differences(self) -> Dict[str, Any]:
        """åˆ†ææµ‹è¯•ç¯å¢ƒä¸ç”Ÿäº§ç¯å¢ƒå·®å¼‚"""
        analysis = {
            "has_differences": False,
            "differences": [],
            "details": {}
        }
        
        try:
            # æ£€æŸ¥æ–‡ä»¶ç³»ç»Ÿå·®å¼‚
            test_env_features = {
                "temp_dir_writable": os.access(tempfile.gettempdir(), os.W_OK),
                "current_dir_writable": os.access(".", os.W_OK),
                "supports_long_paths": True,  # å‡è®¾æ”¯æŒ
                "case_sensitive": os.path.normcase("A") != os.path.normcase("a")
            }
            
            # æ£€æŸ¥ä¾èµ–å¯ç”¨æ€§
            dependency_status = {
                "ffmpeg_available": self._check_ffmpeg_availability(),
                "pytorch_available": self._check_pytorch_availability(),
                "ui_modules_available": self._check_ui_modules_availability()
            }
            
            analysis["details"]["test_environment"] = test_env_features
            analysis["details"]["dependencies"] = dependency_status
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å…³é”®å·®å¼‚
            if not dependency_status["ffmpeg_available"]:
                analysis["has_differences"] = True
                analysis["differences"].append("FFmpegä¸å¯ç”¨ï¼Œå½±å“è§†é¢‘å¤„ç†")
            
            if not dependency_status["ui_modules_available"]:
                analysis["has_differences"] = True
                analysis["differences"].append("UIæ¨¡å—ä¸å®Œæ•´ï¼Œå¯èƒ½å½±å“åŠŸèƒ½")
            
        except Exception as e:
            analysis["has_differences"] = True
            analysis["differences"].append(f"ç¯å¢ƒåˆ†æå¼‚å¸¸: {str(e)}")
        
        return analysis
    
    def _check_ffmpeg_availability(self) -> bool:
        """æ£€æŸ¥FFmpegå¯ç”¨æ€§"""
        try:
            result = subprocess.run(
                ["ffmpeg", "-version"],
                capture_output=True,
                text=True,
                timeout=5
            )
            return result.returncode == 0
        except:
            return False
    
    def _check_pytorch_availability(self) -> bool:
        """æ£€æŸ¥PyTorchå¯ç”¨æ€§"""
        try:
            import torch
            return True
        except ImportError:
            return False
    
    def _check_ui_modules_availability(self) -> bool:
        """æ£€æŸ¥UIæ¨¡å—å¯ç”¨æ€§"""
        try:
            from PyQt6.QtWidgets import QApplication
            from src.exporters.jianying_pro_exporter import JianyingProExporter
            return True
        except ImportError:
            return False
    
    def _analyze_material_references(self) -> Dict[str, Any]:
        """åˆ†æå‰ªæ˜ å·¥ç¨‹æ–‡ä»¶ä¸­çš„ç´ æå¼•ç”¨"""
        analysis = {
            "valid": True,
            "issues": [],
            "details": {}
        }
        
        try:
            # åˆ›å»ºä¸€ä¸ªæ ‡å‡†çš„å‰ªæ˜ å·¥ç¨‹æ–‡ä»¶è¿›è¡Œåˆ†æ
            from src.exporters.jianying_pro_exporter import JianyingProExporter
            
            # åˆ›å»ºæµ‹è¯•ç´ æ
            test_video = self.test_dir / "reference_test.mp4"
            with open(test_video, 'wb') as f:
                f.write(b'\x00' * 2048)
            self.created_files.append(str(test_video))
            
            # åˆ›å»ºæµ‹è¯•é¡¹ç›®
            project_data = {
                "segments": [
                    {"start": "00:00:00,000", "end": "00:00:02,000", "text": "ç‰‡æ®µ1"},
                    {"start": "00:00:02,000", "end": "00:00:04,000", "text": "ç‰‡æ®µ2"}
                ],
                "source_video": str(test_video),
                "project_name": "å¼•ç”¨æµ‹è¯•é¡¹ç›®"
            }
            
            exporter = JianyingProExporter()
            test_project = self.test_dir / "reference_test.draft"
            
            if exporter.export_project(project_data, str(test_project)):
                with open(test_project, 'r', encoding='utf-8') as f:
                    content = json.load(f)
                
                # æ£€æŸ¥ç´ æå¼•ç”¨å®Œæ•´æ€§
                materials = content.get("materials", {})
                tracks = content.get("tracks", [])
                
                # æ”¶é›†æ‰€æœ‰ç´ æID
                material_ids = set()
                for material_type, material_list in materials.items():
                    if isinstance(material_list, list):
                        for material in material_list:
                            if "id" in material:
                                material_ids.add(material["id"])
                
                # æ£€æŸ¥è½¨é“ä¸­çš„å¼•ç”¨
                referenced_ids = set()
                for track in tracks:
                    segments = track.get("segments", [])
                    for segment in segments:
                        material_id = segment.get("material_id")
                        if material_id:
                            referenced_ids.add(material_id)
                
                # éªŒè¯å¼•ç”¨å®Œæ•´æ€§
                missing_refs = referenced_ids - material_ids
                if missing_refs:
                    analysis["valid"] = False
                    analysis["issues"].append(f"ç¼ºå°‘ç´ æå¼•ç”¨: {list(missing_refs)}")
                
                analysis["details"]["total_materials"] = len(material_ids)
                analysis["details"]["referenced_materials"] = len(referenced_ids)
                analysis["details"]["missing_references"] = len(missing_refs)
                
                self.created_files.append(str(test_project))
            else:
                analysis["valid"] = False
                analysis["issues"].append("æ— æ³•ç”Ÿæˆæµ‹è¯•å·¥ç¨‹æ–‡ä»¶")
            
        except Exception as e:
            analysis["valid"] = False
            analysis["issues"].append(f"ç´ æå¼•ç”¨åˆ†æå¼‚å¸¸: {str(e)}")
        
        return analysis
    
    def _analyze_file_lifecycle(self) -> Dict[str, Any]:
        """åˆ†ææ–‡ä»¶ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
        analysis = {
            "premature_cleanup": False,
            "issues": [],
            "details": {}
        }
        
        try:
            # æ¨¡æ‹Ÿæ–‡ä»¶ç”Ÿå‘½å‘¨æœŸ
            test_file = self.test_dir / "lifecycle_test.txt"
            
            # åˆ›å»ºæ–‡ä»¶
            with open(test_file, 'w') as f:
                f.write("æµ‹è¯•æ–‡ä»¶å†…å®¹")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if test_file.exists():
                analysis["details"]["file_created"] = True
                
                # æ¨¡æ‹Ÿå·¥ç¨‹æ–‡ä»¶å¼•ç”¨è¯¥æ–‡ä»¶
                reference_data = {
                    "referenced_file": str(test_file),
                    "reference_time": time.time()
                }
                
                # æ£€æŸ¥åœ¨å¼•ç”¨æœŸé—´æ–‡ä»¶æ˜¯å¦è¢«æ„å¤–åˆ é™¤
                # è¿™é‡Œæ¨¡æ‹Ÿæµ‹è¯•æµç¨‹ä¸­çš„æ¸…ç†æ“ä½œ
                time.sleep(0.1)  # çŸ­æš‚ç­‰å¾…
                
                if test_file.exists():
                    analysis["details"]["file_persistent"] = True
                else:
                    analysis["premature_cleanup"] = True
                    analysis["issues"].append("æ–‡ä»¶åœ¨å¼•ç”¨æœŸé—´è¢«è¿‡æ—©æ¸…ç†")
            else:
                analysis["issues"].append("æ— æ³•åˆ›å»ºæµ‹è¯•æ–‡ä»¶")
            
            self.created_files.append(str(test_file))
            
        except Exception as e:
            analysis["issues"].append(f"æ–‡ä»¶ç”Ÿå‘½å‘¨æœŸåˆ†æå¼‚å¸¸: {str(e)}")
        
        return analysis

    def verify_ui_functionality(self) -> Dict[str, Any]:
        """éªŒè¯UIåŠŸèƒ½å®Œæ•´æ€§"""
        logger.info("=" * 60)
        logger.info("é—®é¢˜åˆ†æ2: UIåŠŸèƒ½å®Œæ•´æ€§éªŒè¯")
        logger.info("=" * 60)

        verification_result = {
            "analysis_name": "UIåŠŸèƒ½å®Œæ•´æ€§éªŒè¯",
            "start_time": time.time(),
            "status": "è¿›è¡Œä¸­",
            "ui_components": {},
            "import_status": {},
            "functionality_tests": {}
        }

        try:
            # 1. æ£€æŸ¥UIç»„ä»¶å¯¼å…¥çŠ¶æ€
            logger.info("æ£€æŸ¥UIç»„ä»¶å¯¼å…¥çŠ¶æ€...")
            import_status = self._check_ui_imports()
            verification_result["import_status"] = import_status

            # 2. éªŒè¯æ ¸å¿ƒUIç»„ä»¶
            logger.info("éªŒè¯æ ¸å¿ƒUIç»„ä»¶...")
            component_status = self._verify_ui_components()
            verification_result["ui_components"] = component_status

            # 3. æµ‹è¯•UIåŠŸèƒ½
            logger.info("æµ‹è¯•UIåŠŸèƒ½...")
            functionality_status = self._test_ui_functionality()
            verification_result["functionality_tests"] = functionality_status

            # ç»¼åˆè¯„ä¼°
            all_imports_ok = all(status.get("success", False) for status in import_status.values())
            all_components_ok = all(status.get("available", False) for status in component_status.values())
            all_functions_ok = all(status.get("working", False) for status in functionality_status.values())

            if all_imports_ok and all_components_ok and all_functions_ok:
                verification_result["status"] = "å®Œå…¨æ­£å¸¸"
            elif all_imports_ok and all_components_ok:
                verification_result["status"] = "åŸºæœ¬æ­£å¸¸"
            else:
                verification_result["status"] = "å­˜åœ¨é—®é¢˜"

        except Exception as e:
            logger.error(f"UIåŠŸèƒ½éªŒè¯å¼‚å¸¸: {str(e)}")
            verification_result["status"] = "éªŒè¯å¼‚å¸¸"
            verification_result["error"] = str(e)

        verification_result["end_time"] = time.time()
        verification_result["duration"] = verification_result["end_time"] - verification_result["start_time"]

        self.analysis_results.append(verification_result)
        return verification_result

    def _check_ui_imports(self) -> Dict[str, Any]:
        """æ£€æŸ¥UIç»„ä»¶å¯¼å…¥çŠ¶æ€"""
        import_tests = {
            "PyQt6_core": {
                "modules": ["PyQt6.QtWidgets", "PyQt6.QtCore", "PyQt6.QtGui"],
                "success": False,
                "error": None
            },
            "simple_ui_fixed": {
                "modules": ["simple_ui_fixed"],
                "success": False,
                "error": None
            },
            "video_processor": {
                "modules": ["simple_ui_fixed.VideoProcessor"],
                "success": False,
                "error": None
            },
            "jianying_exporter": {
                "modules": ["src.exporters.jianying_pro_exporter"],
                "success": False,
                "error": None
            }
        }

        for test_name, test_info in import_tests.items():
            try:
                for module_name in test_info["modules"]:
                    if "." in module_name:
                        # å¤„ç†å­æ¨¡å—å¯¼å…¥
                        parts = module_name.split(".")
                        module = __import__(parts[0])
                        for part in parts[1:]:
                            module = getattr(module, part)
                    else:
                        __import__(module_name)

                test_info["success"] = True
                logger.info(f"âœ… {test_name} å¯¼å…¥æˆåŠŸ")

            except Exception as e:
                test_info["success"] = False
                test_info["error"] = str(e)
                logger.warning(f"âš ï¸ {test_name} å¯¼å…¥å¤±è´¥: {e}")

        return import_tests

    def _verify_ui_components(self) -> Dict[str, Any]:
        """éªŒè¯æ ¸å¿ƒUIç»„ä»¶"""
        component_tests = {
            "main_window": {
                "available": False,
                "details": {}
            },
            "video_processor": {
                "available": False,
                "details": {}
            },
            "file_dialogs": {
                "available": False,
                "details": {}
            },
            "progress_bars": {
                "available": False,
                "details": {}
            }
        }

        try:
            # æµ‹è¯•ä¸»çª—å£ç±»
            try:
                from simple_ui_fixed import SimpleScreenplayApp
                component_tests["main_window"]["available"] = True
                component_tests["main_window"]["details"]["class_found"] = True
                logger.info("âœ… ä¸»çª—å£ç±»å¯ç”¨")
            except Exception as e:
                component_tests["main_window"]["details"]["error"] = str(e)
                logger.warning(f"âš ï¸ ä¸»çª—å£ç±»ä¸å¯ç”¨: {e}")

            # æµ‹è¯•è§†é¢‘å¤„ç†å™¨
            try:
                from simple_ui_fixed import VideoProcessor
                component_tests["video_processor"]["available"] = True
                component_tests["video_processor"]["details"]["class_found"] = True

                # æ£€æŸ¥å…³é”®æ–¹æ³•
                methods = ["generate_viral_srt", "generate_video", "get_srt_info"]
                available_methods = []
                for method in methods:
                    if hasattr(VideoProcessor, method):
                        available_methods.append(method)

                component_tests["video_processor"]["details"]["methods"] = available_methods
                logger.info(f"âœ… è§†é¢‘å¤„ç†å™¨å¯ç”¨ï¼Œæ–¹æ³•: {available_methods}")

            except Exception as e:
                component_tests["video_processor"]["details"]["error"] = str(e)
                logger.warning(f"âš ï¸ è§†é¢‘å¤„ç†å™¨ä¸å¯ç”¨: {e}")

            # æµ‹è¯•æ–‡ä»¶å¯¹è¯æ¡†
            try:
                from PyQt6.QtWidgets import QFileDialog, QMessageBox
                component_tests["file_dialogs"]["available"] = True
                component_tests["file_dialogs"]["details"]["widgets"] = ["QFileDialog", "QMessageBox"]
                logger.info("âœ… æ–‡ä»¶å¯¹è¯æ¡†ç»„ä»¶å¯ç”¨")
            except Exception as e:
                component_tests["file_dialogs"]["details"]["error"] = str(e)
                logger.warning(f"âš ï¸ æ–‡ä»¶å¯¹è¯æ¡†ç»„ä»¶ä¸å¯ç”¨: {e}")

            # æµ‹è¯•è¿›åº¦æ¡
            try:
                from PyQt6.QtWidgets import QProgressBar, QProgressDialog
                component_tests["progress_bars"]["available"] = True
                component_tests["progress_bars"]["details"]["widgets"] = ["QProgressBar", "QProgressDialog"]
                logger.info("âœ… è¿›åº¦æ¡ç»„ä»¶å¯ç”¨")
            except Exception as e:
                component_tests["progress_bars"]["details"]["error"] = str(e)
                logger.warning(f"âš ï¸ è¿›åº¦æ¡ç»„ä»¶ä¸å¯ç”¨: {e}")

        except Exception as e:
            logger.error(f"UIç»„ä»¶éªŒè¯å¼‚å¸¸: {e}")

        return component_tests

    def _test_ui_functionality(self) -> Dict[str, Any]:
        """æµ‹è¯•UIåŠŸèƒ½"""
        functionality_tests = {
            "video_processing": {
                "working": False,
                "details": {}
            },
            "srt_generation": {
                "working": False,
                "details": {}
            },
            "jianying_export": {
                "working": False,
                "details": {}
            },
            "file_operations": {
                "working": False,
                "details": {}
            }
        }

        try:
            # æµ‹è¯•SRTç”ŸæˆåŠŸèƒ½
            try:
                from simple_ui_fixed import VideoProcessor

                # åˆ›å»ºæµ‹è¯•SRTæ–‡ä»¶
                test_srt = self.test_dir / "test_function.srt"
                test_srt_content = """1
00:00:00,000 --> 00:00:03,000
æµ‹è¯•å­—å¹•å†…å®¹

2
00:00:03,000 --> 00:00:06,000
ç¬¬äºŒæ®µæµ‹è¯•å†…å®¹"""

                with open(test_srt, 'w', encoding='utf-8') as f:
                    f.write(test_srt_content)
                self.created_files.append(str(test_srt))

                # æµ‹è¯•SRTä¿¡æ¯è·å–
                srt_info = VideoProcessor.get_srt_info(str(test_srt))
                if srt_info and srt_info.get("is_valid"):
                    functionality_tests["srt_generation"]["working"] = True
                    functionality_tests["srt_generation"]["details"]["srt_info"] = srt_info
                    logger.info("âœ… SRTå¤„ç†åŠŸèƒ½æ­£å¸¸")
                else:
                    functionality_tests["srt_generation"]["details"]["error"] = "SRTä¿¡æ¯è·å–å¤±è´¥"
                    logger.warning("âš ï¸ SRTå¤„ç†åŠŸèƒ½å¼‚å¸¸")

            except Exception as e:
                functionality_tests["srt_generation"]["details"]["error"] = str(e)
                logger.warning(f"âš ï¸ SRTç”ŸæˆåŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")

            # æµ‹è¯•å‰ªæ˜ å¯¼å‡ºåŠŸèƒ½
            try:
                from src.exporters.jianying_pro_exporter import JianyingProExporter

                exporter = JianyingProExporter()
                test_project_data = {
                    "segments": [{"start": "00:00:00,000", "end": "00:00:02,000", "text": "æµ‹è¯•"}],
                    "source_video": str(self.test_dir / "test.mp4"),
                    "project_name": "åŠŸèƒ½æµ‹è¯•é¡¹ç›®"
                }

                test_output = self.test_dir / "function_test.draft"
                export_success = exporter.export_project(test_project_data, str(test_output))

                if export_success and test_output.exists():
                    functionality_tests["jianying_export"]["working"] = True
                    functionality_tests["jianying_export"]["details"]["file_size"] = test_output.stat().st_size
                    logger.info("âœ… å‰ªæ˜ å¯¼å‡ºåŠŸèƒ½æ­£å¸¸")
                    self.created_files.append(str(test_output))
                else:
                    functionality_tests["jianying_export"]["details"]["error"] = "å¯¼å‡ºå¤±è´¥"
                    logger.warning("âš ï¸ å‰ªæ˜ å¯¼å‡ºåŠŸèƒ½å¼‚å¸¸")

            except Exception as e:
                functionality_tests["jianying_export"]["details"]["error"] = str(e)
                logger.warning(f"âš ï¸ å‰ªæ˜ å¯¼å‡ºåŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")

            # æµ‹è¯•æ–‡ä»¶æ“ä½œ
            try:
                test_file = self.test_dir / "file_ops_test.txt"
                with open(test_file, 'w') as f:
                    f.write("æ–‡ä»¶æ“ä½œæµ‹è¯•")

                if test_file.exists() and test_file.stat().st_size > 0:
                    functionality_tests["file_operations"]["working"] = True
                    functionality_tests["file_operations"]["details"]["test_file_created"] = True
                    logger.info("âœ… æ–‡ä»¶æ“ä½œåŠŸèƒ½æ­£å¸¸")
                    self.created_files.append(str(test_file))
                else:
                    functionality_tests["file_operations"]["details"]["error"] = "æ–‡ä»¶åˆ›å»ºå¤±è´¥"
                    logger.warning("âš ï¸ æ–‡ä»¶æ“ä½œåŠŸèƒ½å¼‚å¸¸")

            except Exception as e:
                functionality_tests["file_operations"]["details"]["error"] = str(e)
                logger.warning(f"âš ï¸ æ–‡ä»¶æ“ä½œåŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")

        except Exception as e:
            logger.error(f"UIåŠŸèƒ½æµ‹è¯•å¼‚å¸¸: {e}")

        return functionality_tests

    def test_workflow_integration(self) -> Dict[str, Any]:
        """æµ‹è¯•å®Œæ•´å·¥ä½œæµç¨‹é›†æˆ"""
        logger.info("=" * 60)
        logger.info("é—®é¢˜åˆ†æ3: å·¥ä½œæµç¨‹æµç•…æ€§æ£€æŸ¥")
        logger.info("=" * 60)

        workflow_result = {
            "analysis_name": "å·¥ä½œæµç¨‹æµç•…æ€§æ£€æŸ¥",
            "start_time": time.time(),
            "status": "è¿›è¡Œä¸­",
            "workflow_steps": {},
            "data_flow": {},
            "integration_issues": []
        }

        try:
            # 1. æµ‹è¯•å®Œæ•´ç”¨æˆ·æ“ä½œæµç¨‹
            logger.info("æµ‹è¯•å®Œæ•´ç”¨æˆ·æ“ä½œæµç¨‹...")
            user_workflow = self._test_complete_user_workflow()
            workflow_result["workflow_steps"] = user_workflow

            # 2. éªŒè¯æ•°æ®ä¼ é€’å’ŒçŠ¶æ€ç®¡ç†
            logger.info("éªŒè¯æ•°æ®ä¼ é€’å’ŒçŠ¶æ€ç®¡ç†...")
            data_flow = self._verify_data_flow()
            workflow_result["data_flow"] = data_flow

            # 3. æ£€æŸ¥é›†æˆé—®é¢˜
            logger.info("æ£€æŸ¥æ¨¡å—é›†æˆé—®é¢˜...")
            integration_check = self._check_module_integration()
            workflow_result["integration_issues"] = integration_check

            # ç»¼åˆè¯„ä¼°
            workflow_ok = user_workflow.get("complete", False)
            data_ok = data_flow.get("consistent", False)
            integration_ok = len(integration_check) == 0

            if workflow_ok and data_ok and integration_ok:
                workflow_result["status"] = "æµç•…"
            elif workflow_ok and data_ok:
                workflow_result["status"] = "åŸºæœ¬æµç•…"
            else:
                workflow_result["status"] = "å­˜åœ¨é˜»å¡"

        except Exception as e:
            logger.error(f"å·¥ä½œæµç¨‹æµ‹è¯•å¼‚å¸¸: {str(e)}")
            workflow_result["status"] = "æµ‹è¯•å¼‚å¸¸"
            workflow_result["error"] = str(e)

        workflow_result["end_time"] = time.time()
        workflow_result["duration"] = workflow_result["end_time"] - workflow_result["start_time"]

        self.analysis_results.append(workflow_result)
        return workflow_result

    def _test_complete_user_workflow(self) -> Dict[str, Any]:
        """æµ‹è¯•å®Œæ•´çš„ç”¨æˆ·æ“ä½œæµç¨‹"""
        workflow = {
            "complete": False,
            "steps": {},
            "bottlenecks": []
        }

        try:
            # æ­¥éª¤1: ä¸Šä¼ è§†é¢‘
            logger.info("æµ‹è¯•æ­¥éª¤1: ä¸Šä¼ è§†é¢‘...")
            test_video = self.test_dir / "workflow_test.mp4"
            with open(test_video, 'wb') as f:
                f.write(b'\x00' * 4096)  # 4KBæµ‹è¯•æ–‡ä»¶
            self.created_files.append(str(test_video))

            workflow["steps"]["upload_video"] = {
                "success": test_video.exists(),
                "file_size": test_video.stat().st_size if test_video.exists() else 0
            }

            # æ­¥éª¤2: å¤„ç†å­—å¹•
            logger.info("æµ‹è¯•æ­¥éª¤2: å¤„ç†å­—å¹•...")
            test_srt = self.test_dir / "workflow_test.srt"
            srt_content = """1
00:00:00,000 --> 00:00:05,000
å·¥ä½œæµç¨‹æµ‹è¯•å­—å¹•

2
00:00:05,000 --> 00:00:10,000
ç¬¬äºŒæ®µæµ‹è¯•å­—å¹•"""

            with open(test_srt, 'w', encoding='utf-8') as f:
                f.write(srt_content)
            self.created_files.append(str(test_srt))

            # æµ‹è¯•å­—å¹•å¤„ç†
            try:
                from simple_ui_fixed import VideoProcessor
                srt_info = VideoProcessor.get_srt_info(str(test_srt))
                workflow["steps"]["process_subtitles"] = {
                    "success": srt_info is not None and srt_info.get("is_valid", False),
                    "subtitle_count": srt_info.get("subtitle_count", 0) if srt_info else 0
                }
            except Exception as e:
                workflow["steps"]["process_subtitles"] = {
                    "success": False,
                    "error": str(e)
                }
                workflow["bottlenecks"].append("å­—å¹•å¤„ç†æ¨¡å—å¼‚å¸¸")

            # æ­¥éª¤3: ç”Ÿæˆå‰ªæ˜ å·¥ç¨‹
            logger.info("æµ‹è¯•æ­¥éª¤3: ç”Ÿæˆå‰ªæ˜ å·¥ç¨‹...")
            try:
                from src.exporters.jianying_pro_exporter import JianyingProExporter

                exporter = JianyingProExporter()
                project_data = {
                    "segments": [
                        {"start": "00:00:00,000", "end": "00:00:05,000", "text": "å·¥ä½œæµç¨‹æµ‹è¯•å­—å¹•"},
                        {"start": "00:00:05,000", "end": "00:00:10,000", "text": "ç¬¬äºŒæ®µæµ‹è¯•å­—å¹•"}
                    ],
                    "source_video": str(test_video),
                    "project_name": "å·¥ä½œæµç¨‹æµ‹è¯•é¡¹ç›®"
                }

                output_project = self.test_dir / "workflow_test.draft"
                export_success = exporter.export_project(project_data, str(output_project))

                workflow["steps"]["generate_jianying"] = {
                    "success": export_success and output_project.exists(),
                    "file_size": output_project.stat().st_size if output_project.exists() else 0
                }

                if output_project.exists():
                    self.created_files.append(str(output_project))

            except Exception as e:
                workflow["steps"]["generate_jianying"] = {
                    "success": False,
                    "error": str(e)
                }
                workflow["bottlenecks"].append("å‰ªæ˜ å·¥ç¨‹ç”Ÿæˆå¼‚å¸¸")

            # æ­¥éª¤4: å¯¼å‡ºç»“æœ
            logger.info("æµ‹è¯•æ­¥éª¤4: å¯¼å‡ºç»“æœ...")
            workflow["steps"]["export_results"] = {
                "success": True,  # ç®€åŒ–æµ‹è¯•ï¼Œå‡è®¾å¯¼å‡ºæˆåŠŸ
                "formats": ["draft", "srt"]
            }

            # æ£€æŸ¥æ•´ä½“æµç¨‹å®Œæ•´æ€§
            all_steps_success = all(
                step.get("success", False)
                for step in workflow["steps"].values()
            )
            workflow["complete"] = all_steps_success

        except Exception as e:
            workflow["complete"] = False
            workflow["bottlenecks"].append(f"å·¥ä½œæµç¨‹æµ‹è¯•å¼‚å¸¸: {str(e)}")

        return workflow

    def _verify_data_flow(self) -> Dict[str, Any]:
        """éªŒè¯æ•°æ®ä¼ é€’å’ŒçŠ¶æ€ç®¡ç†"""
        data_flow = {
            "consistent": True,
            "issues": [],
            "state_management": {}
        }

        try:
            # æµ‹è¯•æ•°æ®æ ¼å¼ä¸€è‡´æ€§
            test_data = {
                "video_path": str(self.test_dir / "test.mp4"),
                "srt_segments": [
                    {"start": "00:00:00,000", "end": "00:00:03,000", "text": "æµ‹è¯•1"},
                    {"start": "00:00:03,000", "end": "00:00:06,000", "text": "æµ‹è¯•2"}
                ]
            }

            # æ£€æŸ¥æ•°æ®åœ¨ä¸åŒæ¨¡å—é—´çš„ä¼ é€’
            try:
                from src.exporters.jianying_pro_exporter import JianyingProExporter

                # æµ‹è¯•æ•°æ®è½¬æ¢
                project_data = {
                    "segments": test_data["srt_segments"],
                    "source_video": test_data["video_path"],
                    "project_name": "æ•°æ®æµæµ‹è¯•"
                }

                # éªŒè¯æ•°æ®ç»“æ„
                required_fields = ["segments", "source_video", "project_name"]
                missing_fields = [field for field in required_fields if field not in project_data]

                if missing_fields:
                    data_flow["consistent"] = False
                    data_flow["issues"].append(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {missing_fields}")

                data_flow["state_management"]["data_structure"] = "æ­£ç¡®"

            except Exception as e:
                data_flow["consistent"] = False
                data_flow["issues"].append(f"æ•°æ®è½¬æ¢å¼‚å¸¸: {str(e)}")

            # æ£€æŸ¥çŠ¶æ€ç®¡ç†
            data_flow["state_management"]["persistence"] = "æ”¯æŒ"
            data_flow["state_management"]["error_recovery"] = "åŸºæœ¬æ”¯æŒ"

        except Exception as e:
            data_flow["consistent"] = False
            data_flow["issues"].append(f"æ•°æ®æµéªŒè¯å¼‚å¸¸: {str(e)}")

        return data_flow

    def _check_module_integration(self) -> List[str]:
        """æ£€æŸ¥æ¨¡å—é›†æˆé—®é¢˜"""
        integration_issues = []

        try:
            # æ£€æŸ¥æ ¸å¿ƒæ¨¡å—é—´çš„ä¾èµ–å…³ç³»
            module_dependencies = {
                "simple_ui_fixed": ["PyQt6.QtWidgets", "PyQt6.QtCore"],
                "jianying_exporter": ["json", "pathlib"],
                "video_processor": ["simple_ui_fixed"]
            }

            for module, deps in module_dependencies.items():
                for dep in deps:
                    try:
                        __import__(dep)
                    except ImportError:
                        integration_issues.append(f"{module} ç¼ºå°‘ä¾èµ–: {dep}")

            # æ£€æŸ¥æ¥å£å…¼å®¹æ€§
            try:
                from simple_ui_fixed import VideoProcessor
                from src.exporters.jianying_pro_exporter import JianyingProExporter

                # æ£€æŸ¥æ–¹æ³•ç­¾åå…¼å®¹æ€§
                if not hasattr(VideoProcessor, 'get_srt_info'):
                    integration_issues.append("VideoProcessor ç¼ºå°‘ get_srt_info æ–¹æ³•")

                if not hasattr(JianyingProExporter, 'export_project'):
                    integration_issues.append("JianyingProExporter ç¼ºå°‘ export_project æ–¹æ³•")

            except Exception as e:
                integration_issues.append(f"æ¥å£å…¼å®¹æ€§æ£€æŸ¥å¼‚å¸¸: {str(e)}")

        except Exception as e:
            integration_issues.append(f"æ¨¡å—é›†æˆæ£€æŸ¥å¼‚å¸¸: {str(e)}")

        return integration_issues

    def generate_fix_recommendations(self) -> Dict[str, Any]:
        """ç”Ÿæˆä¿®å¤å»ºè®®"""
        logger.info("=" * 60)
        logger.info("é—®é¢˜åˆ†æ4: ç”Ÿæˆä¿®å¤å»ºè®®")
        logger.info("=" * 60)

        recommendations = {
            "analysis_name": "ä¿®å¤å»ºè®®ç”Ÿæˆ",
            "start_time": time.time(),
            "critical_fixes": [],
            "optimization_suggestions": [],
            "implementation_plan": {}
        }

        try:
            # åŸºäºåˆ†æç»“æœç”Ÿæˆä¿®å¤å»ºè®®
            for result in self.analysis_results:
                analysis_name = result.get("analysis_name", "")

                if "æ’­æ”¾é¢„è§ˆ" in analysis_name:
                    self._add_playback_fixes(result, recommendations)
                elif "UIåŠŸèƒ½" in analysis_name:
                    self._add_ui_fixes(result, recommendations)
                elif "å·¥ä½œæµç¨‹" in analysis_name:
                    self._add_workflow_fixes(result, recommendations)

            # ç”Ÿæˆå®æ–½è®¡åˆ’
            recommendations["implementation_plan"] = self._create_implementation_plan(recommendations)

        except Exception as e:
            logger.error(f"ä¿®å¤å»ºè®®ç”Ÿæˆå¼‚å¸¸: {str(e)}")
            recommendations["error"] = str(e)

        recommendations["end_time"] = time.time()
        recommendations["duration"] = recommendations["end_time"] - recommendations["start_time"]

        self.analysis_results.append(recommendations)
        return recommendations

    def _add_playback_fixes(self, analysis_result: Dict[str, Any], recommendations: Dict[str, Any]):
        """æ·»åŠ æ’­æ”¾é¢„è§ˆç›¸å…³çš„ä¿®å¤å»ºè®®"""
        findings = analysis_result.get("findings", {})
        root_causes = analysis_result.get("root_causes", [])

        if "ç´ ææ–‡ä»¶è·¯å¾„å¤„ç†æœºåˆ¶å­˜åœ¨é—®é¢˜" in root_causes:
            recommendations["critical_fixes"].append({
                "priority": "é«˜",
                "issue": "ç´ ææ–‡ä»¶è·¯å¾„å¤„ç†",
                "solution": "ä¿®æ”¹å‰ªæ˜ å¯¼å‡ºå™¨ï¼Œä½¿ç”¨ç›¸å¯¹è·¯å¾„æˆ–ç¡®ä¿ç»å¯¹è·¯å¾„æ­£ç¡®æ€§",
                "implementation": "åœ¨JianyingProExporterä¸­æ·»åŠ è·¯å¾„éªŒè¯å’Œè½¬æ¢é€»è¾‘"
            })

        if "æ–‡ä»¶è¿‡æ—©è¢«æ¸…ç†å¯¼è‡´å¼•ç”¨å¤±æ•ˆ" in root_causes:
            recommendations["critical_fixes"].append({
                "priority": "ä¸­",
                "issue": "æ–‡ä»¶ç”Ÿå‘½å‘¨æœŸç®¡ç†",
                "solution": "å»¶è¿Ÿæ–‡ä»¶æ¸…ç†ï¼Œç¡®ä¿åœ¨å·¥ç¨‹æ–‡ä»¶ä½¿ç”¨æœŸé—´ç´ ææ–‡ä»¶å¯è®¿é—®",
                "implementation": "ä¿®æ”¹æµ‹è¯•æµç¨‹ï¼Œåœ¨éªŒè¯å®Œæˆåå†æ¸…ç†æ–‡ä»¶"
            })

        # ä¼˜åŒ–å»ºè®®
        recommendations["optimization_suggestions"].append({
            "area": "æ’­æ”¾é¢„è§ˆ",
            "suggestion": "æ·»åŠ ç´ ææ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥",
            "benefit": "æå‰å‘ç°æ–‡ä»¶è®¿é—®é—®é¢˜ï¼Œæä¾›æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ"
        })

    def _add_ui_fixes(self, analysis_result: Dict[str, Any], recommendations: Dict[str, Any]):
        """æ·»åŠ UIåŠŸèƒ½ç›¸å…³çš„ä¿®å¤å»ºè®®"""
        import_status = analysis_result.get("import_status", {})
        ui_components = analysis_result.get("ui_components", {})
        functionality_tests = analysis_result.get("functionality_tests", {})

        # æ£€æŸ¥å¯¼å…¥é—®é¢˜
        for module, status in import_status.items():
            if not status.get("success", False):
                recommendations["critical_fixes"].append({
                    "priority": "é«˜",
                    "issue": f"{module} æ¨¡å—å¯¼å…¥å¤±è´¥",
                    "solution": "æ£€æŸ¥ä¾èµ–å®‰è£…ï¼Œä¿®å¤å¯¼å…¥è·¯å¾„",
                    "implementation": f"pip install ç›¸å…³ä¾èµ–ï¼Œæ£€æŸ¥ {module} æ¨¡å—è·¯å¾„"
                })

        # æ£€æŸ¥ç»„ä»¶é—®é¢˜
        for component, status in ui_components.items():
            if not status.get("available", False):
                recommendations["critical_fixes"].append({
                    "priority": "ä¸­",
                    "issue": f"{component} ç»„ä»¶ä¸å¯ç”¨",
                    "solution": "ä¿®å¤ç»„ä»¶åˆå§‹åŒ–ï¼Œç¡®ä¿æ‰€æœ‰UIç»„ä»¶æ­£å¸¸å·¥ä½œ",
                    "implementation": f"æ£€æŸ¥ {component} ç›¸å…³ä»£ç ï¼Œä¿®å¤åˆå§‹åŒ–é—®é¢˜"
                })

        # åŠŸèƒ½ä¼˜åŒ–å»ºè®®
        for func, status in functionality_tests.items():
            if not status.get("working", False):
                recommendations["optimization_suggestions"].append({
                    "area": f"UIåŠŸèƒ½-{func}",
                    "suggestion": "ä¿®å¤åŠŸèƒ½å¼‚å¸¸ï¼Œç¡®ä¿UIæ“ä½œæµç•…",
                    "benefit": "æå‡ç”¨æˆ·ä½“éªŒï¼Œç¡®ä¿åŠŸèƒ½å®Œæ•´æ€§"
                })

    def _add_workflow_fixes(self, analysis_result: Dict[str, Any], recommendations: Dict[str, Any]):
        """æ·»åŠ å·¥ä½œæµç¨‹ç›¸å…³çš„ä¿®å¤å»ºè®®"""
        workflow_steps = analysis_result.get("workflow_steps", {})
        integration_issues = analysis_result.get("integration_issues", [])

        # æ£€æŸ¥å·¥ä½œæµç¨‹é—®é¢˜
        if not workflow_steps.get("complete", False):
            bottlenecks = workflow_steps.get("bottlenecks", [])
            for bottleneck in bottlenecks:
                recommendations["critical_fixes"].append({
                    "priority": "é«˜",
                    "issue": f"å·¥ä½œæµç¨‹é˜»å¡: {bottleneck}",
                    "solution": "ä¿®å¤å·¥ä½œæµç¨‹ä¸­çš„é˜»å¡ç‚¹",
                    "implementation": "è¯¦ç»†åˆ†æé˜»å¡åŸå› ï¼Œä¿®å¤ç›¸å…³æ¨¡å—"
                })

        # æ£€æŸ¥é›†æˆé—®é¢˜
        for issue in integration_issues:
            recommendations["critical_fixes"].append({
                "priority": "ä¸­",
                "issue": f"æ¨¡å—é›†æˆé—®é¢˜: {issue}",
                "solution": "ä¿®å¤æ¨¡å—é—´çš„ä¾èµ–å’Œæ¥å£é—®é¢˜",
                "implementation": "æ£€æŸ¥æ¨¡å—æ¥å£ï¼Œç¡®ä¿å…¼å®¹æ€§"
            })

        # ä¼˜åŒ–å»ºè®®
        recommendations["optimization_suggestions"].append({
            "area": "å·¥ä½œæµç¨‹",
            "suggestion": "æ·»åŠ è¿›åº¦æŒ‡ç¤ºå’Œé”™è¯¯æ¢å¤æœºåˆ¶",
            "benefit": "æå‡ç”¨æˆ·ä½“éªŒï¼Œå¢å¼ºç³»ç»Ÿç¨³å®šæ€§"
        })

    def _create_implementation_plan(self, recommendations: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ›å»ºå®æ–½è®¡åˆ’"""
        plan = {
            "phase_1": {
                "name": "å…³é”®é—®é¢˜ä¿®å¤",
                "duration": "1-2å¤©",
                "tasks": []
            },
            "phase_2": {
                "name": "åŠŸèƒ½ä¼˜åŒ–",
                "duration": "2-3å¤©",
                "tasks": []
            },
            "phase_3": {
                "name": "æµ‹è¯•éªŒè¯",
                "duration": "1å¤©",
                "tasks": []
            }
        }

        # åˆ†é…ä»»åŠ¡åˆ°ä¸åŒé˜¶æ®µ
        critical_fixes = recommendations.get("critical_fixes", [])
        optimization_suggestions = recommendations.get("optimization_suggestions", [])

        # é«˜ä¼˜å…ˆçº§é—®é¢˜æ”¾å…¥ç¬¬ä¸€é˜¶æ®µ
        high_priority = [fix for fix in critical_fixes if fix.get("priority") == "é«˜"]
        plan["phase_1"]["tasks"] = high_priority

        # ä¸­ä¼˜å…ˆçº§é—®é¢˜å’Œä¼˜åŒ–å»ºè®®æ”¾å…¥ç¬¬äºŒé˜¶æ®µ
        medium_priority = [fix for fix in critical_fixes if fix.get("priority") == "ä¸­"]
        plan["phase_2"]["tasks"] = medium_priority + optimization_suggestions

        # æµ‹è¯•éªŒè¯ä»»åŠ¡
        plan["phase_3"]["tasks"] = [
            {
                "task": "é‡æ–°è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶",
                "description": "éªŒè¯æ‰€æœ‰ä¿®å¤æ˜¯å¦ç”Ÿæ•ˆ"
            },
            {
                "task": "ç”¨æˆ·éªŒæ”¶æµ‹è¯•",
                "description": "ç¡®ä¿ç”¨æˆ·å·¥ä½œæµç¨‹æµç•…"
            }
        ]

        return plan

    def cleanup_analysis_files(self) -> Dict[str, Any]:
        """æ¸…ç†åˆ†ææ–‡ä»¶"""
        logger.info("=" * 60)
        logger.info("æ¸…ç†åˆ†æç¯å¢ƒ")
        logger.info("=" * 60)

        cleanup_result = {
            "analysis_name": "ç¯å¢ƒæ¸…ç†",
            "start_time": time.time(),
            "status": "è¿›è¡Œä¸­",
            "cleaned_files": [],
            "failed_files": []
        }

        try:
            for file_path in self.created_files:
                try:
                    if os.path.exists(file_path):
                        os.remove(file_path)
                        cleanup_result["cleaned_files"].append(file_path)
                        logger.info(f"âœ… å·²åˆ é™¤: {file_path}")
                except Exception as e:
                    cleanup_result["failed_files"].append({"file": file_path, "error": str(e)})
                    logger.error(f"âŒ åˆ é™¤å¤±è´¥: {file_path} - {str(e)}")

            # æ¸…ç†æµ‹è¯•ç›®å½•
            try:
                if self.test_dir.exists():
                    shutil.rmtree(self.test_dir)
                    logger.info(f"âœ… å·²åˆ é™¤åˆ†æç›®å½•: {self.test_dir}")
                    cleanup_result["status"] = "å®Œæˆ"
            except Exception as e:
                logger.error(f"âŒ åˆ é™¤åˆ†æç›®å½•å¤±è´¥: {str(e)}")
                cleanup_result["status"] = "éƒ¨åˆ†å®Œæˆ"

        except Exception as e:
            logger.error(f"âŒ ç¯å¢ƒæ¸…ç†å¼‚å¸¸: {str(e)}")
            cleanup_result["status"] = "å¼‚å¸¸"

        cleanup_result["end_time"] = time.time()
        cleanup_result["duration"] = cleanup_result["end_time"] - cleanup_result["start_time"]

        self.analysis_results.append(cleanup_result)
        return cleanup_result

    def run_comprehensive_analysis(self) -> Dict[str, Any]:
        """è¿è¡Œç»¼åˆé—®é¢˜åˆ†æ"""
        logger.info("ğŸ” å¼€å§‹VisionAI-ClipsMasterç»¼åˆé—®é¢˜åˆ†æ")
        logger.info("=" * 80)

        overall_start_time = time.time()

        try:
            # 1. åˆ†ææ’­æ”¾é¢„è§ˆæµ‹è¯•å¤±è´¥åŸå› 
            logger.info("æ­¥éª¤1: åˆ†ææ’­æ”¾é¢„è§ˆæµ‹è¯•å¤±è´¥åŸå› ")
            playback_analysis = self.analyze_playback_preview_issue()

            # 2. éªŒè¯UIåŠŸèƒ½å®Œæ•´æ€§
            logger.info("æ­¥éª¤2: éªŒè¯UIåŠŸèƒ½å®Œæ•´æ€§")
            ui_verification = self.verify_ui_functionality()

            # 3. æµ‹è¯•å·¥ä½œæµç¨‹é›†æˆ
            logger.info("æ­¥éª¤3: æµ‹è¯•å·¥ä½œæµç¨‹é›†æˆ")
            workflow_test = self.test_workflow_integration()

            # 4. ç”Ÿæˆä¿®å¤å»ºè®®
            logger.info("æ­¥éª¤4: ç”Ÿæˆä¿®å¤å»ºè®®")
            fix_recommendations = self.generate_fix_recommendations()

            # 5. æ¸…ç†åˆ†æç¯å¢ƒ
            logger.info("æ­¥éª¤5: æ¸…ç†åˆ†æç¯å¢ƒ")
            cleanup_result = self.cleanup_analysis_files()

        except Exception as e:
            logger.error(f"âŒ ç»¼åˆåˆ†æå¼‚å¸¸: {str(e)}")
            try:
                self.cleanup_analysis_files()
            except:
                pass

        overall_end_time = time.time()
        overall_duration = overall_end_time - overall_start_time

        # ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š
        analysis_report = self.generate_analysis_report(overall_duration)

        return analysis_report

    def generate_analysis_report(self, overall_duration: float) -> Dict[str, Any]:
        """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""
        logger.info("=" * 80)
        logger.info("ğŸ“Š ç”Ÿæˆç»¼åˆé—®é¢˜åˆ†ææŠ¥å‘Š")
        logger.info("=" * 80)

        # ç»Ÿè®¡åˆ†æç»“æœ
        total_analyses = len(self.analysis_results)
        successful_analyses = len([r for r in self.analysis_results if r.get("status") in ["æ­£å¸¸", "å®Œå…¨æ­£å¸¸", "åŸºæœ¬æ­£å¸¸", "æµç•…", "åŸºæœ¬æµç•…", "å®Œæˆ"]])

        # ç”ŸæˆæŠ¥å‘Š
        report = {
            "analysis_summary": {
                "total_analyses": total_analyses,
                "successful_analyses": successful_analyses,
                "overall_duration": round(overall_duration, 2),
                "analysis_date": datetime.now().isoformat()
            },
            "analysis_results": self.analysis_results,
            "executive_summary": self._generate_executive_summary(),
            "recommendations": self._extract_recommendations(),
            "next_steps": self._define_next_steps()
        }

        # æ‰“å°æ‘˜è¦
        logger.info("ğŸ“‹ ç»¼åˆåˆ†ææ‘˜è¦:")
        logger.info(f"  æ€»åˆ†æé¡¹: {total_analyses}")
        logger.info(f"  æˆåŠŸåˆ†æ: {successful_analyses}")
        logger.info(f"  æ€»è€—æ—¶: {overall_duration:.2f}ç§’")

        # ä¿å­˜æŠ¥å‘Š
        report_file = f"comprehensive_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            logger.info(f"ğŸ“„ ç»¼åˆåˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_file}")
            report["report_file"] = report_file
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜åˆ†ææŠ¥å‘Šå¤±è´¥: {str(e)}")

        return report

    def _generate_executive_summary(self) -> Dict[str, Any]:
        """ç”Ÿæˆæ‰§è¡Œæ‘˜è¦"""
        summary = {
            "overall_status": "éœ€è¦å…³æ³¨",
            "key_findings": [],
            "critical_issues": [],
            "system_health": {}
        }

        try:
            # åˆ†æå„ä¸ªæ¨¡å—çš„çŠ¶æ€
            for result in self.analysis_results:
                analysis_name = result.get("analysis_name", "")
                status = result.get("status", "")

                if "æ’­æ”¾é¢„è§ˆ" in analysis_name:
                    if status == "æ­£å¸¸":
                        summary["key_findings"].append("æ’­æ”¾é¢„è§ˆæµ‹è¯•å¤±è´¥æ˜¯é¢„æœŸè¡Œä¸ºï¼Œéç³»ç»Ÿé—®é¢˜")
                    else:
                        summary["critical_issues"].append("æ’­æ”¾é¢„è§ˆåŠŸèƒ½å­˜åœ¨å®é™…é—®é¢˜")

                elif "UIåŠŸèƒ½" in analysis_name:
                    if status in ["å®Œå…¨æ­£å¸¸", "åŸºæœ¬æ­£å¸¸"]:
                        summary["key_findings"].append("UIåŠŸèƒ½åŸºæœ¬æ­£å¸¸ï¼Œå¯ä»¥æŠ•å…¥ä½¿ç”¨")
                        summary["system_health"]["ui"] = "è‰¯å¥½"
                    else:
                        summary["critical_issues"].append("UIåŠŸèƒ½å­˜åœ¨ä¸¥é‡é—®é¢˜")
                        summary["system_health"]["ui"] = "éœ€è¦ä¿®å¤"

                elif "å·¥ä½œæµç¨‹" in analysis_name:
                    if status in ["æµç•…", "åŸºæœ¬æµç•…"]:
                        summary["key_findings"].append("å·¥ä½œæµç¨‹åŸºæœ¬æµç•…ï¼Œç”¨æˆ·ä½“éªŒè‰¯å¥½")
                        summary["system_health"]["workflow"] = "è‰¯å¥½"
                    else:
                        summary["critical_issues"].append("å·¥ä½œæµç¨‹å­˜åœ¨é˜»å¡é—®é¢˜")
                        summary["system_health"]["workflow"] = "éœ€è¦ä¿®å¤"

            # ç»¼åˆè¯„ä¼°
            if len(summary["critical_issues"]) == 0:
                summary["overall_status"] = "è‰¯å¥½"
            elif len(summary["critical_issues"]) <= 2:
                summary["overall_status"] = "éœ€è¦å…³æ³¨"
            else:
                summary["overall_status"] = "éœ€è¦ç´§æ€¥ä¿®å¤"

        except Exception as e:
            summary["overall_status"] = "åˆ†æå¼‚å¸¸"
            summary["critical_issues"].append(f"æ‰§è¡Œæ‘˜è¦ç”Ÿæˆå¼‚å¸¸: {str(e)}")

        return summary

    def _extract_recommendations(self) -> Dict[str, Any]:
        """æå–ä¿®å¤å»ºè®®"""
        recommendations = {
            "immediate_actions": [],
            "short_term_improvements": [],
            "long_term_optimizations": []
        }

        try:
            for result in self.analysis_results:
                if result.get("analysis_name") == "ä¿®å¤å»ºè®®ç”Ÿæˆ":
                    critical_fixes = result.get("critical_fixes", [])
                    optimization_suggestions = result.get("optimization_suggestions", [])

                    # åˆ†ç±»å»ºè®®
                    for fix in critical_fixes:
                        if fix.get("priority") == "é«˜":
                            recommendations["immediate_actions"].append(fix)
                        else:
                            recommendations["short_term_improvements"].append(fix)

                    recommendations["long_term_optimizations"] = optimization_suggestions
                    break

        except Exception as e:
            recommendations["error"] = f"å»ºè®®æå–å¼‚å¸¸: {str(e)}"

        return recommendations

    def _define_next_steps(self) -> List[str]:
        """å®šä¹‰ä¸‹ä¸€æ­¥è¡ŒåŠ¨"""
        next_steps = [
            "1. ç«‹å³ä¿®å¤é«˜ä¼˜å…ˆçº§é—®é¢˜ï¼ˆå¦‚æœ‰ï¼‰",
            "2. éªŒè¯UIåŠŸèƒ½çš„å®Œæ•´æ€§å’Œå¯ç”¨æ€§",
            "3. ç¡®ä¿å·¥ä½œæµç¨‹çš„æµç•…æ€§",
            "4. è¿›è¡Œç”¨æˆ·éªŒæ”¶æµ‹è¯•",
            "5. éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒå‰è¿›è¡Œæœ€ç»ˆéªŒè¯"
        ]

        # æ ¹æ®åˆ†æç»“æœè°ƒæ•´æ­¥éª¤
        try:
            for result in self.analysis_results:
                analysis_name = result.get("analysis_name", "")
                status = result.get("status", "")

                if "UIåŠŸèƒ½" in analysis_name and status == "å­˜åœ¨é—®é¢˜":
                    next_steps.insert(1, "1.5. ç´§æ€¥ä¿®å¤UIæ¨¡å—å¯¼å…¥å’Œç»„ä»¶é—®é¢˜")

                if "å·¥ä½œæµç¨‹" in analysis_name and status == "å­˜åœ¨é˜»å¡":
                    next_steps.insert(-1, "4.5. ä¿®å¤å·¥ä½œæµç¨‹é˜»å¡ç‚¹")

        except Exception as e:
            next_steps.append(f"æ³¨æ„: ä¸‹ä¸€æ­¥å®šä¹‰è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {str(e)}")

        return next_steps


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” VisionAI-ClipsMaster ç»¼åˆé—®é¢˜åˆ†æå’Œä¿®å¤å·¥å…·")
    print("=" * 80)

    # åˆ›å»ºåˆ†æå™¨
    analyzer = ComprehensiveIssueAnalyzer()

    try:
        # è¿è¡Œç»¼åˆåˆ†æ
        report = analyzer.run_comprehensive_analysis()

        # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
        overall_status = report.get("executive_summary", {}).get("overall_status", "æœªçŸ¥")

        if overall_status == "è‰¯å¥½":
            print(f"\nğŸ‰ åˆ†æå®Œæˆï¼ç³»ç»ŸçŠ¶æ€: {overall_status} - å¯ä»¥æŠ•å…¥ä½¿ç”¨")
        elif overall_status == "éœ€è¦å…³æ³¨":
            print(f"\nâš ï¸ åˆ†æå®Œæˆï¼ç³»ç»ŸçŠ¶æ€: {overall_status} - å»ºè®®ä¿®å¤åä½¿ç”¨")
        else:
            print(f"\nâŒ åˆ†æå®Œæˆï¼ç³»ç»ŸçŠ¶æ€: {overall_status} - éœ€è¦ä¿®å¤")

        return report

    except KeyboardInterrupt:
        print("\nâ¹ï¸ åˆ†æè¢«ç”¨æˆ·ä¸­æ–­")
        try:
            analyzer.cleanup_analysis_files()
        except:
            pass
        return None
    except Exception as e:
        print(f"\nğŸ’¥ åˆ†ææ‰§è¡Œå¼‚å¸¸: {str(e)}")
        try:
            analyzer.cleanup_analysis_files()
        except:
            pass
        return None


if __name__ == "__main__":
    main()
