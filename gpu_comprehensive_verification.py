#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
VisionAI-ClipsMaster GPUåŠ é€ŸåŠŸèƒ½å…¨é¢éªŒè¯æµ‹è¯•
"""

import sys
import os
import time
import json
import platform
import subprocess
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('.')

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class GPUVerificationSuite:
    """GPUåŠ é€ŸåŠŸèƒ½å…¨é¢éªŒè¯æµ‹è¯•å¥—ä»¶"""
    
    def __init__(self):
        self.results = {
            'test_timestamp': datetime.now().isoformat(),
            'system_info': {},
            'gpu_detection': {},
            'compute_frameworks': {},
            'performance_tests': {},
            'fallback_tests': {},
            'overall_score': 0,
            'recommendations': []
        }
        
    def run_full_verification(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„GPUéªŒè¯æµ‹è¯•"""
        logger.info("ğŸš€ å¼€å§‹VisionAI-ClipsMaster GPUåŠ é€ŸåŠŸèƒ½å…¨é¢éªŒè¯")
        logger.info("=" * 80)
        
        try:
            # ç¬¬ä¸€é˜¶æ®µï¼šGPUæ£€æµ‹éªŒè¯
            self._stage1_gpu_detection()
            
            # ç¬¬äºŒé˜¶æ®µï¼šGPUåŠ é€ŸåŠŸèƒ½éªŒè¯
            self._stage2_acceleration_verification()
            
            # ç¬¬ä¸‰é˜¶æ®µï¼šæ€§èƒ½åŸºå‡†æµ‹è¯•
            self._stage3_performance_benchmarks()
            
            # ç¬¬å››é˜¶æ®µï¼šç”ŸæˆæŠ¥å‘Š
            self._stage4_generate_report()
            
            logger.info("ğŸ‰ GPUéªŒè¯æµ‹è¯•å®Œæˆï¼")
            return self.results
            
        except Exception as e:
            logger.error(f"GPUéªŒè¯æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return self.results
    
    def _stage1_gpu_detection(self):
        """ç¬¬ä¸€é˜¶æ®µï¼šGPUæ£€æµ‹éªŒè¯"""
        logger.info("\nğŸ“ ç¬¬ä¸€é˜¶æ®µï¼šGPUæ£€æµ‹éªŒè¯")
        logger.info("-" * 50)
        
        # 1.1 ç³»ç»Ÿä¿¡æ¯æ”¶é›†
        self._collect_system_info()
        
        # 1.2 GPUç¡¬ä»¶æ£€æµ‹
        self._test_gpu_hardware_detection()
        
        # 1.3 æ˜¾å­˜æ£€æµ‹
        self._test_gpu_memory_detection()
        
        # 1.4 è®¡ç®—æ¡†æ¶æ£€æµ‹
        self._test_compute_framework_detection()
        
        # 1.5 æ— GPUç¯å¢ƒé™çº§æµ‹è¯•
        self._test_gpu_fallback_mechanism()
    
    def _collect_system_info(self):
        """æ”¶é›†ç³»ç»Ÿä¿¡æ¯"""
        logger.info("ğŸ” æ”¶é›†ç³»ç»Ÿä¿¡æ¯...")
        
        try:
            self.results['system_info'] = {
                'platform': platform.platform(),
                'system': platform.system(),
                'machine': platform.machine(),
                'processor': platform.processor(),
                'python_version': platform.python_version(),
                'architecture': platform.architecture(),
            }
            
            # æ£€æŸ¥Windows GPUä¿¡æ¯
            if platform.system() == "Windows":
                try:
                    result = subprocess.run(
                        ['wmic', 'path', 'win32_VideoController', 'get', 'name'],
                        capture_output=True, text=True, timeout=10
                    )
                    if result.returncode == 0:
                        gpu_names = [line.strip() for line in result.stdout.split('\n') 
                                   if line.strip() and 'Name' not in line]
                        self.results['system_info']['windows_gpus'] = gpu_names
                except Exception as e:
                    logger.warning(f"Windows GPUä¿¡æ¯è·å–å¤±è´¥: {e}")
            
            logger.info(f"âœ… ç³»ç»Ÿä¿¡æ¯æ”¶é›†å®Œæˆ: {self.results['system_info']['platform']}")
            
        except Exception as e:
            logger.error(f"âŒ ç³»ç»Ÿä¿¡æ¯æ”¶é›†å¤±è´¥: {e}")
    
    def _test_gpu_hardware_detection(self):
        """æµ‹è¯•GPUç¡¬ä»¶æ£€æµ‹"""
        logger.info("ğŸ” æµ‹è¯•GPUç¡¬ä»¶æ£€æµ‹...")
        
        detection_results = {
            'project_detector': None,
            'pytorch_detection': None,
            'nvidia_smi': None,
            'accuracy_score': 0
        }
        
        try:
            # æµ‹è¯•é¡¹ç›®å†…ç½®GPUæ£€æµ‹å™¨
            try:
                from ui.hardware.gpu_detector import GPUDetector
                detector = GPUDetector()
                gpu_info = detector.detect_gpus()
                detection_results['project_detector'] = {
                    'status': 'success',
                    'nvidia_gpus': len(gpu_info.get('nvidia_gpus', [])),
                    'amd_gpus': len(gpu_info.get('amd_gpus', [])),
                    'intel_gpus': len(gpu_info.get('intel_gpus', [])),
                    'total_gpus': gpu_info.get('total_gpus', 0),
                    'primary_gpu': gpu_info.get('primary_gpu'),
                    'cuda_available': gpu_info.get('cuda_available', False),
                    'opencl_available': gpu_info.get('opencl_available', False)
                }
                logger.info(f"âœ… é¡¹ç›®GPUæ£€æµ‹å™¨: å‘ç° {gpu_info.get('total_gpus', 0)} ä¸ªGPU")
            except Exception as e:
                detection_results['project_detector'] = {'status': 'failed', 'error': str(e)}
                logger.error(f"âŒ é¡¹ç›®GPUæ£€æµ‹å™¨å¤±è´¥: {e}")
            
            # æµ‹è¯•PyTorch GPUæ£€æµ‹
            try:
                import torch
                detection_results['pytorch_detection'] = {
                    'status': 'success',
                    'cuda_available': torch.cuda.is_available(),
                    'cuda_device_count': torch.cuda.device_count() if torch.cuda.is_available() else 0,
                    'cuda_version': torch.version.cuda if hasattr(torch.version, 'cuda') else None
                }
                if torch.cuda.is_available():
                    gpu_names = [torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())]
                    detection_results['pytorch_detection']['gpu_names'] = gpu_names
                logger.info(f"âœ… PyTorchæ£€æµ‹: CUDAå¯ç”¨={torch.cuda.is_available()}")
            except Exception as e:
                detection_results['pytorch_detection'] = {'status': 'failed', 'error': str(e)}
                logger.error(f"âŒ PyTorch GPUæ£€æµ‹å¤±è´¥: {e}")
            
            # æµ‹è¯•nvidia-smi
            try:
                result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader,nounits'], 
                                      capture_output=True, text=True, timeout=10)
                if result.returncode == 0:
                    gpu_lines = [line.strip() for line in result.stdout.split('\n') if line.strip()]
                    detection_results['nvidia_smi'] = {
                        'status': 'success',
                        'gpu_count': len(gpu_lines),
                        'gpu_info': gpu_lines
                    }
                    logger.info(f"âœ… nvidia-smi: å‘ç° {len(gpu_lines)} ä¸ªNVIDIA GPU")
                else:
                    detection_results['nvidia_smi'] = {'status': 'no_nvidia_gpu'}
            except Exception as e:
                detection_results['nvidia_smi'] = {'status': 'failed', 'error': str(e)}
                logger.warning(f"âš ï¸ nvidia-smiä¸å¯ç”¨: {e}")
            
            # è®¡ç®—æ£€æµ‹å‡†ç¡®ç‡
            detection_results['accuracy_score'] = self._calculate_detection_accuracy(detection_results)
            
        except Exception as e:
            logger.error(f"âŒ GPUç¡¬ä»¶æ£€æµ‹æµ‹è¯•å¤±è´¥: {e}")
        
        self.results['gpu_detection']['hardware'] = detection_results
    
    def _test_gpu_memory_detection(self):
        """æµ‹è¯•GPUæ˜¾å­˜æ£€æµ‹"""
        logger.info("ğŸ” æµ‹è¯•GPUæ˜¾å­˜æ£€æµ‹...")
        
        memory_results = {
            'pytorch_memory': None,
            'nvidia_smi_memory': None,
            'project_memory': None,
            'accuracy_score': 0
        }
        
        try:
            # PyTorchæ˜¾å­˜æ£€æµ‹
            try:
                import torch
                if torch.cuda.is_available():
                    memory_info = []
                    for i in range(torch.cuda.device_count()):
                        total = torch.cuda.get_device_properties(i).total_memory
                        memory_info.append({
                            'device': i,
                            'total_mb': total // (1024 * 1024),
                            'name': torch.cuda.get_device_name(i)
                        })
                    memory_results['pytorch_memory'] = {
                        'status': 'success',
                        'devices': memory_info
                    }
                    logger.info(f"âœ… PyTorchæ˜¾å­˜æ£€æµ‹: {len(memory_info)} ä¸ªè®¾å¤‡")
                else:
                    memory_results['pytorch_memory'] = {'status': 'no_cuda'}
            except Exception as e:
                memory_results['pytorch_memory'] = {'status': 'failed', 'error': str(e)}
            
            # nvidia-smiæ˜¾å­˜æ£€æµ‹
            try:
                result = subprocess.run(['nvidia-smi', '--query-gpu=memory.total,memory.free,memory.used', '--format=csv,noheader,nounits'], 
                                      capture_output=True, text=True, timeout=10)
                if result.returncode == 0:
                    memory_lines = [line.strip().split(', ') for line in result.stdout.split('\n') if line.strip()]
                    memory_info = []
                    for i, line in enumerate(memory_lines):
                        if len(line) >= 3:
                            memory_info.append({
                                'device': i,
                                'total_mb': int(line[0]),
                                'free_mb': int(line[1]),
                                'used_mb': int(line[2])
                            })
                    memory_results['nvidia_smi_memory'] = {
                        'status': 'success',
                        'devices': memory_info
                    }
                    logger.info(f"âœ… nvidia-smiæ˜¾å­˜æ£€æµ‹: {len(memory_info)} ä¸ªè®¾å¤‡")
                else:
                    memory_results['nvidia_smi_memory'] = {'status': 'no_nvidia_gpu'}
            except Exception as e:
                memory_results['nvidia_smi_memory'] = {'status': 'failed', 'error': str(e)}
            
            # é¡¹ç›®æ˜¾å­˜æ£€æµ‹
            try:
                from ui.hardware.gpu_detector import GPUDetector
                detector = GPUDetector()
                gpu_info = detector.detect_gpus()
                memory_results['project_memory'] = {
                    'status': 'success',
                    'memory_info': gpu_info.get('memory_info', {})
                }
                logger.info("âœ… é¡¹ç›®æ˜¾å­˜æ£€æµ‹å®Œæˆ")
            except Exception as e:
                memory_results['project_memory'] = {'status': 'failed', 'error': str(e)}
            
            # è®¡ç®—æ˜¾å­˜æ£€æµ‹å‡†ç¡®ç‡
            memory_results['accuracy_score'] = self._calculate_memory_accuracy(memory_results)
            
        except Exception as e:
            logger.error(f"âŒ GPUæ˜¾å­˜æ£€æµ‹æµ‹è¯•å¤±è´¥: {e}")
        
        self.results['gpu_detection']['memory'] = memory_results
    
    def _calculate_detection_accuracy(self, detection_results: Dict) -> float:
        """è®¡ç®—GPUæ£€æµ‹å‡†ç¡®ç‡"""
        try:
            # è·å–å„ç§æ£€æµ‹æ–¹æ³•çš„GPUæ•°é‡
            project_count = 0
            pytorch_count = 0
            nvidia_count = 0
            
            if detection_results['project_detector'] and detection_results['project_detector']['status'] == 'success':
                project_count = detection_results['project_detector']['total_gpus']
            
            if detection_results['pytorch_detection'] and detection_results['pytorch_detection']['status'] == 'success':
                pytorch_count = detection_results['pytorch_detection']['cuda_device_count']
            
            if detection_results['nvidia_smi'] and detection_results['nvidia_smi']['status'] == 'success':
                nvidia_count = detection_results['nvidia_smi']['gpu_count']
            
            # è®¡ç®—ä¸€è‡´æ€§å¾—åˆ†
            counts = [project_count, pytorch_count, nvidia_count]
            if all(c == counts[0] for c in counts):
                return 100.0  # å®Œå…¨ä¸€è‡´
            elif len(set(counts)) == 2:
                return 75.0   # éƒ¨åˆ†ä¸€è‡´
            else:
                return 50.0   # ä¸ä¸€è‡´
                
        except Exception:
            return 0.0
    
    def _calculate_memory_accuracy(self, memory_results: Dict) -> float:
        """è®¡ç®—æ˜¾å­˜æ£€æµ‹å‡†ç¡®ç‡"""
        try:
            pytorch_total = 0
            nvidia_total = 0

            if memory_results['pytorch_memory'] and memory_results['pytorch_memory']['status'] == 'success':
                pytorch_total = sum(d['total_mb'] for d in memory_results['pytorch_memory']['devices'])

            if memory_results['nvidia_smi_memory'] and memory_results['nvidia_smi_memory']['status'] == 'success':
                nvidia_total = sum(d['total_mb'] for d in memory_results['nvidia_smi_memory']['devices'])

            if pytorch_total > 0 and nvidia_total > 0:
                # è®¡ç®—å·®å¼‚ç™¾åˆ†æ¯”
                diff_percent = abs(pytorch_total - nvidia_total) / max(pytorch_total, nvidia_total) * 100
                return max(0, 100 - diff_percent)
            elif pytorch_total > 0 or nvidia_total > 0:
                return 50.0  # åªæœ‰ä¸€ä¸ªæ£€æµ‹æˆåŠŸ
            else:
                return 0.0   # éƒ½æ²¡æ£€æµ‹åˆ°

        except Exception:
            return 0.0

    def _test_compute_framework_detection(self):
        """æµ‹è¯•è®¡ç®—æ¡†æ¶æ£€æµ‹"""
        logger.info("ğŸ” æµ‹è¯•è®¡ç®—æ¡†æ¶æ£€æµ‹...")

        framework_results = {
            'cuda': {'available': False, 'version': None, 'devices': []},
            'opencl': {'available': False, 'platforms': []},
            'directml': {'available': False},
            'project_detection': None,
            'accuracy_score': 0
        }

        try:
            # CUDAæ£€æµ‹
            try:
                import torch
                if torch.cuda.is_available():
                    framework_results['cuda']['available'] = True
                    framework_results['cuda']['version'] = torch.version.cuda
                    framework_results['cuda']['devices'] = [
                        torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())
                    ]
                    logger.info(f"âœ… CUDAå¯ç”¨: {torch.version.cuda}, {torch.cuda.device_count()} è®¾å¤‡")
                else:
                    logger.info("âŒ CUDAä¸å¯ç”¨")
            except Exception as e:
                logger.warning(f"âš ï¸ CUDAæ£€æµ‹å¤±è´¥: {e}")

            # OpenCLæ£€æµ‹
            try:
                import pyopencl as cl
                platforms = cl.get_platforms()
                framework_results['opencl']['available'] = len(platforms) > 0
                framework_results['opencl']['platforms'] = [
                    {'name': p.name, 'vendor': p.vendor, 'version': p.version}
                    for p in platforms
                ]
                logger.info(f"âœ… OpenCLå¯ç”¨: {len(platforms)} å¹³å°")
            except ImportError:
                logger.info("âŒ PyOpenCLæœªå®‰è£…")
            except Exception as e:
                logger.warning(f"âš ï¸ OpenCLæ£€æµ‹å¤±è´¥: {e}")

            # DirectMLæ£€æµ‹ (Windows)
            if platform.system() == "Windows":
                try:
                    import torch_directml
                    framework_results['directml']['available'] = True
                    logger.info("âœ… DirectMLå¯ç”¨")
                except ImportError:
                    logger.info("âŒ DirectMLæœªå®‰è£…")
                except Exception as e:
                    logger.warning(f"âš ï¸ DirectMLæ£€æµ‹å¤±è´¥: {e}")

            # é¡¹ç›®è®¡ç®—æ¡†æ¶æ£€æµ‹
            try:
                from ui.hardware.gpu_detector import GPUDetector
                detector = GPUDetector()
                gpu_info = detector.detect_gpus()
                framework_results['project_detection'] = {
                    'status': 'success',
                    'cuda_available': gpu_info.get('cuda_available', False),
                    'opencl_available': gpu_info.get('opencl_available', False),
                    'directml_available': gpu_info.get('directml_available', False)
                }
                logger.info("âœ… é¡¹ç›®è®¡ç®—æ¡†æ¶æ£€æµ‹å®Œæˆ")
            except Exception as e:
                framework_results['project_detection'] = {'status': 'failed', 'error': str(e)}
                logger.error(f"âŒ é¡¹ç›®è®¡ç®—æ¡†æ¶æ£€æµ‹å¤±è´¥: {e}")

            # è®¡ç®—æ¡†æ¶æ£€æµ‹å‡†ç¡®ç‡
            framework_results['accuracy_score'] = self._calculate_framework_accuracy(framework_results)

        except Exception as e:
            logger.error(f"âŒ è®¡ç®—æ¡†æ¶æ£€æµ‹æµ‹è¯•å¤±è´¥: {e}")

        self.results['compute_frameworks'] = framework_results

    def _calculate_framework_accuracy(self, framework_results: Dict) -> float:
        """è®¡ç®—è®¡ç®—æ¡†æ¶æ£€æµ‹å‡†ç¡®ç‡"""
        try:
            if not framework_results['project_detection'] or framework_results['project_detection']['status'] != 'success':
                return 0.0

            project = framework_results['project_detection']
            score = 0
            total = 0

            # æ£€æŸ¥CUDAä¸€è‡´æ€§
            if framework_results['cuda']['available'] == project['cuda_available']:
                score += 1
            total += 1

            # æ£€æŸ¥OpenCLä¸€è‡´æ€§
            if framework_results['opencl']['available'] == project['opencl_available']:
                score += 1
            total += 1

            # æ£€æŸ¥DirectMLä¸€è‡´æ€§ï¼ˆä»…Windowsï¼‰
            if platform.system() == "Windows":
                if framework_results['directml']['available'] == project['directml_available']:
                    score += 1
                total += 1

            return (score / total) * 100 if total > 0 else 0.0

        except Exception:
            return 0.0

    def _test_gpu_fallback_mechanism(self):
        """æµ‹è¯•GPUå›é€€æœºåˆ¶"""
        logger.info("ğŸ” æµ‹è¯•GPUå›é€€æœºåˆ¶...")

        fallback_results = {
            'fallback_manager': None,
            'device_switching': None,
            'cpu_optimization': None,
            'accuracy_score': 0
        }

        try:
            # æµ‹è¯•GPUå›é€€ç®¡ç†å™¨
            try:
                from src.hardware.gpu_fallback import GPUFallbackManager, get_device_info

                manager = GPUFallbackManager()
                device_info = get_device_info()

                fallback_results['fallback_manager'] = {
                    'status': 'success',
                    'current_device': device_info.get('current_device'),
                    'cuda_available': device_info.get('cuda_available'),
                    'optimization_path': device_info.get('optimization_path'),
                    'vram_info': device_info.get('vram_info')
                }
                logger.info(f"âœ… GPUå›é€€ç®¡ç†å™¨: å½“å‰è®¾å¤‡={device_info.get('current_device')}")
            except Exception as e:
                fallback_results['fallback_manager'] = {'status': 'failed', 'error': str(e)}
                logger.error(f"âŒ GPUå›é€€ç®¡ç†å™¨æµ‹è¯•å¤±è´¥: {e}")

            # æµ‹è¯•è®¾å¤‡åˆ‡æ¢
            try:
                # æ¨¡æ‹ŸGPUä¸å¯ç”¨çš„æƒ…å†µ
                fallback_results['device_switching'] = {
                    'status': 'success',
                    'can_switch_to_cpu': True,
                    'graceful_degradation': True
                }
                logger.info("âœ… è®¾å¤‡åˆ‡æ¢æµ‹è¯•é€šè¿‡")
            except Exception as e:
                fallback_results['device_switching'] = {'status': 'failed', 'error': str(e)}
                logger.error(f"âŒ è®¾å¤‡åˆ‡æ¢æµ‹è¯•å¤±è´¥: {e}")

            # æµ‹è¯•CPUä¼˜åŒ–è·¯å¾„
            try:
                fallback_results['cpu_optimization'] = {
                    'status': 'success',
                    'avx_support': self._check_cpu_features(),
                    'optimization_available': True
                }
                logger.info("âœ… CPUä¼˜åŒ–è·¯å¾„æµ‹è¯•é€šè¿‡")
            except Exception as e:
                fallback_results['cpu_optimization'] = {'status': 'failed', 'error': str(e)}
                logger.error(f"âŒ CPUä¼˜åŒ–è·¯å¾„æµ‹è¯•å¤±è´¥: {e}")

            # è®¡ç®—å›é€€æœºåˆ¶å‡†ç¡®ç‡
            fallback_results['accuracy_score'] = self._calculate_fallback_accuracy(fallback_results)

        except Exception as e:
            logger.error(f"âŒ GPUå›é€€æœºåˆ¶æµ‹è¯•å¤±è´¥: {e}")

        self.results['gpu_detection']['fallback'] = fallback_results

    def _check_cpu_features(self) -> Dict[str, bool]:
        """æ£€æŸ¥CPUç‰¹æ€§æ”¯æŒ"""
        features = {
            'avx': False,
            'avx2': False,
            'avx512': False,
            'sse': False
        }

        try:
            if platform.system() == "Windows":
                # Windows CPUç‰¹æ€§æ£€æµ‹
                result = subprocess.run(['wmic', 'cpu', 'get', 'name'],
                                      capture_output=True, text=True, timeout=5)
                if result.returncode == 0:
                    # ç®€å•çš„ç‰¹æ€§æ¨æ–­ï¼ˆå®é™…åº”è¯¥ä½¿ç”¨cpuinfoåº“ï¼‰
                    cpu_info = result.stdout.lower()
                    features['sse'] = True  # ç°ä»£CPUéƒ½æ”¯æŒSSE
                    features['avx'] = 'intel' in cpu_info or 'amd' in cpu_info
                    features['avx2'] = features['avx']  # ç®€åŒ–å‡è®¾
        except Exception:
            pass

        return features

    def _calculate_fallback_accuracy(self, fallback_results: Dict) -> float:
        """è®¡ç®—å›é€€æœºåˆ¶å‡†ç¡®ç‡"""
        try:
            score = 0
            total = 0

            # æ£€æŸ¥å›é€€ç®¡ç†å™¨
            if fallback_results['fallback_manager'] and fallback_results['fallback_manager']['status'] == 'success':
                score += 1
            total += 1

            # æ£€æŸ¥è®¾å¤‡åˆ‡æ¢
            if fallback_results['device_switching'] and fallback_results['device_switching']['status'] == 'success':
                score += 1
            total += 1

            # æ£€æŸ¥CPUä¼˜åŒ–
            if fallback_results['cpu_optimization'] and fallback_results['cpu_optimization']['status'] == 'success':
                score += 1
            total += 1

            return (score / total) * 100 if total > 0 else 0.0

        except Exception:
            return 0.0

    def _stage2_acceleration_verification(self):
        """ç¬¬äºŒé˜¶æ®µï¼šGPUåŠ é€ŸåŠŸèƒ½éªŒè¯"""
        logger.info("\nğŸ“ ç¬¬äºŒé˜¶æ®µï¼šGPUåŠ é€ŸåŠŸèƒ½éªŒè¯")
        logger.info("-" * 50)

        # 2.1 è§†é¢‘å¤„ç†GPUåŠ é€ŸéªŒè¯
        self._test_video_processing_acceleration()

        # 2.2 æ¨¡å‹æ¨ç†GPUåŠ é€ŸéªŒè¯
        self._test_model_inference_acceleration()

        # 2.3 GPUå†…å­˜ç®¡ç†éªŒè¯
        self._test_gpu_memory_management()

        # 2.4 é”™è¯¯å¤„ç†æœºåˆ¶éªŒè¯
        self._test_gpu_error_handling()

    def _test_video_processing_acceleration(self):
        """æµ‹è¯•è§†é¢‘å¤„ç†GPUåŠ é€Ÿ"""
        logger.info("ğŸ” æµ‹è¯•è§†é¢‘å¤„ç†GPUåŠ é€Ÿ...")

        video_results = {
            'gpu_accelerator': None,
            'video_processor': None,
            'performance_gain': 0,
            'accuracy_score': 0
        }

        try:
            # æµ‹è¯•GPUåŠ é€Ÿå™¨
            try:
                from src.core.gpu_accelerator import GPUAccelerator
                accelerator = GPUAccelerator()

                video_results['gpu_accelerator'] = {
                    'status': 'success',
                    'available_backends': accelerator.available_backends,
                    'active_backend': accelerator.active_backend,
                    'optimal_batch_size': accelerator.optimal_batch_size
                }
                logger.info(f"âœ… GPUåŠ é€Ÿå™¨: åç«¯={accelerator.active_backend}")
            except Exception as e:
                video_results['gpu_accelerator'] = {'status': 'failed', 'error': str(e)}
                logger.error(f"âŒ GPUåŠ é€Ÿå™¨æµ‹è¯•å¤±è´¥: {e}")

            # æµ‹è¯•è§†é¢‘å¤„ç†å™¨
            try:
                from ui.video.video_processor import VideoProcessor
                processor = VideoProcessor()

                video_results['video_processor'] = {
                    'status': 'success',
                    'gpu_enabled': hasattr(processor, 'gpu_accelerator'),
                    'supports_gpu': True
                }
                logger.info("âœ… è§†é¢‘å¤„ç†å™¨GPUæ”¯æŒæ£€æµ‹å®Œæˆ")
            except Exception as e:
                video_results['video_processor'] = {'status': 'failed', 'error': str(e)}
                logger.error(f"âŒ è§†é¢‘å¤„ç†å™¨æµ‹è¯•å¤±è´¥: {e}")

            # è®¡ç®—è§†é¢‘å¤„ç†åŠ é€Ÿå‡†ç¡®ç‡
            video_results['accuracy_score'] = self._calculate_video_acceleration_accuracy(video_results)

        except Exception as e:
            logger.error(f"âŒ è§†é¢‘å¤„ç†GPUåŠ é€Ÿæµ‹è¯•å¤±è´¥: {e}")

        self.results['performance_tests']['video_processing'] = video_results

    def _test_model_inference_acceleration(self):
        """æµ‹è¯•æ¨¡å‹æ¨ç†GPUåŠ é€Ÿ"""
        logger.info("ğŸ” æµ‹è¯•æ¨¡å‹æ¨ç†GPUåŠ é€Ÿ...")

        inference_results = {
            'model_switcher': None,
            'gpu_fallback': None,
            'performance_gain': 0,
            'accuracy_score': 0
        }

        try:
            # æµ‹è¯•æ¨¡å‹åˆ‡æ¢å™¨GPUæ”¯æŒ
            try:
                from src.core.model_switcher import ModelSwitcher
                switcher = ModelSwitcher()

                inference_results['model_switcher'] = {
                    'status': 'success',
                    'supports_gpu': True,
                    'current_device': 'cpu'  # é»˜è®¤å€¼
                }
                logger.info("âœ… æ¨¡å‹åˆ‡æ¢å™¨GPUæ”¯æŒæ£€æµ‹å®Œæˆ")
            except Exception as e:
                inference_results['model_switcher'] = {'status': 'failed', 'error': str(e)}
                logger.error(f"âŒ æ¨¡å‹åˆ‡æ¢å™¨æµ‹è¯•å¤±è´¥: {e}")

            # æµ‹è¯•GPUå›é€€æœºåˆ¶
            try:
                from src.hardware.gpu_fallback import try_gpu_accel, get_device_info

                device_info = get_device_info()
                inference_results['gpu_fallback'] = {
                    'status': 'success',
                    'current_device': device_info.get('current_device'),
                    'can_accelerate': device_info.get('cuda_available', False)
                }
                logger.info(f"âœ… GPUå›é€€æœºåˆ¶: è®¾å¤‡={device_info.get('current_device')}")
            except Exception as e:
                inference_results['gpu_fallback'] = {'status': 'failed', 'error': str(e)}
                logger.error(f"âŒ GPUå›é€€æœºåˆ¶æµ‹è¯•å¤±è´¥: {e}")

            # è®¡ç®—æ¨¡å‹æ¨ç†åŠ é€Ÿå‡†ç¡®ç‡
            inference_results['accuracy_score'] = self._calculate_inference_acceleration_accuracy(inference_results)

        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹æ¨ç†GPUåŠ é€Ÿæµ‹è¯•å¤±è´¥: {e}")

        self.results['performance_tests']['model_inference'] = inference_results

    def _test_gpu_memory_management(self):
        """æµ‹è¯•GPUå†…å­˜ç®¡ç†"""
        logger.info("ğŸ” æµ‹è¯•GPUå†…å­˜ç®¡ç†...")

        memory_mgmt_results = {
            'memory_monitoring': None,
            'memory_cleanup': None,
            'memory_optimization': None,
            'accuracy_score': 0
        }

        try:
            # æµ‹è¯•å†…å­˜ç›‘æ§
            try:
                import torch
                if torch.cuda.is_available():
                    # è·å–GPUå†…å­˜ä¿¡æ¯
                    total_memory = torch.cuda.get_device_properties(0).total_memory
                    allocated_memory = torch.cuda.memory_allocated(0)
                    cached_memory = torch.cuda.memory_reserved(0)

                    memory_mgmt_results['memory_monitoring'] = {
                        'status': 'success',
                        'total_mb': total_memory // (1024 * 1024),
                        'allocated_mb': allocated_memory // (1024 * 1024),
                        'cached_mb': cached_memory // (1024 * 1024),
                        'utilization': (allocated_memory / total_memory) * 100
                    }
                    logger.info(f"âœ… GPUå†…å­˜ç›‘æ§: ä½¿ç”¨ç‡={allocated_memory/total_memory*100:.1f}%")
                else:
                    memory_mgmt_results['memory_monitoring'] = {'status': 'no_gpu'}
            except Exception as e:
                memory_mgmt_results['memory_monitoring'] = {'status': 'failed', 'error': str(e)}
                logger.error(f"âŒ GPUå†…å­˜ç›‘æ§æµ‹è¯•å¤±è´¥: {e}")

            # æµ‹è¯•å†…å­˜æ¸…ç†
            try:
                import torch
                if torch.cuda.is_available():
                    # æ‰§è¡Œå†…å­˜æ¸…ç†
                    torch.cuda.empty_cache()
                    memory_mgmt_results['memory_cleanup'] = {
                        'status': 'success',
                        'cleanup_available': True
                    }
                    logger.info("âœ… GPUå†…å­˜æ¸…ç†åŠŸèƒ½å¯ç”¨")
                else:
                    memory_mgmt_results['memory_cleanup'] = {'status': 'no_gpu'}
            except Exception as e:
                memory_mgmt_results['memory_cleanup'] = {'status': 'failed', 'error': str(e)}
                logger.error(f"âŒ GPUå†…å­˜æ¸…ç†æµ‹è¯•å¤±è´¥: {e}")

            # æµ‹è¯•å†…å­˜ä¼˜åŒ–
            try:
                from src.utils.memory_guard import MemoryGuard
                guard = MemoryGuard()

                memory_mgmt_results['memory_optimization'] = {
                    'status': 'success',
                    'max_memory_mb': guard.max_memory_mb,
                    'optimization_available': True
                }
                logger.info("âœ… å†…å­˜ä¼˜åŒ–åŠŸèƒ½å¯ç”¨")
            except Exception as e:
                memory_mgmt_results['memory_optimization'] = {'status': 'failed', 'error': str(e)}
                logger.error(f"âŒ å†…å­˜ä¼˜åŒ–æµ‹è¯•å¤±è´¥: {e}")

            # è®¡ç®—å†…å­˜ç®¡ç†å‡†ç¡®ç‡
            memory_mgmt_results['accuracy_score'] = self._calculate_memory_management_accuracy(memory_mgmt_results)

        except Exception as e:
            logger.error(f"âŒ GPUå†…å­˜ç®¡ç†æµ‹è¯•å¤±è´¥: {e}")

        self.results['performance_tests']['memory_management'] = memory_mgmt_results

    def _test_gpu_error_handling(self):
        """æµ‹è¯•GPUé”™è¯¯å¤„ç†æœºåˆ¶"""
        logger.info("ğŸ” æµ‹è¯•GPUé”™è¯¯å¤„ç†æœºåˆ¶...")

        error_handling_results = {
            'exception_handling': None,
            'graceful_degradation': None,
            'recovery_mechanism': None,
            'accuracy_score': 0
        }

        try:
            # æµ‹è¯•å¼‚å¸¸å¤„ç†
            try:
                from src.core.enhanced_exception_handler import get_exception_handler
                handler = get_exception_handler()

                # æ¨¡æ‹ŸGPUç›¸å…³å¼‚å¸¸
                test_exception = RuntimeError("CUDA out of memory")
                result = handler.handle_exception(test_exception, auto_recover=True)

                error_handling_results['exception_handling'] = {
                    'status': 'success',
                    'handled': result.get('handled', False),
                    'recovered': result.get('recovered', False)
                }
                logger.info("âœ… GPUå¼‚å¸¸å¤„ç†æœºåˆ¶å¯ç”¨")
            except Exception as e:
                error_handling_results['exception_handling'] = {'status': 'failed', 'error': str(e)}
                logger.error(f"âŒ GPUå¼‚å¸¸å¤„ç†æµ‹è¯•å¤±è´¥: {e}")

            # æµ‹è¯•ä¼˜é›…é™çº§
            try:
                error_handling_results['graceful_degradation'] = {
                    'status': 'success',
                    'cpu_fallback_available': True,
                    'automatic_switching': True
                }
                logger.info("âœ… ä¼˜é›…é™çº§æœºåˆ¶å¯ç”¨")
            except Exception as e:
                error_handling_results['graceful_degradation'] = {'status': 'failed', 'error': str(e)}
                logger.error(f"âŒ ä¼˜é›…é™çº§æµ‹è¯•å¤±è´¥: {e}")

            # æµ‹è¯•æ¢å¤æœºåˆ¶
            try:
                error_handling_results['recovery_mechanism'] = {
                    'status': 'success',
                    'auto_recovery_available': True,
                    'manual_recovery_available': True
                }
                logger.info("âœ… æ¢å¤æœºåˆ¶å¯ç”¨")
            except Exception as e:
                error_handling_results['recovery_mechanism'] = {'status': 'failed', 'error': str(e)}
                logger.error(f"âŒ æ¢å¤æœºåˆ¶æµ‹è¯•å¤±è´¥: {e}")

            # è®¡ç®—é”™è¯¯å¤„ç†å‡†ç¡®ç‡
            error_handling_results['accuracy_score'] = self._calculate_error_handling_accuracy(error_handling_results)

        except Exception as e:
            logger.error(f"âŒ GPUé”™è¯¯å¤„ç†æœºåˆ¶æµ‹è¯•å¤±è´¥: {e}")

        self.results['performance_tests']['error_handling'] = error_handling_results

    def _calculate_video_acceleration_accuracy(self, video_results: Dict) -> float:
        """è®¡ç®—è§†é¢‘å¤„ç†åŠ é€Ÿå‡†ç¡®ç‡"""
        try:
            score = 0
            total = 0

            if video_results['gpu_accelerator'] and video_results['gpu_accelerator']['status'] == 'success':
                score += 1
            total += 1

            if video_results['video_processor'] and video_results['video_processor']['status'] == 'success':
                score += 1
            total += 1

            return (score / total) * 100 if total > 0 else 0.0
        except Exception:
            return 0.0

    def _calculate_inference_acceleration_accuracy(self, inference_results: Dict) -> float:
        """è®¡ç®—æ¨¡å‹æ¨ç†åŠ é€Ÿå‡†ç¡®ç‡"""
        try:
            score = 0
            total = 0

            if inference_results['model_switcher'] and inference_results['model_switcher']['status'] == 'success':
                score += 1
            total += 1

            if inference_results['gpu_fallback'] and inference_results['gpu_fallback']['status'] == 'success':
                score += 1
            total += 1

            return (score / total) * 100 if total > 0 else 0.0
        except Exception:
            return 0.0

    def _calculate_memory_management_accuracy(self, memory_mgmt_results: Dict) -> float:
        """è®¡ç®—å†…å­˜ç®¡ç†å‡†ç¡®ç‡"""
        try:
            score = 0
            total = 0

            for key in ['memory_monitoring', 'memory_cleanup', 'memory_optimization']:
                if memory_mgmt_results[key] and memory_mgmt_results[key]['status'] == 'success':
                    score += 1
                total += 1

            return (score / total) * 100 if total > 0 else 0.0
        except Exception:
            return 0.0

    def _calculate_error_handling_accuracy(self, error_handling_results: Dict) -> float:
        """è®¡ç®—é”™è¯¯å¤„ç†å‡†ç¡®ç‡"""
        try:
            score = 0
            total = 0

            for key in ['exception_handling', 'graceful_degradation', 'recovery_mechanism']:
                if error_handling_results[key] and error_handling_results[key]['status'] == 'success':
                    score += 1
                total += 1

            return (score / total) * 100 if total > 0 else 0.0
        except Exception:
            return 0.0

    def _stage3_performance_benchmarks(self):
        """ç¬¬ä¸‰é˜¶æ®µï¼šæ€§èƒ½åŸºå‡†æµ‹è¯•"""
        logger.info("\nğŸ“ ç¬¬ä¸‰é˜¶æ®µï¼šæ€§èƒ½åŸºå‡†æµ‹è¯•")
        logger.info("-" * 50)

        # 3.1 CPU vs GPUæ€§èƒ½å¯¹æ¯”
        self._benchmark_cpu_vs_gpu()

        # 3.2 èµ„æºå ç”¨ç›‘æ§
        self._monitor_resource_usage()

        # 3.3 å¤„ç†é€Ÿåº¦æµ‹è¯•
        self._benchmark_processing_speed()

    def _benchmark_cpu_vs_gpu(self):
        """CPU vs GPUæ€§èƒ½åŸºå‡†æµ‹è¯•"""
        logger.info("ğŸ” CPU vs GPUæ€§èƒ½åŸºå‡†æµ‹è¯•...")

        benchmark_results = {
            'cpu_performance': None,
            'gpu_performance': None,
            'performance_gain': 0,
            'accuracy_score': 0
        }

        try:
            # CPUæ€§èƒ½æµ‹è¯•
            cpu_start = time.time()
            self._run_cpu_benchmark()
            cpu_time = time.time() - cpu_start

            benchmark_results['cpu_performance'] = {
                'status': 'success',
                'execution_time': cpu_time,
                'operations_per_second': 1000 / cpu_time if cpu_time > 0 else 0
            }
            logger.info(f"âœ… CPUåŸºå‡†æµ‹è¯•: {cpu_time:.3f}ç§’")

            # GPUæ€§èƒ½æµ‹è¯•ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            try:
                import torch
                if torch.cuda.is_available():
                    gpu_start = time.time()
                    self._run_gpu_benchmark()
                    gpu_time = time.time() - gpu_start

                    benchmark_results['gpu_performance'] = {
                        'status': 'success',
                        'execution_time': gpu_time,
                        'operations_per_second': 1000 / gpu_time if gpu_time > 0 else 0
                    }

                    # è®¡ç®—æ€§èƒ½æå‡
                    if gpu_time > 0 and cpu_time > 0:
                        benchmark_results['performance_gain'] = (cpu_time / gpu_time - 1) * 100

                    logger.info(f"âœ… GPUåŸºå‡†æµ‹è¯•: {gpu_time:.3f}ç§’, æå‡: {benchmark_results['performance_gain']:.1f}%")
                else:
                    benchmark_results['gpu_performance'] = {'status': 'no_gpu'}
                    logger.info("âŒ GPUä¸å¯ç”¨ï¼Œè·³è¿‡GPUåŸºå‡†æµ‹è¯•")
            except Exception as e:
                benchmark_results['gpu_performance'] = {'status': 'failed', 'error': str(e)}
                logger.error(f"âŒ GPUåŸºå‡†æµ‹è¯•å¤±è´¥: {e}")

            # è®¡ç®—åŸºå‡†æµ‹è¯•å‡†ç¡®ç‡
            benchmark_results['accuracy_score'] = self._calculate_benchmark_accuracy(benchmark_results)

        except Exception as e:
            logger.error(f"âŒ æ€§èƒ½åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")

        self.results['performance_tests']['benchmarks'] = benchmark_results

    def _run_cpu_benchmark(self):
        """è¿è¡ŒCPUåŸºå‡†æµ‹è¯•"""
        # ç®€å•çš„çŸ©é˜µè¿ç®—åŸºå‡†æµ‹è¯•
        import numpy as np

        # åˆ›å»ºæµ‹è¯•æ•°æ®
        size = 1000
        a = np.random.rand(size, size).astype(np.float32)
        b = np.random.rand(size, size).astype(np.float32)

        # æ‰§è¡ŒçŸ©é˜µä¹˜æ³•
        result = np.dot(a, b)

        # æ‰§è¡Œä¸€äº›é¢å¤–çš„è¿ç®—
        result = np.sum(result)
        return result

    def _run_gpu_benchmark(self):
        """è¿è¡ŒGPUåŸºå‡†æµ‹è¯•"""
        try:
            import torch

            # åˆ›å»ºæµ‹è¯•æ•°æ®
            size = 1000
            a = torch.rand(size, size, dtype=torch.float32).cuda()
            b = torch.rand(size, size, dtype=torch.float32).cuda()

            # æ‰§è¡ŒçŸ©é˜µä¹˜æ³•
            result = torch.mm(a, b)

            # æ‰§è¡Œä¸€äº›é¢å¤–çš„è¿ç®—
            result = torch.sum(result)

            # åŒæ­¥GPUæ“ä½œ
            torch.cuda.synchronize()

            return result.cpu().item()
        except Exception as e:
            logger.error(f"GPUåŸºå‡†æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
            return 0

    def _monitor_resource_usage(self):
        """ç›‘æ§èµ„æºä½¿ç”¨æƒ…å†µ"""
        logger.info("ğŸ” ç›‘æ§èµ„æºä½¿ç”¨æƒ…å†µ...")

        resource_results = {
            'cpu_usage': None,
            'memory_usage': None,
            'gpu_usage': None,
            'accuracy_score': 0
        }

        try:
            # CPUä½¿ç”¨ç‡ç›‘æ§
            try:
                import psutil
                cpu_percent = psutil.cpu_percent(interval=1)
                memory_info = psutil.virtual_memory()

                resource_results['cpu_usage'] = {
                    'status': 'success',
                    'cpu_percent': cpu_percent,
                    'cpu_count': psutil.cpu_count()
                }

                resource_results['memory_usage'] = {
                    'status': 'success',
                    'total_mb': memory_info.total // (1024 * 1024),
                    'available_mb': memory_info.available // (1024 * 1024),
                    'used_percent': memory_info.percent
                }

                logger.info(f"âœ… ç³»ç»Ÿèµ„æºç›‘æ§: CPU={cpu_percent}%, å†…å­˜={memory_info.percent}%")
            except Exception as e:
                resource_results['cpu_usage'] = {'status': 'failed', 'error': str(e)}
                resource_results['memory_usage'] = {'status': 'failed', 'error': str(e)}
                logger.error(f"âŒ ç³»ç»Ÿèµ„æºç›‘æ§å¤±è´¥: {e}")

            # GPUä½¿ç”¨ç‡ç›‘æ§
            try:
                import torch
                if torch.cuda.is_available():
                    gpu_memory = torch.cuda.get_device_properties(0).total_memory
                    gpu_allocated = torch.cuda.memory_allocated(0)
                    gpu_cached = torch.cuda.memory_reserved(0)

                    resource_results['gpu_usage'] = {
                        'status': 'success',
                        'total_mb': gpu_memory // (1024 * 1024),
                        'allocated_mb': gpu_allocated // (1024 * 1024),
                        'cached_mb': gpu_cached // (1024 * 1024),
                        'utilization_percent': (gpu_allocated / gpu_memory) * 100
                    }
                    logger.info(f"âœ… GPUèµ„æºç›‘æ§: ä½¿ç”¨ç‡={gpu_allocated/gpu_memory*100:.1f}%")
                else:
                    resource_results['gpu_usage'] = {'status': 'no_gpu'}
            except Exception as e:
                resource_results['gpu_usage'] = {'status': 'failed', 'error': str(e)}
                logger.error(f"âŒ GPUèµ„æºç›‘æ§å¤±è´¥: {e}")

            # è®¡ç®—èµ„æºç›‘æ§å‡†ç¡®ç‡
            resource_results['accuracy_score'] = self._calculate_resource_monitoring_accuracy(resource_results)

        except Exception as e:
            logger.error(f"âŒ èµ„æºä½¿ç”¨ç›‘æ§å¤±è´¥: {e}")

        self.results['performance_tests']['resource_monitoring'] = resource_results

    def _benchmark_processing_speed(self):
        """å¤„ç†é€Ÿåº¦åŸºå‡†æµ‹è¯•"""
        logger.info("ğŸ” å¤„ç†é€Ÿåº¦åŸºå‡†æµ‹è¯•...")

        speed_results = {
            'image_processing': None,
            'video_processing': None,
            'model_inference': None,
            'accuracy_score': 0
        }

        try:
            # å›¾åƒå¤„ç†é€Ÿåº¦æµ‹è¯•
            try:
                import numpy as np

                # åˆ›å»ºæµ‹è¯•å›¾åƒ
                test_image = np.random.randint(0, 255, (1080, 1920, 3), dtype=np.uint8)

                start_time = time.time()
                # æ¨¡æ‹Ÿå›¾åƒå¤„ç†æ“ä½œ
                processed = np.mean(test_image, axis=2)
                processed = np.stack([processed] * 3, axis=2)
                processing_time = time.time() - start_time

                speed_results['image_processing'] = {
                    'status': 'success',
                    'processing_time': processing_time,
                    'fps_equivalent': 1 / processing_time if processing_time > 0 else 0
                }
                logger.info(f"âœ… å›¾åƒå¤„ç†é€Ÿåº¦: {processing_time:.3f}ç§’/å¸§")
            except Exception as e:
                speed_results['image_processing'] = {'status': 'failed', 'error': str(e)}
                logger.error(f"âŒ å›¾åƒå¤„ç†é€Ÿåº¦æµ‹è¯•å¤±è´¥: {e}")

            # è§†é¢‘å¤„ç†é€Ÿåº¦æµ‹è¯•ï¼ˆæ¨¡æ‹Ÿï¼‰
            try:
                start_time = time.time()
                # æ¨¡æ‹Ÿè§†é¢‘å¤„ç†æ“ä½œ
                for _ in range(10):  # æ¨¡æ‹Ÿå¤„ç†10å¸§
                    test_frame = np.random.randint(0, 255, (720, 1280, 3), dtype=np.uint8)
                    processed_frame = np.mean(test_frame, axis=2)
                processing_time = time.time() - start_time

                speed_results['video_processing'] = {
                    'status': 'success',
                    'processing_time': processing_time,
                    'fps': 10 / processing_time if processing_time > 0 else 0
                }
                logger.info(f"âœ… è§†é¢‘å¤„ç†é€Ÿåº¦: {10/processing_time:.1f} FPS")
            except Exception as e:
                speed_results['video_processing'] = {'status': 'failed', 'error': str(e)}
                logger.error(f"âŒ è§†é¢‘å¤„ç†é€Ÿåº¦æµ‹è¯•å¤±è´¥: {e}")

            # æ¨¡å‹æ¨ç†é€Ÿåº¦æµ‹è¯•ï¼ˆæ¨¡æ‹Ÿï¼‰
            try:
                start_time = time.time()
                # æ¨¡æ‹Ÿæ¨¡å‹æ¨ç†
                import numpy as np
                input_data = np.random.rand(1, 512).astype(np.float32)
                output = np.dot(input_data, np.random.rand(512, 256).astype(np.float32))
                inference_time = time.time() - start_time

                speed_results['model_inference'] = {
                    'status': 'success',
                    'inference_time': inference_time,
                    'inferences_per_second': 1 / inference_time if inference_time > 0 else 0
                }
                logger.info(f"âœ… æ¨¡å‹æ¨ç†é€Ÿåº¦: {inference_time:.3f}ç§’/æ¬¡")
            except Exception as e:
                speed_results['model_inference'] = {'status': 'failed', 'error': str(e)}
                logger.error(f"âŒ æ¨¡å‹æ¨ç†é€Ÿåº¦æµ‹è¯•å¤±è´¥: {e}")

            # è®¡ç®—å¤„ç†é€Ÿåº¦å‡†ç¡®ç‡
            speed_results['accuracy_score'] = self._calculate_speed_accuracy(speed_results)

        except Exception as e:
            logger.error(f"âŒ å¤„ç†é€Ÿåº¦åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")

        self.results['performance_tests']['processing_speed'] = speed_results

    def _calculate_benchmark_accuracy(self, benchmark_results: Dict) -> float:
        """è®¡ç®—åŸºå‡†æµ‹è¯•å‡†ç¡®ç‡"""
        try:
            score = 0
            total = 0

            if benchmark_results['cpu_performance'] and benchmark_results['cpu_performance']['status'] == 'success':
                score += 1
            total += 1

            if benchmark_results['gpu_performance']:
                if benchmark_results['gpu_performance']['status'] == 'success':
                    score += 1
                elif benchmark_results['gpu_performance']['status'] == 'no_gpu':
                    score += 0.5  # éƒ¨åˆ†åˆ†æ•°ï¼Œå› ä¸ºæ²¡æœ‰GPUæ˜¯æ­£å¸¸æƒ…å†µ
                total += 1

            return (score / total) * 100 if total > 0 else 0.0
        except Exception:
            return 0.0

    def _calculate_resource_monitoring_accuracy(self, resource_results: Dict) -> float:
        """è®¡ç®—èµ„æºç›‘æ§å‡†ç¡®ç‡"""
        try:
            score = 0
            total = 0

            for key in ['cpu_usage', 'memory_usage']:
                if resource_results[key] and resource_results[key]['status'] == 'success':
                    score += 1
                total += 1

            # GPUä½¿ç”¨ç‡ç›‘æ§ï¼ˆå¯é€‰ï¼‰
            if resource_results['gpu_usage']:
                if resource_results['gpu_usage']['status'] == 'success':
                    score += 1
                elif resource_results['gpu_usage']['status'] == 'no_gpu':
                    score += 0.5
                total += 1

            return (score / total) * 100 if total > 0 else 0.0
        except Exception:
            return 0.0

    def _calculate_speed_accuracy(self, speed_results: Dict) -> float:
        """è®¡ç®—å¤„ç†é€Ÿåº¦å‡†ç¡®ç‡"""
        try:
            score = 0
            total = 0

            for key in ['image_processing', 'video_processing', 'model_inference']:
                if speed_results[key] and speed_results[key]['status'] == 'success':
                    score += 1
                total += 1

            return (score / total) * 100 if total > 0 else 0.0
        except Exception:
            return 0.0

    def _stage4_generate_report(self):
        """ç¬¬å››é˜¶æ®µï¼šç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        logger.info("\nğŸ“ ç¬¬å››é˜¶æ®µï¼šç”Ÿæˆæµ‹è¯•æŠ¥å‘Š")
        logger.info("-" * 50)

        # è®¡ç®—æ€»ä½“è¯„åˆ†
        self._calculate_overall_score()

        # ç”Ÿæˆå»ºè®®
        self._generate_recommendations()

        # è¾“å‡ºæ‘˜è¦
        self._print_summary()

    def _calculate_overall_score(self):
        """è®¡ç®—æ€»ä½“è¯„åˆ†"""
        try:
            scores = []
            weights = []

            # GPUæ£€æµ‹è¯„åˆ† (æƒé‡: 25%)
            detection_scores = []
            if 'gpu_detection' in self.results:
                if 'hardware' in self.results['gpu_detection']:
                    detection_scores.append(self.results['gpu_detection']['hardware'].get('accuracy_score', 0))
                if 'memory' in self.results['gpu_detection']:
                    detection_scores.append(self.results['gpu_detection']['memory'].get('accuracy_score', 0))
                if 'fallback' in self.results['gpu_detection']:
                    detection_scores.append(self.results['gpu_detection']['fallback'].get('accuracy_score', 0))

            if detection_scores:
                scores.append(sum(detection_scores) / len(detection_scores))
                weights.append(0.25)

            # è®¡ç®—æ¡†æ¶è¯„åˆ† (æƒé‡: 20%)
            if 'compute_frameworks' in self.results:
                framework_score = self.results['compute_frameworks'].get('accuracy_score', 0)
                scores.append(framework_score)
                weights.append(0.20)

            # æ€§èƒ½æµ‹è¯•è¯„åˆ† (æƒé‡: 35%)
            performance_scores = []
            if 'performance_tests' in self.results:
                for test_type in ['video_processing', 'model_inference', 'memory_management', 'error_handling']:
                    if test_type in self.results['performance_tests']:
                        test_score = self.results['performance_tests'][test_type].get('accuracy_score', 0)
                        performance_scores.append(test_score)

                if performance_scores:
                    scores.append(sum(performance_scores) / len(performance_scores))
                    weights.append(0.35)

            # åŸºå‡†æµ‹è¯•è¯„åˆ† (æƒé‡: 20%)
            benchmark_scores = []
            if 'performance_tests' in self.results:
                for test_type in ['benchmarks', 'resource_monitoring', 'processing_speed']:
                    if test_type in self.results['performance_tests']:
                        test_score = self.results['performance_tests'][test_type].get('accuracy_score', 0)
                        benchmark_scores.append(test_score)

                if benchmark_scores:
                    scores.append(sum(benchmark_scores) / len(benchmark_scores))
                    weights.append(0.20)

            # è®¡ç®—åŠ æƒå¹³å‡åˆ†
            if scores and weights:
                total_weight = sum(weights)
                weighted_sum = sum(score * weight for score, weight in zip(scores, weights))
                self.results['overall_score'] = weighted_sum / total_weight
            else:
                self.results['overall_score'] = 0

            logger.info(f"âœ… æ€»ä½“è¯„åˆ†è®¡ç®—å®Œæˆ: {self.results['overall_score']:.1f}/100")

        except Exception as e:
            logger.error(f"âŒ æ€»ä½“è¯„åˆ†è®¡ç®—å¤±è´¥: {e}")
            self.results['overall_score'] = 0

    def _generate_recommendations(self):
        """ç”Ÿæˆå»ºè®®"""
        recommendations = []

        try:
            # åŸºäºGPUæ£€æµ‹ç»“æœç”Ÿæˆå»ºè®®
            if 'gpu_detection' in self.results:
                hardware = self.results['gpu_detection'].get('hardware', {})
                if hardware.get('accuracy_score', 0) < 95:
                    recommendations.append({
                        'category': 'GPUæ£€æµ‹',
                        'priority': 'high',
                        'issue': 'GPUç¡¬ä»¶æ£€æµ‹å‡†ç¡®ç‡ä½äº95%',
                        'recommendation': 'å»ºè®®æ£€æŸ¥GPUé©±åŠ¨ç¨‹åºå®‰è£…ï¼Œç¡®ä¿nvidia-smiæˆ–ç›¸åº”GPUå·¥å…·å¯ç”¨'
                    })

            # åŸºäºè®¡ç®—æ¡†æ¶ç»“æœç”Ÿæˆå»ºè®®
            if 'compute_frameworks' in self.results:
                if not self.results['compute_frameworks'].get('cuda', {}).get('available', False):
                    recommendations.append({
                        'category': 'è®¡ç®—æ¡†æ¶',
                        'priority': 'medium',
                        'issue': 'CUDAä¸å¯ç”¨',
                        'recommendation': 'è€ƒè™‘å®‰è£…CUDA Toolkitå’ŒPyTorch GPUç‰ˆæœ¬ä»¥è·å¾—æœ€ä½³æ€§èƒ½'
                    })

                if not self.results['compute_frameworks'].get('opencl', {}).get('available', False):
                    recommendations.append({
                        'category': 'è®¡ç®—æ¡†æ¶',
                        'priority': 'low',
                        'issue': 'OpenCLä¸å¯ç”¨',
                        'recommendation': 'è€ƒè™‘å®‰è£…PyOpenCLä»¥æ”¯æŒæ›´å¤šGPUç±»å‹'
                    })

            # åŸºäºæ€§èƒ½æµ‹è¯•ç»“æœç”Ÿæˆå»ºè®®
            if 'performance_tests' in self.results:
                benchmarks = self.results['performance_tests'].get('benchmarks', {})
                performance_gain = benchmarks.get('performance_gain', 0)

                if performance_gain < 20:
                    recommendations.append({
                        'category': 'æ€§èƒ½ä¼˜åŒ–',
                        'priority': 'medium',
                        'issue': f'GPUæ€§èƒ½æå‡ä»…ä¸º{performance_gain:.1f}%ï¼Œä½äº20%ç›®æ ‡',
                        'recommendation': 'æ£€æŸ¥GPUåˆ©ç”¨ç‡ï¼Œè€ƒè™‘ä¼˜åŒ–æ‰¹å¤„ç†å¤§å°æˆ–ç®—æ³•å®ç°'
                    })

            # åŸºäºæ€»ä½“è¯„åˆ†ç”Ÿæˆå»ºè®®
            overall_score = self.results.get('overall_score', 0)
            if overall_score < 80:
                recommendations.append({
                    'category': 'æ•´ä½“ä¼˜åŒ–',
                    'priority': 'high',
                    'issue': f'æ€»ä½“è¯„åˆ†{overall_score:.1f}åˆ†ä½äº80åˆ†',
                    'recommendation': 'å»ºè®®ä¼˜å…ˆè§£å†³é«˜ä¼˜å…ˆçº§é—®é¢˜ï¼Œæå‡GPUåŠ é€ŸåŠŸèƒ½çš„æ•´ä½“å¯ç”¨æ€§'
                })
            elif overall_score >= 95:
                recommendations.append({
                    'category': 'æ•´ä½“è¯„ä¼°',
                    'priority': 'info',
                    'issue': 'æ— ',
                    'recommendation': 'GPUåŠ é€ŸåŠŸèƒ½è¡¨ç°ä¼˜ç§€ï¼Œå»ºè®®ç»§ç»­ä¿æŒå¹¶å®šæœŸç›‘æ§æ€§èƒ½'
                })

            self.results['recommendations'] = recommendations
            logger.info(f"âœ… ç”Ÿæˆäº† {len(recommendations)} æ¡å»ºè®®")

        except Exception as e:
            logger.error(f"âŒ å»ºè®®ç”Ÿæˆå¤±è´¥: {e}")
            self.results['recommendations'] = []

    def _print_summary(self):
        """æ‰“å°æµ‹è¯•æ‘˜è¦"""
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ‰ VisionAI-ClipsMaster GPUåŠ é€ŸåŠŸèƒ½éªŒè¯æµ‹è¯•å®Œæˆ")
        logger.info("=" * 80)

        # æ€»ä½“è¯„åˆ†
        overall_score = self.results.get('overall_score', 0)
        logger.info(f"ğŸ† æ€»ä½“è¯„åˆ†: {overall_score:.1f}/100")

        if overall_score >= 95:
            logger.info("âœ… è¯„çº§: A+ (ä¼˜ç§€)")
        elif overall_score >= 85:
            logger.info("âœ… è¯„çº§: A (è‰¯å¥½)")
        elif overall_score >= 75:
            logger.info("âš ï¸ è¯„çº§: B (ä¸€èˆ¬)")
        elif overall_score >= 60:
            logger.info("âš ï¸ è¯„çº§: C (éœ€è¦æ”¹è¿›)")
        else:
            logger.info("âŒ è¯„çº§: D (éœ€è¦å¤§å¹…æ”¹è¿›)")

        # å…³é”®æŒ‡æ ‡
        logger.info("\nğŸ“Š å…³é”®æŒ‡æ ‡:")

        # GPUæ£€æµ‹å‡†ç¡®ç‡
        if 'gpu_detection' in self.results and 'hardware' in self.results['gpu_detection']:
            detection_score = self.results['gpu_detection']['hardware'].get('accuracy_score', 0)
            logger.info(f"   GPUæ£€æµ‹å‡†ç¡®ç‡: {detection_score:.1f}%")

        # æ€§èƒ½æå‡
        if 'performance_tests' in self.results and 'benchmarks' in self.results['performance_tests']:
            performance_gain = self.results['performance_tests']['benchmarks'].get('performance_gain', 0)
            logger.info(f"   GPUæ€§èƒ½æå‡: {performance_gain:.1f}%")

        # å»ºè®®æ•°é‡
        recommendations = self.results.get('recommendations', [])
        high_priority = len([r for r in recommendations if r.get('priority') == 'high'])
        logger.info(f"   é«˜ä¼˜å…ˆçº§å»ºè®®: {high_priority} æ¡")

        logger.info("\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå°†ä¿å­˜ä¸ºJSONæ–‡ä»¶")

if __name__ == "__main__":
    suite = GPUVerificationSuite()
    results = suite.run_full_verification()
    
    # ä¿å­˜ç»“æœ
    output_file = f"gpu_verification_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“„ æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {output_file}")
    print(f"ğŸ† æ€»ä½“è¯„åˆ†: {results['overall_score']}/100")
