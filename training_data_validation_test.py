#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è®­ç»ƒæ•°æ®éªŒè¯æµ‹è¯•
ä¸“é—¨éªŒè¯"åŸç‰‡å­—å¹•â†’çˆ†æ¬¾å­—å¹•"çš„è®­ç»ƒæ•°æ®å¯¹æ ¼å¼å’Œè´¨é‡
"""

import os
import sys
import json
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Tuple

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "src"))

class TrainingDataValidator:
    """è®­ç»ƒæ•°æ®éªŒè¯å™¨"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent
        self.results = {
            "timestamp": datetime.now().isoformat(),
            "validation_results": {},
            "data_quality_metrics": {},
            "recommendations": []
        }
        self.setup_logging()
        
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
        
    def validate_srt_format(self, srt_content: str) -> Dict[str, Any]:
        """éªŒè¯SRTå­—å¹•æ ¼å¼"""
        lines = srt_content.strip().split('\n')
        
        validation = {
            "is_valid": True,
            "subtitle_count": 0,
            "format_errors": [],
            "time_format_errors": [],
            "encoding_issues": []
        }
        
        i = 0
        subtitle_count = 0
        
        while i < len(lines):
            # è·³è¿‡ç©ºè¡Œ
            while i < len(lines) and not lines[i].strip():
                i += 1
                
            if i >= len(lines):
                break
                
            # æ£€æŸ¥åºå·
            if not lines[i].strip().isdigit():
                validation["format_errors"].append(f"è¡Œ {i+1}: åºå·æ ¼å¼é”™è¯¯")
                validation["is_valid"] = False
                i += 1
                continue
                
            i += 1
            if i >= len(lines):
                validation["format_errors"].append("æ–‡ä»¶æ„å¤–ç»“æŸ")
                break
                
            # æ£€æŸ¥æ—¶é—´è½´æ ¼å¼
            time_line = lines[i].strip()
            if "-->" not in time_line:
                validation["format_errors"].append(f"è¡Œ {i+1}: æ—¶é—´è½´æ ¼å¼é”™è¯¯")
                validation["is_valid"] = False
            else:
                # éªŒè¯æ—¶é—´æ ¼å¼ (HH:MM:SS,mmm --> HH:MM:SS,mmm)
                parts = time_line.split(" --> ")
                if len(parts) != 2:
                    validation["time_format_errors"].append(f"è¡Œ {i+1}: æ—¶é—´è½´åˆ†éš”ç¬¦é”™è¯¯")
                else:
                    for part in parts:
                        if not self._is_valid_time_format(part.strip()):
                            validation["time_format_errors"].append(f"è¡Œ {i+1}: æ—¶é—´æ ¼å¼é”™è¯¯ - {part}")
                            
            i += 1
            
            # è¯»å–å­—å¹•æ–‡æœ¬
            subtitle_text = []
            while i < len(lines) and lines[i].strip():
                subtitle_text.append(lines[i])
                i += 1
                
            if not subtitle_text:
                validation["format_errors"].append(f"å­—å¹• {subtitle_count + 1}: ç¼ºå°‘å­—å¹•æ–‡æœ¬")
                
            subtitle_count += 1
            
        validation["subtitle_count"] = subtitle_count
        return validation
        
    def _is_valid_time_format(self, time_str: str) -> bool:
        """æ£€æŸ¥æ—¶é—´æ ¼å¼æ˜¯å¦æ­£ç¡®"""
        try:
            # æ ¼å¼: HH:MM:SS,mmm
            if ',' not in time_str:
                return False
            time_part, ms_part = time_str.split(',')
            if len(ms_part) != 3:
                return False
            time_components = time_part.split(':')
            if len(time_components) != 3:
                return False
            hours, minutes, seconds = map(int, time_components)
            milliseconds = int(ms_part)
            return 0 <= hours <= 23 and 0 <= minutes <= 59 and 0 <= seconds <= 59 and 0 <= milliseconds <= 999
        except:
            return False
            
    def validate_training_pair(self, original_srt: str, viral_srt: str) -> Dict[str, Any]:
        """éªŒè¯è®­ç»ƒæ•°æ®å¯¹"""
        validation = {
            "pair_valid": True,
            "original_validation": {},
            "viral_validation": {},
            "pair_analysis": {},
            "issues": []
        }
        
        # éªŒè¯åŸç‰‡å­—å¹•
        validation["original_validation"] = self.validate_srt_format(original_srt)
        
        # éªŒè¯çˆ†æ¬¾å­—å¹•
        validation["viral_validation"] = self.validate_srt_format(viral_srt)
        
        # åˆ†ææ•°æ®å¯¹å…³ç³»
        if validation["original_validation"]["is_valid"] and validation["viral_validation"]["is_valid"]:
            original_count = validation["original_validation"]["subtitle_count"]
            viral_count = validation["viral_validation"]["subtitle_count"]
            
            validation["pair_analysis"] = {
                "original_subtitle_count": original_count,
                "viral_subtitle_count": viral_count,
                "compression_ratio": viral_count / original_count if original_count > 0 else 0,
                "is_compressed": viral_count < original_count,
                "compression_percentage": (1 - viral_count / original_count) * 100 if original_count > 0 else 0
            }
            
            # æ£€æŸ¥å‹ç¼©æ¯”æ˜¯å¦åˆç†
            compression_ratio = validation["pair_analysis"]["compression_ratio"]
            if compression_ratio < 0.1:  # å‹ç¼©è¿‡åº¦
                validation["issues"].append("å‹ç¼©æ¯”è¿‡ä½ï¼Œå¯èƒ½ä¸¢å¤±é‡è¦å‰§æƒ…")
                validation["pair_valid"] = False
            elif compression_ratio > 0.9:  # å‡ ä¹æ²¡æœ‰å‹ç¼©
                validation["issues"].append("å‹ç¼©æ¯”è¿‡é«˜ï¼Œä¸åŸç‰‡å·®å¼‚ä¸å¤§")
                validation["pair_valid"] = False
                
        else:
            validation["pair_valid"] = False
            if not validation["original_validation"]["is_valid"]:
                validation["issues"].append("åŸç‰‡å­—å¹•æ ¼å¼æ— æ•ˆ")
            if not validation["viral_validation"]["is_valid"]:
                validation["issues"].append("çˆ†æ¬¾å­—å¹•æ ¼å¼æ— æ•ˆ")
                
        return validation
        
    def scan_training_data(self) -> Dict[str, Any]:
        """æ‰«ææ‰€æœ‰è®­ç»ƒæ•°æ®"""
        results = {
            "english_data": {"valid_pairs": 0, "invalid_pairs": 0, "total_files": 0},
            "chinese_data": {"valid_pairs": 0, "invalid_pairs": 0, "total_files": 0},
            "detailed_results": [],
            "quality_metrics": {}
        }
        
        # æ‰«æè‹±æ–‡è®­ç»ƒæ•°æ®
        en_dir = self.project_root / "data/training/en"
        if en_dir.exists():
            en_results = self._scan_language_data(en_dir, "en")
            results["english_data"].update(en_results)
            
        # æ‰«æä¸­æ–‡è®­ç»ƒæ•°æ®
        zh_dir = self.project_root / "data/training/zh"
        if zh_dir.exists():
            zh_results = self._scan_language_data(zh_dir, "zh")
            results["chinese_data"].update(zh_results)
            
        # è®¡ç®—æ•´ä½“è´¨é‡æŒ‡æ ‡
        total_valid = results["english_data"]["valid_pairs"] + results["chinese_data"]["valid_pairs"]
        total_invalid = results["english_data"]["invalid_pairs"] + results["chinese_data"]["invalid_pairs"]
        total_pairs = total_valid + total_invalid
        
        results["quality_metrics"] = {
            "total_training_pairs": total_pairs,
            "valid_pairs": total_valid,
            "invalid_pairs": total_invalid,
            "validity_rate": total_valid / total_pairs * 100 if total_pairs > 0 else 0,
            "data_quality_score": self._calculate_quality_score(results)
        }
        
        return results
        
    def _scan_language_data(self, data_dir: Path, language: str) -> Dict[str, Any]:
        """æ‰«æç‰¹å®šè¯­è¨€çš„è®­ç»ƒæ•°æ®"""
        results = {
            "valid_pairs": 0,
            "invalid_pairs": 0,
            "total_files": 0,
            "file_details": []
        }
        
        # æŸ¥æ‰¾è®­ç»ƒæ•°æ®æ–‡ä»¶
        data_files = list(data_dir.glob("*.json")) + list(data_dir.glob("*.txt"))
        results["total_files"] = len(data_files)
        
        for file_path in data_files:
            try:
                file_result = self._validate_training_file(file_path, language)
                results["file_details"].append(file_result)
                
                if file_result["is_valid"]:
                    results["valid_pairs"] += file_result.get("pair_count", 0)
                else:
                    results["invalid_pairs"] += 1
                    
            except Exception as e:
                self.logger.error(f"å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
                results["invalid_pairs"] += 1
                
        return results
        
    def _validate_training_file(self, file_path: Path, language: str) -> Dict[str, Any]:
        """éªŒè¯å•ä¸ªè®­ç»ƒæ–‡ä»¶"""
        result = {
            "file_name": file_path.name,
            "language": language,
            "is_valid": False,
            "pair_count": 0,
            "issues": []
        }
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            if file_path.suffix == '.json':
                # JSONæ ¼å¼çš„è®­ç»ƒæ•°æ®
                data = json.loads(content)
                if isinstance(data, dict) and "original_srt" in data and "viral_srt" in data:
                    validation = self.validate_training_pair(data["original_srt"], data["viral_srt"])
                    result["is_valid"] = validation["pair_valid"]
                    result["pair_count"] = 1
                    result["issues"] = validation["issues"]
                elif isinstance(data, list):
                    # å¤šä¸ªè®­ç»ƒå¯¹
                    valid_pairs = 0
                    for item in data:
                        if isinstance(item, dict) and "original_srt" in item and "viral_srt" in item:
                            validation = self.validate_training_pair(item["original_srt"], item["viral_srt"])
                            if validation["pair_valid"]:
                                valid_pairs += 1
                            else:
                                result["issues"].extend(validation["issues"])
                    result["pair_count"] = len(data)
                    result["is_valid"] = valid_pairs > 0
                else:
                    result["issues"].append("JSONæ ¼å¼ä¸ç¬¦åˆè®­ç»ƒæ•°æ®è¦æ±‚")
            else:
                # æ–‡æœ¬æ ¼å¼ï¼Œå‡è®¾æ˜¯ç®€å•çš„å­—å¹•æ–‡ä»¶
                if self.validate_srt_format(content)["is_valid"]:
                    result["is_valid"] = True
                    result["pair_count"] = 1
                else:
                    result["issues"].append("å­—å¹•æ ¼å¼æ— æ•ˆ")
                    
        except json.JSONDecodeError:
            result["issues"].append("JSONæ ¼å¼é”™è¯¯")
        except UnicodeDecodeError:
            result["issues"].append("æ–‡ä»¶ç¼–ç é”™è¯¯")
        except Exception as e:
            result["issues"].append(f"æ–‡ä»¶å¤„ç†é”™è¯¯: {str(e)}")
            
        return result
        
    def _calculate_quality_score(self, results: Dict[str, Any]) -> float:
        """è®¡ç®—æ•°æ®è´¨é‡åˆ†æ•°"""
        en_data = results["english_data"]
        zh_data = results["chinese_data"]
        
        # åŸºç¡€åˆ†æ•°ï¼šæœ‰æ•ˆæ€§
        total_valid = en_data["valid_pairs"] + zh_data["valid_pairs"]
        total_pairs = total_valid + en_data["invalid_pairs"] + zh_data["invalid_pairs"]
        validity_score = total_valid / total_pairs * 100 if total_pairs > 0 else 0
        
        # æ•°æ®å¹³è¡¡æ€§åˆ†æ•°
        balance_score = 100
        if total_valid > 0:
            en_ratio = en_data["valid_pairs"] / total_valid
            zh_ratio = zh_data["valid_pairs"] / total_valid
            # ç†æƒ³æƒ…å†µæ˜¯ä¸­è‹±æ–‡æ•°æ®å„å 50%
            balance_score = 100 - abs(en_ratio - 0.5) * 200
            
        # æ•°æ®é‡å……è¶³æ€§åˆ†æ•°
        volume_score = min(total_valid / 10 * 100, 100)  # å‡è®¾10å¯¹æ˜¯åŸºæœ¬è¦æ±‚
        
        # ç»¼åˆåˆ†æ•°
        quality_score = (validity_score * 0.5 + balance_score * 0.3 + volume_score * 0.2)
        return round(quality_score, 2)
        
    def generate_recommendations(self, scan_results: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        quality_score = scan_results["quality_metrics"]["data_quality_score"]
        validity_rate = scan_results["quality_metrics"]["validity_rate"]
        
        if validity_rate < 80:
            recommendations.append("æ•°æ®æœ‰æ•ˆæ€§ä¸è¶³ï¼Œå»ºè®®æ£€æŸ¥å’Œä¿®å¤æ— æ•ˆçš„è®­ç»ƒæ•°æ®å¯¹")
            
        if quality_score < 70:
            recommendations.append("æ•´ä½“æ•°æ®è´¨é‡åä½ï¼Œå»ºè®®å¢åŠ é«˜è´¨é‡è®­ç»ƒæ ·æœ¬")
            
        en_pairs = scan_results["english_data"]["valid_pairs"]
        zh_pairs = scan_results["chinese_data"]["valid_pairs"]
        
        if en_pairs == 0:
            recommendations.append("ç¼ºå°‘è‹±æ–‡è®­ç»ƒæ•°æ®ï¼Œå»ºè®®æ·»åŠ è‹±æ–‡åŸç‰‡â†’çˆ†æ¬¾å­—å¹•å¯¹")
        elif en_pairs < 5:
            recommendations.append("è‹±æ–‡è®­ç»ƒæ•°æ®ä¸è¶³ï¼Œå»ºè®®å¢åŠ æ›´å¤šè‹±æ–‡è®­ç»ƒæ ·æœ¬")
            
        if zh_pairs == 0:
            recommendations.append("ç¼ºå°‘ä¸­æ–‡è®­ç»ƒæ•°æ®ï¼Œå»ºè®®æ·»åŠ ä¸­æ–‡åŸç‰‡â†’çˆ†æ¬¾å­—å¹•å¯¹")
        elif zh_pairs < 5:
            recommendations.append("ä¸­æ–‡è®­ç»ƒæ•°æ®ä¸è¶³ï¼Œå»ºè®®å¢åŠ æ›´å¤šä¸­æ–‡è®­ç»ƒæ ·æœ¬")
            
        total_pairs = scan_results["quality_metrics"]["total_training_pairs"]
        if total_pairs < 10:
            recommendations.append("è®­ç»ƒæ•°æ®æ€»é‡ä¸è¶³ï¼Œå»ºè®®æ”¶é›†æ›´å¤šåŸç‰‡â†’çˆ†æ¬¾çš„è®­ç»ƒå¯¹")
            
        return recommendations
        
    def run_validation(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„è®­ç»ƒæ•°æ®éªŒè¯"""
        self.logger.info("å¼€å§‹è®­ç»ƒæ•°æ®éªŒè¯")
        
        # æ‰«æè®­ç»ƒæ•°æ®
        scan_results = self.scan_training_data()
        self.results["validation_results"] = scan_results
        
        # ç”Ÿæˆå»ºè®®
        recommendations = self.generate_recommendations(scan_results)
        self.results["recommendations"] = recommendations
        
        # ä¿å­˜ç»“æœ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"training_data_validation_{timestamp}.json"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
            
        self.logger.info(f"éªŒè¯å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³: {output_file}")
        return self.results


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” å¯åŠ¨è®­ç»ƒæ•°æ®éªŒè¯æµ‹è¯•")
    print("=" * 50)
    
    validator = TrainingDataValidator()
    results = validator.run_validation()
    
    # æ˜¾ç¤ºç»“æœæ‘˜è¦
    metrics = results["validation_results"]["quality_metrics"]
    print(f"\nğŸ“Š éªŒè¯ç»“æœæ‘˜è¦:")
    print(f"  æ€»è®­ç»ƒå¯¹æ•°: {metrics['total_training_pairs']}")
    print(f"  æœ‰æ•ˆè®­ç»ƒå¯¹: {metrics['valid_pairs']}")
    print(f"  æ— æ•ˆè®­ç»ƒå¯¹: {metrics['invalid_pairs']}")
    print(f"  æœ‰æ•ˆæ€§ç‡: {metrics['validity_rate']:.1f}%")
    print(f"  æ•°æ®è´¨é‡åˆ†æ•°: {metrics['data_quality_score']:.1f}/100")
    
    # æ˜¾ç¤ºå»ºè®®
    if results["recommendations"]:
        print(f"\nğŸ’¡ æ”¹è¿›å»ºè®®:")
        for i, rec in enumerate(results["recommendations"], 1):
            print(f"  {i}. {rec}")
    else:
        print(f"\nâœ… è®­ç»ƒæ•°æ®è´¨é‡è‰¯å¥½ï¼Œæ— éœ€ç‰¹åˆ«æ”¹è¿›")
        
    return 0


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
