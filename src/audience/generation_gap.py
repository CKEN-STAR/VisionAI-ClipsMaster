#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ä»£é™…å·®å¼‚æ¡¥æ¥å™¨æ¨¡å—

å¸®åŠ©å¼¥åˆä¸åŒä»£é™…ç¾¤ä½“ä¹‹é—´çš„æ–‡åŒ–å·®å¼‚ï¼Œä¼˜åŒ–å†…å®¹åœ¨ä¸åŒå¹´é¾„å±‚å—ä¼—ä¸­çš„ç†è§£å’Œæ¥å—åº¦ã€‚
é€šè¿‡è¯†åˆ«å’Œè½¬æ¢ä»£é™…æ–‡åŒ–å‚è€ƒï¼Œä½¿å†…å®¹èƒ½å¤Ÿè·¨ä»£é™…æœ‰æ•ˆä¼ æ’­ã€‚
æ”¯æŒZä¸–ä»£ã€80åã€90åã€00åç­‰ä¸åŒä¸–ä»£ç¾¤ä½“ä¹‹é—´çš„æ–‡åŒ–è¡¨è¾¾æ¡¥æ¥ã€‚
"""

import os
import copy
import json
import logging
import re
from typing import Dict, List, Any, Optional, Tuple, Union, Set
from pathlib import Path

from loguru import logger
from src.utils.log_handler import get_logger
from src.adaptation.culture_adapter import CultureAdapter
from src.nlp.text_processor import TextProcessor

# é…ç½®æ—¥å¿—
generation_logger = get_logger("generation_bridge")

class GenerationBridge:
    """
    ä»£é™…å·®å¼‚æ¡¥æ¥å™¨
    
    å¸®åŠ©ä¼˜åŒ–å†…å®¹åœ¨ä¸åŒä¸–ä»£å—ä¼—ä¹‹é—´çš„æœ‰æ•ˆä¼ æ’­ï¼Œé€šè¿‡è½¬æ¢ä»£é™…ç‰¹å®šçš„æ–‡åŒ–å‚è€ƒã€
    æµè¡Œè¯­ã€è¡¨è¾¾æ–¹å¼å’Œæ¢—ï¼Œä½¿å†…å®¹æ›´å®¹æ˜“è¢«ç›®æ ‡ä¸–ä»£ç†è§£å’Œæ¥å—ã€‚
    """
    
    # é»˜è®¤ä»£é™…å‚è€ƒç‚¹æ˜ å°„
    REFERENCE_POINTS = {
        "Zä¸–ä»£": ["äºŒæ¬¡å…ƒ", "æ•´ç‰‡åŒ–", "ç©æ¢—", "åŸç¥", "é¬¼ç•œ", "å˜å˜çŒ›", "ç»ç»å­", "ç¬‘æ­»", "yyds", "ç ´é˜²", "çœŸé¦™"],
        "90å": ["QQç©ºé—´", "éä¸»æµ", "è´´å§", "ç¥æ›²", "LOL", "å¾®åš", "ç§’æ‡‚", "è“ç˜¦é¦™è‡", "å°é²œè‚‰", "æ¥åœ°æ°”"],
        "80å": ["æ€€æ—§", "ç»å…¸æ¬¾", "é•¿å™äº‹", "ç«¥å¹´", "æ¸¯å°æ–‡åŒ–", "æµè¡Œæ­Œ", "é’æ˜¥", "å°æ—¶å€™", "æˆé•¿", "è€æ­Œ"],
        "70å": ["å²æœˆ", "è€æ•…äº‹", "ä¼ ç»Ÿ", "ç»å…¸", "ä»·å€¼è§‚", "æ–‡åŒ–åº•è•´", "ç”µè§†å‰§", "é›†ä½“è®°å¿†", "æ€€æ—§é‡‘æ›²", "å¹´ä»£æ„Ÿ"],
        "60å": ["ä¼ ç»Ÿæ–‡åŒ–", "å†å²", "å›½äº§", "è€ç”µå½±", "ç›¸å£°", "æˆæ›²", "å¹´ä»£å‰§", "çº¢è‰²ç»å…¸", "é©å‘½æ•…äº‹", "é›†ä½“ä¸»ä¹‰"]
    }
    
    # ä¸–ä»£ä¹‹é—´çš„å…±åŒå‚è€ƒç‚¹æ˜ å°„ï¼ˆè¾…åŠ©è·¨ä»£ç¿»è¯‘ï¼‰
    COMMON_REFERENCES = {
        ("Zä¸–ä»£", "90å"): ["ç½‘ç»œæ–‡åŒ–", "ç”µå­æ¸¸æˆ", "æ‰‹æœºAPP", "çŸ­è§†é¢‘"],
        ("90å", "80å"): ["æ ¡å›­ç”Ÿæ´»", "é’æ˜¥å›å¿†", "æˆé•¿çƒ¦æ¼", "å¶åƒæ–‡åŒ–"],
        ("80å", "70å"): ["å®¶åº­è§‚å¿µ", "å·¥ä½œæ€åº¦", "ç¤¾ä¼šå˜è¿", "ä¼ ç»Ÿä»·å€¼"]
    }
    
    def __init__(self, config_path: Optional[str] = None):
        """
        åˆå§‹åŒ–ä»£é™…å·®å¼‚æ¡¥æ¥å™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
        """
        # åŠ è½½é…ç½®
        self.config = self._load_config(config_path)
        
        # åˆå§‹åŒ–æ–‡åŒ–é€‚é…å™¨
        self.culture_adapter = CultureAdapter()
        
        # åˆå§‹åŒ–æ–‡æœ¬å¤„ç†å™¨
        self.text_processor = TextProcessor()
        
        # åŠ è½½ä»£é™…è¡¨è¾¾æ˜ å°„
        self._load_generation_mappings()
        
        generation_logger.info("ä»£é™…å·®å¼‚æ¡¥æ¥å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _load_config(self, config_path: Optional[str]) -> Dict[str, Any]:
        """
        åŠ è½½é…ç½®æ–‡ä»¶
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            
        Returns:
            é…ç½®å­—å…¸
        """
        default_config = {
            "adaptation_level": 0.7,  # ä»£é™…é€‚é…å¼ºåº¦ï¼Œ0-1ä¹‹é—´
            "preserve_core_meaning": True,  # ä¿ç•™æ ¸å¿ƒå«ä¹‰
            "translate_slang": True,  # è½¬æ¢ä¿šè¯­/æµè¡Œè¯­
            "translate_references": True,  # è½¬æ¢æ–‡åŒ–å‚è€ƒ
            "translate_memes": True,  # è½¬æ¢æ¢—
            "add_explanations": False,  # ä¸ºç›®æ ‡ä»£é™…æ·»åŠ è§£é‡Š
            "explanation_style": "parentheses",  # è§£é‡Šæ ·å¼ï¼šparentheses, footnote
            "generation_definitions": {
                "Zä¸–ä»£": {"birth_years": [2000, 2015], "also_known_as": ["00å", "10å", "Zæ—¶ä»£"]},
                "90å": {"birth_years": [1990, 1999], "also_known_as": ["90å"]},
                "80å": {"birth_years": [1980, 1989], "also_known_as": ["80å"]},
                "70å": {"birth_years": [1970, 1979], "also_known_as": ["70å"]},
                "60å": {"birth_years": [1960, 1969], "also_known_as": ["60å"]}
            }
        }
        
        if config_path and os.path.exists(config_path):
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                default_config.update(config)
                generation_logger.info(f"ä»{config_path}åŠ è½½é…ç½®æ–‡ä»¶æˆåŠŸ")
            except Exception as e:
                generation_logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
                
        return default_config
    
    def _load_generation_mappings(self):
        """
        åŠ è½½ä»£é™…è¡¨è¾¾æ˜ å°„æ•°æ®
        """
        self.generation_maps = {}
        
        # é¢„å®šä¹‰çš„åŸºç¡€æ˜ å°„
        base_mappings = {
            ("Zä¸–ä»£", "80å"): {
                "äºŒæ¬¡å…ƒ": "åŠ¨æ¼«",
                "yyds": "æœ€æ£’çš„",
                "ç»ç»å­": "å¤ªå‰å®³äº†",
                "ç ´é˜²": "å—æ‰“å‡»",
                "çœŸé¦™": "çœŸçš„å¾ˆä¸é”™",
                "é¬¼ç•œ": "æç¬‘è§†é¢‘",
                "æ•´ç‰‡åŒ–": "å®Œæ•´è§‚çœ‹",
                "åŸç¥": "çƒ­é—¨æ¸¸æˆ",
                "å˜å˜çŒ›": "éå¸¸å‰å®³",
                "ç¬‘æ­»": "å¾ˆå¥½ç¬‘"
            },
            ("80å", "Zä¸–ä»£"): {
                "éä¸»æµ": "ç‹¬ç‰¹é£æ ¼",
                "è´´å§": "ç½‘ç»œè®ºå›",
                "QQç©ºé—´": "ç¤¾äº¤å¹³å°",
                "å°æ—¶å€™": "ç«¥å¹´",
                "æ€€æ—§": "å¤å¤",
                "90å¹´ä»£": "è€æ—§æ—¶æœŸ",
                "è€æ­Œ": "ç»å…¸æ­Œæ›²",
                "æ¸¯å°": "é¦™æ¸¯å°æ¹¾",
                "é•¿ç¯‡æ•…äº‹": "é•¿å†…å®¹"
            }
        }
        
        # æ‰©å±•åˆ°æ‰€æœ‰ä»£é™…ç»„åˆ
        generations = list(self.REFERENCE_POINTS.keys())
        for i, gen1 in enumerate(generations):
            for j, gen2 in enumerate(generations):
                if i != j:
                    key = (gen1, gen2)
                    
                    # æŸ¥æ‰¾æ˜¯å¦æœ‰é¢„å®šä¹‰æ˜ å°„
                    if key in base_mappings:
                        self.generation_maps[key] = base_mappings[key]
                    elif (gen2, gen1) in base_mappings:
                        # åˆ›å»ºåå‘æ˜ å°„
                        self.generation_maps[key] = {v: k for k, v in base_mappings[(gen2, gen1)].items()}
                    else:
                        # åˆ›å»ºç©ºæ˜ å°„
                        self.generation_maps[key] = {}
        
        # å°è¯•ä»æ–‡ä»¶åŠ è½½æ›´å¤šæ˜ å°„
        try:
            data_dir = Path(__file__).parent.parent.parent / 'data' / 'generation'
            if not data_dir.exists():
                data_dir.mkdir(parents=True, exist_ok=True)
                
            # æ£€æŸ¥æ˜¯å¦æœ‰æ˜ å°„æ–‡ä»¶å­˜åœ¨
            for gen1 in generations:
                for gen2 in generations:
                    if gen1 != gen2:
                        file_path = data_dir / f"{gen1}_to_{gen2}.json"
                        
                        if file_path.exists():
                            with open(file_path, 'r', encoding='utf-8') as f:
                                additional_map = json.load(f)
                                
                            key = (gen1, gen2)
                            if key in self.generation_maps:
                                self.generation_maps[key].update(additional_map)
                            else:
                                self.generation_maps[key] = additional_map
                                
                            generation_logger.info(f"ä»{file_path}åŠ è½½äº†{len(additional_map)}ä¸ªä»£é™…è¡¨è¾¾æ˜ å°„")
        except Exception as e:
            generation_logger.warning(f"åŠ è½½ä»£é™…æ˜ å°„æ–‡ä»¶å¤±è´¥: {str(e)}")
    
    def bridge_gap(self, content: Dict[str, Any], target_gen: str) -> Dict[str, Any]:
        """
        å¼¥åˆä¸åŒä¸–ä»£ä¹‹é—´çš„ä»£é™…å·®å¼‚
        
        å°†å†…å®¹ä¸­çš„ä»£é™…ç‰¹å®šè¡¨è¾¾è½¬æ¢ä¸ºç›®æ ‡ä¸–ä»£æ›´å®¹æ˜“ç†è§£çš„å½¢å¼ï¼Œ
        ä¼˜åŒ–è·¨ä»£é™…å†…å®¹ä¼ æ’­æ•ˆæœã€‚
        
        Args:
            content: éœ€è¦è½¬æ¢çš„å†…å®¹
            target_gen: ç›®æ ‡ä¸–ä»£ï¼Œä¾‹å¦‚ "Zä¸–ä»£", "80å" ç­‰
            
        Returns:
            è½¬æ¢åçš„å†…å®¹
        """
        generation_logger.info(f"å¼€å§‹å°†å†…å®¹è½¬æ¢ä¸º{target_gen}é£æ ¼")
        
        # æ£€æŸ¥ç›®æ ‡ä¸–ä»£æ˜¯å¦æœ‰æ•ˆ
        if target_gen not in self.REFERENCE_POINTS:
            generation_logger.warning(f"æœªçŸ¥çš„ç›®æ ‡ä¸–ä»£: {target_gen}ï¼Œä½¿ç”¨é»˜è®¤ä¸–ä»£")
            target_gen = list(self.REFERENCE_POINTS.keys())[0]
        
        # åˆ›å»ºå†…å®¹å‰¯æœ¬
        result = copy.deepcopy(content)
        
        # æ£€æµ‹æºå†…å®¹çš„ä¸–ä»£å€¾å‘
        source_gen = self._detect_generation(content)
        generation_logger.debug(f"æ£€æµ‹åˆ°æºå†…å®¹ä¸–ä»£å€¾å‘: {source_gen}")
        
        # å¦‚æœæºä¸–ä»£å’Œç›®æ ‡ä¸–ä»£ç›¸åŒï¼Œæ— éœ€è½¬æ¢
        if source_gen == target_gen:
            generation_logger.info("æºä¸–ä»£ä¸ç›®æ ‡ä¸–ä»£ç›¸åŒï¼Œæ— éœ€è½¬æ¢")
            return result
        
        # è·å–ç›®æ ‡ä¸–ä»£çš„å‚è€ƒç‚¹
        target_references = self.REFERENCE_POINTS[target_gen]
        
        # åº”ç”¨ä»£é™…è½¬æ¢
        result = self._transform_to_generation(result, source_gen, target_gen)
        
        generation_logger.info(f"å†…å®¹æˆåŠŸè½¬æ¢ä¸º{target_gen}é£æ ¼")
        return result
    
    def _detect_generation(self, content: Dict[str, Any]) -> str:
        """
        æ£€æµ‹å†…å®¹çš„ä¸–ä»£å€¾å‘
        
        æ ¹æ®å†…å®¹ä¸­çš„å…³é”®è¯å’Œè¡¨è¾¾æ–¹å¼ï¼Œåˆ¤æ–­å†…å®¹æ›´æ¥è¿‘å“ªä¸ªä¸–ä»£
        
        Args:
            content: å†…å®¹æ•°æ®
            
        Returns:
            æ£€æµ‹åˆ°çš„ä¸–ä»£æ ‡è¯†
        """
        # æå–æ‰€æœ‰æ–‡æœ¬
        text_content = self._extract_text_content(content)
        
        # è®¡ç®—æ¯ä¸ªä¸–ä»£çš„åŒ¹é…åˆ†æ•°
        scores = {}
        for generation, references in self.REFERENCE_POINTS.items():
            score = 0
            for ref in references:
                if ref in text_content:
                    score += 1
            
            # å½’ä¸€åŒ–åˆ†æ•°
            if references:
                scores[generation] = score / len(references)
            else:
                scores[generation] = 0
        
        # æ‰¾å‡ºå¾—åˆ†æœ€é«˜çš„ä¸–ä»£
        if scores:
            max_gen = max(scores.items(), key=lambda x: x[1])
            if max_gen[1] > 0:
                return max_gen[0]
        
        # é»˜è®¤è¿”å›ä¸­é—´ä»£é™…
        return list(self.REFERENCE_POINTS.keys())[len(self.REFERENCE_POINTS) // 2]
    
    def _extract_text_content(self, content: Dict[str, Any]) -> str:
        """
        ä»å†…å®¹ä¸­æå–æ‰€æœ‰æ–‡æœ¬
        
        Args:
            content: å†…å®¹æ•°æ®
            
        Returns:
            åˆå¹¶åçš„æ–‡æœ¬
        """
        text_parts = []
        
        # æå–æ ‡é¢˜
        if "title" in content and isinstance(content["title"], str):
            text_parts.append(content["title"])
        
        # æå–æè¿°
        if "description" in content and isinstance(content["description"], str):
            text_parts.append(content["description"])
        
        # æå–å¯¹è¯
        if "dialogues" in content and isinstance(content["dialogues"], list):
            for dialogue in content["dialogues"]:
                if isinstance(dialogue, dict) and "text" in dialogue:
                    text_parts.append(dialogue["text"])
        
        # æå–åœºæ™¯æè¿°
        if "scenes" in content and isinstance(content["scenes"], list):
            for scene in content["scenes"]:
                if isinstance(scene, dict):
                    if "description" in scene:
                        text_parts.append(scene["description"])
                    
                    # æå–åœºæ™¯å…ƒç´ å†…å®¹
                    if "elements" in scene and isinstance(scene["elements"], list):
                        for element in scene["elements"]:
                            if isinstance(element, dict) and "content" in element:
                                text_parts.append(element["content"])
        
        # åˆå¹¶æ‰€æœ‰æ–‡æœ¬
        return ' '.join(text_parts)
    
    def _transform_to_generation(self, content: Dict[str, Any], source_gen: str, target_gen: str) -> Dict[str, Any]:
        """
        å°†å†…å®¹è½¬æ¢ä¸ºç›®æ ‡ä¸–ä»£é£æ ¼
        
        Args:
            content: å†…å®¹æ•°æ®
            source_gen: æºä¸–ä»£
            target_gen: ç›®æ ‡ä¸–ä»£
            
        Returns:
            è½¬æ¢åçš„å†…å®¹
        """
        result = copy.deepcopy(content)
        
        # è·å–ä¸–ä»£é—´æ˜ å°„
        generation_map = self.generation_maps.get((source_gen, target_gen), {})
        
        # å¤„ç†æ ‡é¢˜å’Œæè¿°
        if "title" in result and isinstance(result["title"], str):
            result["title"] = self._transform_text(result["title"], generation_map, source_gen, target_gen)
        
        if "description" in result and isinstance(result["description"], str):
            result["description"] = self._transform_text(result["description"], generation_map, source_gen, target_gen)
        
        # å¤„ç†å¯¹è¯
        if "dialogues" in result and isinstance(result["dialogues"], list):
            for dialogue in result["dialogues"]:
                if isinstance(dialogue, dict) and "text" in dialogue:
                    dialogue["text"] = self._transform_text(dialogue["text"], generation_map, source_gen, target_gen)
        
        # å¤„ç†åœºæ™¯
        if "scenes" in result and isinstance(result["scenes"], list):
            for scene in result["scenes"]:
                if isinstance(scene, dict):
                    # å¤„ç†åœºæ™¯æè¿°
                    if "description" in scene:
                        scene["description"] = self._transform_text(scene["description"], generation_map, source_gen, target_gen)
                    
                    # å¤„ç†åœºæ™¯å…ƒç´ 
                    if "elements" in scene and isinstance(scene["elements"], list):
                        for element in scene["elements"]:
                            if isinstance(element, dict) and "content" in element:
                                element["content"] = self._transform_text(element["content"], generation_map, source_gen, target_gen)
        
        # æ·»åŠ ä»£é™…è½¬æ¢æ ‡è®°
        result["generation_adaptation"] = {
            "source_generation": source_gen,
            "target_generation": target_gen,
            "adaptation_level": self.config["adaptation_level"]
        }
        
        return result
    
    def _transform_text(self, text: str, generation_map: Dict[str, str], source_gen: str, target_gen: str) -> str:
        """
        è½¬æ¢å•ä¸ªæ–‡æœ¬
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            generation_map: ä¸–ä»£æ˜ å°„å­—å…¸
            source_gen: æºä¸–ä»£
            target_gen: ç›®æ ‡ä¸–ä»£
            
        Returns:
            è½¬æ¢åçš„æ–‡æœ¬
        """
        if not text:
            return text
        
        result = text
        
        # 1. åº”ç”¨ç›´æ¥è¯æ±‡æ˜ å°„
        for source_term, target_term in generation_map.items():
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ç¡®ä¿åŒ¹é…å®Œæ•´è¯æ±‡
            pattern = r'\b' + re.escape(source_term) + r'\b'
            result = re.sub(pattern, target_term, result)
        
        # 2. æ·»åŠ è§£é‡Šï¼ˆå¦‚æœé…ç½®å¯ç”¨ï¼‰
        if self.config["add_explanations"]:
            # è¯†åˆ«æºä¸–ä»£ç‰¹æœ‰çš„è¯æ±‡å’Œè¡¨è¾¾
            source_unique_terms = set(self.REFERENCE_POINTS[source_gen]) - set(self.REFERENCE_POINTS[target_gen])
            
            for term in source_unique_terms:
                if term in result and term in generation_map:
                    explanation = generation_map[term]
                    
                    # æ ¹æ®é…ç½®é€‰æ‹©è§£é‡Šæ ·å¼
                    if self.config["explanation_style"] == "parentheses":
                        pattern = r'\b' + re.escape(term) + r'\b'
                        replacement = f"{term}ï¼ˆ{explanation}ï¼‰"
                        result = re.sub(pattern, replacement, result, count=1)  # åªæ›¿æ¢ç¬¬ä¸€æ¬¡å‡ºç°
                
        # 3. è°ƒæ•´è¡¨è¾¾é£æ ¼
        # ä¸ºä¸åŒä¸–ä»£åº”ç”¨ä¸åŒçš„è¡¨è¾¾é£æ ¼è½¬æ¢
        if target_gen == "Zä¸–ä»£":
            result = self._apply_z_generation_style(result)
        elif target_gen == "80å":
            result = self._apply_80s_style(result)
        elif target_gen == "90å":
            result = self._apply_90s_style(result)
        
        return result
    
    def _apply_z_generation_style(self, text: str) -> str:
        """
        åº”ç”¨Zä¸–ä»£è¡¨è¾¾é£æ ¼
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            è½¬æ¢åçš„æ–‡æœ¬
        """
        # Zä¸–ä»£é£æ ¼ç‰¹ç‚¹ï¼šç®€çŸ­ã€ç›´æ¥ã€ä½¿ç”¨æµè¡Œè¯
        result = text
        
        # 1. å¢åŠ ä¸€äº›Zä¸–ä»£å¸¸ç”¨è¯­æ°”è¯ï¼ˆå¦‚æœåŸæ–‡è¾ƒé•¿ï¼‰
        if len(text) > 50 and not any(term in text for term in ["ç»ç»å­", "yyds", "ç¬‘æ­»", "ç ´é˜²"]):
            z_expressions = ["ç»ç»å­", "yyds", "ç¬‘æ­»", "ç ´é˜²", "çœŸé¦™", "å¤ªå¯äº†", "æ— è¯­å­"]
            import random
            
            # åœ¨å¥æœ«éšæœºæ·»åŠ Zä¸–ä»£è¡¨è¾¾
            sentences = re.split(r'([.!?ã€‚ï¼ï¼Ÿ])', result)
            if len(sentences) >= 3:  # è‡³å°‘æœ‰ä¸€ä¸ªå®Œæ•´å¥å­
                insert_idx = random.randrange(0, len(sentences) - 2, 2)  # åªåœ¨å¥å­å†…å®¹ä½ç½®æ’å…¥
                z_expr = random.choice(z_expressions)
                
                if sentences[insert_idx].strip():
                    sentences[insert_idx] = sentences[insert_idx] + "ï¼Œ" + z_expr
                
                result = ''.join(sentences)
        
        # 2. ç¼©çŸ­å†—é•¿è¡¨è¾¾
        result = re.sub(r'éå¸¸éå¸¸', 'è¶…çº§', result)
        result = re.sub(r'æˆ‘è®¤ä¸ºè¿™ä¸ªæ˜¯', 'è¿™ä¸ªæ˜¯', result)
        
        # 3. å¢åŠ è¡¨æƒ…ç¬¦å·ï¼ˆå¦‚æœåŸæ–‡æ²¡æœ‰ï¼‰
        if "ï¼" in result and not any(emoji in result for emoji in ["ğŸ˜‚", "ğŸ¤£", "ğŸ‘", "ğŸ”¥"]):
            result = result.replace("ï¼", "ï¼ğŸ”¥", 1)
        
        return result
    
    def _apply_80s_style(self, text: str) -> str:
        """
        åº”ç”¨80åè¡¨è¾¾é£æ ¼
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            è½¬æ¢åçš„æ–‡æœ¬
        """
        # 80åé£æ ¼ç‰¹ç‚¹ï¼šç•¥æ˜¾æ€€æ—§ï¼Œå™äº‹æ€§å¼ºï¼Œæ­£å¼ä¸€äº›
        result = text
        
        # 1. å¢åŠ å™äº‹æ€§å’Œè¿‡æ¸¡è¯
        result = re.sub(r'^è¿™ä¸ª', 'å…¶å®è¿™ä¸ª', result)
        result = re.sub(r'^æˆ‘', 'è¯´å®è¯ï¼Œæˆ‘', result)
        
        # 2. é™ä½è¿‡åº¦å¤¸å¼ è¡¨è¾¾
        result = re.sub(r'ç»ç»å­', 'éå¸¸å¥½', result)
        result = re.sub(r'yyds', 'ç»å…¸', result)
        result = re.sub(r'å¤ªå¯äº†', 'å¾ˆæ£’', result)
        
        # 3. ç§»é™¤è¿‡å¤šè¡¨æƒ…ç¬¦å·
        for emoji in ["ğŸ˜‚", "ğŸ¤£", "ğŸ‘", "ğŸ”¥", "ğŸ’¯", "ğŸ¤¦â€â™€ï¸", "ğŸ¤·â€â™‚ï¸"]:
            if emoji in result:
                result = result.replace(emoji, "", result.count(emoji) - 1)  # ä¿ç•™ä¸€ä¸ª
        
        return result
    
    def _apply_90s_style(self, text: str) -> str:
        """
        åº”ç”¨90åè¡¨è¾¾é£æ ¼
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            è½¬æ¢åçš„æ–‡æœ¬
        """
        # 90åé£æ ¼ï¼šä»‹äº80åå’ŒZä¸–ä»£ä¹‹é—´ï¼Œä½¿ç”¨éƒ¨åˆ†ç½‘ç»œç”¨è¯­ä½†ä¿æŒä¸€å®šå™äº‹æ€§
        result = text
        
        # 1. è°ƒæ•´è¯­æ°”
        result = re.sub(r'^', 'å—¯ï¼Œ', result, count=1)
        result = re.sub(r'ç»ç»å­', 'å¾ˆèµ', result)
        result = re.sub(r'yyds', 'æ°¸è¿œçš„ç¥', result)
        
        # 2. é€‚åº¦æ·»åŠ è¡¨æƒ…ç¬¦å·
        if "ï¼" in result and not any(emoji in result for emoji in ["ğŸ˜Š", "ğŸ‘"]):
            result = result.replace("ï¼", "ï¼ğŸ‘", 1)
        
        return result


def insert_cultural_elements(content: Dict[str, Any], cultural_references: List[str]) -> Dict[str, Any]:
    """
    åœ¨å†…å®¹ä¸­æ’å…¥æ–‡åŒ–å…ƒç´ 
    
    å‘å†…å®¹ä¸­æ·»åŠ ç‰¹å®šä¸–ä»£çš„æ–‡åŒ–å‚è€ƒå’Œè¡¨è¾¾ï¼Œå¢å¼ºä¸–ä»£ç‰¹è‰²
    
    Args:
        content: åŸå§‹å†…å®¹
        cultural_references: æ–‡åŒ–å‚è€ƒåˆ—è¡¨
        
    Returns:
        æ·»åŠ æ–‡åŒ–å…ƒç´ åçš„å†…å®¹
    """
    result = copy.deepcopy(content)
    
    # æå–å…³é”®ä½ç½®ç”¨äºæ’å…¥æ–‡åŒ–å…ƒç´ 
    insertion_points = []
    
    # æ£€æŸ¥å¯¹è¯
    if "dialogues" in result and isinstance(result["dialogues"], list):
        for i, dialogue in enumerate(result["dialogues"]):
            if isinstance(dialogue, dict) and "text" in dialogue and len(dialogue["text"]) > 10:
                insertion_points.append(("dialogues", i))
    
    # æ£€æŸ¥åœºæ™¯
    if "scenes" in result and isinstance(result["scenes"], list):
        for i, scene in enumerate(result["scenes"]):
            if isinstance(scene, dict):
                # åœºæ™¯æè¿°
                if "description" in scene and len(scene["description"]) > 10:
                    insertion_points.append(("scenes_desc", i))
                
                # åœºæ™¯å…ƒç´ 
                if "elements" in scene and isinstance(scene["elements"], list):
                    for j, element in enumerate(scene["elements"]):
                        if isinstance(element, dict) and "content" in element and len(element["content"]) > 10:
                            insertion_points.append(("elements", (i, j)))
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„æ’å…¥ç‚¹ï¼Œè¿”å›åŸå†…å®¹
    if not insertion_points:
        return result
    
    # éšæœºé€‰æ‹©ä¸€äº›æ’å…¥ç‚¹
    import random
    num_insertions = min(len(cultural_references), len(insertion_points) // 2 + 1)
    selected_points = random.sample(insertion_points, num_insertions)
    
    # æ‰§è¡Œæ’å…¥
    for i, (point_type, indices) in enumerate(selected_points):
        if i < len(cultural_references):
            reference = cultural_references[i]
            
            if point_type == "dialogues":
                idx = indices
                dialogue = result["dialogues"][idx]
                dialogue["text"] = _insert_reference_into_text(dialogue["text"], reference)
            
            elif point_type == "scenes_desc":
                idx = indices
                scene = result["scenes"][idx]
                scene["description"] = _insert_reference_into_text(scene["description"], reference)
            
            elif point_type == "elements":
                scene_idx, elem_idx = indices
                element = result["scenes"][scene_idx]["elements"][elem_idx]
                element["content"] = _insert_reference_into_text(element["content"], reference)
    
    return result


def _insert_reference_into_text(text: str, reference: str) -> str:
    """
    åœ¨æ–‡æœ¬ä¸­æ’å…¥æ–‡åŒ–å‚è€ƒ
    
    Args:
        text: åŸå§‹æ–‡æœ¬
        reference: è¦æ’å…¥çš„æ–‡åŒ–å‚è€ƒ
        
    Returns:
        æ’å…¥åçš„æ–‡æœ¬
    """
    # å¦‚æœæ–‡æœ¬å·²åŒ…å«è¯¥å‚è€ƒï¼Œåˆ™ä¸å†æ’å…¥
    if reference in text:
        return text
    
    # å°†æ–‡æœ¬åˆ†å‰²æˆå¥å­
    sentences = re.split(r'([.!?ã€‚ï¼ï¼Ÿ])', text)
    
    # å¦‚æœæ–‡æœ¬å¾ˆçŸ­ï¼Œç›´æ¥é™„åŠ 
    if len(sentences) <= 2:
        return f"{text} {reference}"
    
    # åˆ›å»ºæ’å…¥æ¨¡æ¿
    templates = [
        f"å°±åƒ{reference}ä¸€æ ·ï¼Œ",
        f"è¿™è®©æˆ‘æƒ³èµ·äº†{reference}ï¼Œ",
        f"æœ‰ç‚¹{reference}çš„æ„Ÿè§‰ï¼Œ",
        f"è·Ÿ{reference}å¾ˆåƒï¼Œ"
    ]
    
    import random
    template = random.choice(templates)
    
    # æ‰¾åˆ°åˆé€‚çš„ä½ç½®æ’å…¥ï¼ˆå¥å­å¼€å¤´ï¼‰
    for i in range(2, len(sentences), 2):
        if sentences[i].strip():
            sentences[i] = template + sentences[i]
            break
    else:
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆé€‚ä½ç½®ï¼Œé™„åŠ åˆ°æœ€å
        sentences[-1] = sentences[-1] + f" {reference}"
    
    return ''.join(sentences)


# åˆ›å»ºå•ä¾‹å¯¹è±¡
_generation_bridge = None

def get_generation_bridge() -> GenerationBridge:
    """
    è·å–ä»£é™…å·®å¼‚æ¡¥æ¥å™¨å®ä¾‹
    
    Returns:
        GenerationBridge: ä»£é™…å·®å¼‚æ¡¥æ¥å™¨å®ä¾‹
    """
    global _generation_bridge
    if _generation_bridge is None:
        _generation_bridge = GenerationBridge()
    return _generation_bridge


def bridge_gap(content: Dict[str, Any], target_gen: str) -> Dict[str, Any]:
    """
    å¼¥åˆä¸åŒä¸–ä»£ä¹‹é—´çš„ä»£é™…å·®å¼‚çš„ä¾¿æ·å‡½æ•°
    
    Args:
        content: éœ€è¦è½¬æ¢çš„å†…å®¹
        target_gen: ç›®æ ‡ä¸–ä»£ï¼Œä¾‹å¦‚ "Zä¸–ä»£", "80å" ç­‰
        
    Returns:
        è½¬æ¢åçš„å†…å®¹
    """
    bridge = get_generation_bridge()
    return bridge.bridge_gap(content, target_gen)


def detect_content_generation(content: Dict[str, Any]) -> str:
    """
    æ£€æµ‹å†…å®¹çš„ä¸–ä»£é£æ ¼
    
    Args:
        content: å†…å®¹æ•°æ®
        
    Returns:
        æ£€æµ‹åˆ°çš„ä¸–ä»£æ ‡è¯†
    """
    bridge = get_generation_bridge()
    return bridge._detect_generation(content) 