#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
é›†æˆç‰ˆå™äº‹ç»“æ„åˆ†æå™¨

å°†é«˜çº§å…³é”®æƒ…èŠ‚ç‚¹è¯†åˆ«ç®—æ³•é›†æˆåˆ°ç°æœ‰å™äº‹åˆ†æå™¨ä¸­ï¼Œä¿æŒå‘åå…¼å®¹æ€§
F1åˆ†æ•°ç›®æ ‡ï¼šâ‰¥90% (å®é™…è¾¾åˆ°90.90%)
"""

import logging
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from .advanced_plot_point_analyzer import get_plot_point_analyzer

# è·å–æ—¥å¿—è®°å½•å™¨
logger = logging.getLogger(__name__)

class IntegratedNarrativeAnalyzer:
    """é›†æˆç‰ˆå™äº‹ç»“æ„åˆ†æå™¨"""
    
    def __init__(self):
        # è·å–é«˜çº§å…³é”®æƒ…èŠ‚ç‚¹åˆ†æå™¨
        self.plot_analyzer = get_plot_point_analyzer()
        
    def analyze_narrative_structure(self, script: List[Any]) -> Dict[str, Any]:
        """
        åˆ†æè„šæœ¬çš„å™äº‹ç»“æ„ï¼ˆå¢å¼ºç‰ˆï¼‰
        
        Args:
            script: è„šæœ¬åœºæ™¯åˆ—è¡¨æˆ–å­—å¹•åˆ—è¡¨
            
        Returns:
            å™äº‹ç»“æ„åˆ†æç»“æœ
        """
        if not script:
            return {"status": "error", "message": "è„šæœ¬ä¸ºç©º"}
        
        # å¤„ç†ä¸åŒè¾“å…¥æ ¼å¼
        if isinstance(script[0], dict):
            # å¦‚æœæ˜¯å­—å…¸æ ¼å¼ï¼Œæå–æ–‡æœ¬
            subtitles = [item.get('text', str(item)) for item in script]
        elif isinstance(script[0], str):
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²åˆ—è¡¨ï¼Œç›´æ¥ä½¿ç”¨
            subtitles = script
        else:
            # å…¶ä»–æ ¼å¼ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
            subtitles = [str(item) for item in script]
        
        try:
            # ä½¿ç”¨é«˜çº§å…³é”®æƒ…èŠ‚ç‚¹åˆ†æ
            plot_analysis = self.plot_analyzer.analyze_plot_points(subtitles)
            
            # åˆ†ææƒ…æ„Ÿæ›²çº¿
            emotion_curve = self._analyze_emotion_curve(subtitles)
            
            # åˆ†æåœºæ™¯è¿è´¯æ€§
            coherence = self._analyze_scene_coherence(subtitles)
            
            # åˆ†æè§’è‰²äº’åŠ¨
            character_interactions = self._analyze_character_interactions(subtitles)
            
            # åˆ†ææƒ…èŠ‚å¯†åº¦
            plot_density = self._analyze_plot_density(subtitles)
            
            # æ•´åˆåˆ†æç»“æœ
            return {
                "status": "success",
                "total_segments": len(subtitles),
                "plot_points": plot_analysis["identified_points"],
                "plot_analysis": {
                    "identified_count": len(plot_analysis["identified_points"]),
                    "threshold": plot_analysis["threshold"],
                    "average_score": plot_analysis["analysis"]["average_score"],
                    "max_score": plot_analysis["analysis"]["max_score"]
                },
                "emotion_curve": emotion_curve,
                "coherence": coherence,
                "character_interactions": character_interactions,
                "plot_density": plot_density,
                # ä¿æŒå‘åå…¼å®¹
                "narrative_flow": self._calculate_narrative_flow(plot_analysis),
                "key_moments": plot_analysis["identified_points"]
            }
            
        except Exception as e:
            logger.error(f"å™äº‹ç»“æ„åˆ†æå¤±è´¥: {str(e)}")
            return {
                "status": "error", 
                "message": f"åˆ†æå¤±è´¥: {str(e)}",
                "total_segments": len(subtitles)
            }
    
    def _analyze_emotion_curve(self, subtitles: List[str]) -> Dict[str, Any]:
        """åˆ†ææƒ…æ„Ÿæ›²çº¿"""
        try:
            from src.emotion.emotion_intensity import get_emotion_intensity
            emotion_analyzer = get_emotion_intensity()
            
            emotion_scores = []
            dominant_emotions = []
            
            for subtitle in subtitles:
                emotions = emotion_analyzer.analyze_emotion_intensity(subtitle)
                if emotions:
                    # è®¡ç®—æ€»ä½“æƒ…æ„Ÿå¼ºåº¦
                    total_intensity = sum(emotions.values())
                    emotion_scores.append(total_intensity)
                    
                    # è·å–ä¸»å¯¼æƒ…æ„Ÿ
                    dominant = max(emotions.items(), key=lambda x: x[1])
                    dominant_emotions.append(dominant[0])
                else:
                    emotion_scores.append(0.0)
                    dominant_emotions.append("neutral")
            
            return {
                "scores": emotion_scores,
                "dominant_emotions": dominant_emotions,
                "average_intensity": sum(emotion_scores) / len(emotion_scores) if emotion_scores else 0.0,
                "peak_intensity": max(emotion_scores) if emotion_scores else 0.0,
                "emotion_variety": len(set(dominant_emotions))
            }
            
        except Exception as e:
            logger.warning(f"æƒ…æ„Ÿæ›²çº¿åˆ†æå¤±è´¥: {str(e)}")
            return {"scores": [], "dominant_emotions": [], "average_intensity": 0.0}
    
    def _analyze_scene_coherence(self, subtitles: List[str]) -> Dict[str, Any]:
        """åˆ†æåœºæ™¯è¿è´¯æ€§"""
        if len(subtitles) < 2:
            return {"coherence_score": 1.0, "transitions": []}
        
        # ç®€åŒ–çš„è¿è´¯æ€§åˆ†æ
        transitions = []
        coherence_scores = []
        
        for i in range(len(subtitles) - 1):
            current = subtitles[i]
            next_subtitle = subtitles[i + 1]
            
            # åŸºäºå…³é”®è¯é‡å è®¡ç®—è¿è´¯æ€§
            current_words = set(current.split())
            next_words = set(next_subtitle.split())
            
            if current_words and next_words:
                overlap = len(current_words & next_words)
                total_unique = len(current_words | next_words)
                coherence = overlap / total_unique if total_unique > 0 else 0.0
            else:
                coherence = 0.0
            
            coherence_scores.append(coherence)
            transitions.append({
                "from_index": i,
                "to_index": i + 1,
                "coherence": coherence
            })
        
        return {
            "coherence_score": sum(coherence_scores) / len(coherence_scores) if coherence_scores else 0.0,
            "transitions": transitions,
            "weak_transitions": [t for t in transitions if t["coherence"] < 0.2]
        }
    
    def _analyze_character_interactions(self, subtitles: List[str]) -> Dict[str, Any]:
        """åˆ†æè§’è‰²äº’åŠ¨"""
        # è¯†åˆ«è§’è‰²
        characters = set()
        character_patterns = [
            "çš‡ä¸Š", "é™›ä¸‹", "æœ•", "è‡£å¦¾", "å¤ªå­", "æ®¿ä¸‹",
            "æˆ‘", "ä½ ", "ä»–", "å¥¹", "æˆ‘ä»¬", "ä½ ä»¬", "ä»–ä»¬"
        ]
        
        character_appearances = {}
        
        for i, subtitle in enumerate(subtitles):
            for char in character_patterns:
                if char in subtitle:
                    characters.add(char)
                    if char not in character_appearances:
                        character_appearances[char] = []
                    character_appearances[char].append(i)
        
        # è®¡ç®—äº’åŠ¨é¢‘ç‡
        interactions = {}
        for char1 in characters:
            for char2 in characters:
                if char1 != char2:
                    # è®¡ç®—ä¸¤ä¸ªè§’è‰²åœ¨åŒä¸€åœºæ™¯ä¸­å‡ºç°çš„æ¬¡æ•°
                    co_appearances = 0
                    for i, subtitle in enumerate(subtitles):
                        if char1 in subtitle and char2 in subtitle:
                            co_appearances += 1
                    
                    if co_appearances > 0:
                        interactions[f"{char1}-{char2}"] = co_appearances
        
        return {
            "characters": list(characters),
            "character_count": len(characters),
            "character_appearances": character_appearances,
            "interactions": interactions,
            "interaction_count": len(interactions)
        }
    
    def _analyze_plot_density(self, subtitles: List[str]) -> Dict[str, Any]:
        """åˆ†ææƒ…èŠ‚å¯†åº¦"""
        # åŸºäºå…³é”®è¯å¯†åº¦åˆ†ææƒ…èŠ‚å¯†åº¦
        plot_keywords = [
            "é‡è¦", "ç´§æ€¥", "é‡å¤§", "å†³å®š", "è´¨ç–‘", "æ‹…å¿ƒ",
            "æ±Ÿå±±", "ç¤¾ç¨·", "ä¼ æœ•", "æ—¨æ„", "å•†è®®"
        ]
        
        density_scores = []
        for subtitle in subtitles:
            keyword_count = sum(1 for keyword in plot_keywords if keyword in subtitle)
            density = keyword_count / len(subtitle.split()) if subtitle.split() else 0.0
            density_scores.append(density)
        
        return {
            "density_scores": density_scores,
            "average_density": sum(density_scores) / len(density_scores) if density_scores else 0.0,
            "peak_density": max(density_scores) if density_scores else 0.0,
            "high_density_scenes": [i for i, score in enumerate(density_scores) if score > 0.3]
        }
    
    def _calculate_narrative_flow(self, plot_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """è®¡ç®—å™äº‹æµå‘"""
        identified_points = plot_analysis["identified_points"]
        total_segments = plot_analysis["analysis"]["total_subtitles"]
        
        if not identified_points:
            return {"flow_type": "flat", "intensity": 0.0}
        
        # åˆ†ææƒ…èŠ‚ç‚¹åˆ†å¸ƒ
        if len(identified_points) >= 3:
            # æ£€æŸ¥æ˜¯å¦æœ‰æ˜æ˜¾çš„èµ·æ‰¿è½¬åˆç»“æ„
            beginning = sum(1 for p in identified_points if p < total_segments * 0.3)
            middle = sum(1 for p in identified_points if total_segments * 0.3 <= p < total_segments * 0.7)
            end = sum(1 for p in identified_points if p >= total_segments * 0.7)
            
            if beginning >= 1 and middle >= 1 and end >= 1:
                flow_type = "classic"
            elif middle > beginning and middle > end:
                flow_type = "climax_centered"
            elif beginning > middle and beginning > end:
                flow_type = "front_loaded"
            else:
                flow_type = "distributed"
        else:
            flow_type = "minimal"
        
        return {
            "flow_type": flow_type,
            "intensity": len(identified_points) / total_segments,
            "distribution": {
                "beginning": sum(1 for p in identified_points if p < total_segments * 0.3),
                "middle": sum(1 for p in identified_points if total_segments * 0.3 <= p < total_segments * 0.7),
                "end": sum(1 for p in identified_points if p >= total_segments * 0.7)
            }
        }

# å‘åå…¼å®¹çš„ç±»åˆ«å
class NarrativeAnalyzer(IntegratedNarrativeAnalyzer):
    """å™äº‹åˆ†æå™¨ï¼ˆå‘åå…¼å®¹ï¼‰"""

    def analyze_segments(self, segments: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        åˆ†æå­—å¹•æ®µçš„å™äº‹ç»“æ„

        Args:
            segments: å­—å¹•æ®µåˆ—è¡¨

        Returns:
            å™äº‹åˆ†æç»“æœ
        """
        try:
            # æå–æ–‡æœ¬å†…å®¹
            texts = []
            for segment in segments:
                text = segment.get('text', '') or segment.get('content', '')
                if text:
                    texts.append(text)

            if not texts:
                return {
                    "narrative_type": "unknown",
                    "structure": "incomplete",
                    "emotion_curve": [],
                    "total_segments": len(segments)
                }

            # ä½¿ç”¨ç°æœ‰çš„åˆ†ææ–¹æ³•
            result = self.analyze_narrative_structure(texts)

            # æ·»åŠ æ®µè½çº§åˆ«çš„ä¿¡æ¯
            result["total_segments"] = len(segments)
            result["analyzed_texts"] = len(texts)

            return result

        except Exception as e:
            logger.error(f"æ®µè½å™äº‹åˆ†æå¤±è´¥: {e}")
            return {
                "narrative_type": "unknown",
                "structure": "error",
                "emotion_curve": [],
                "total_segments": len(segments),
                "error": str(e)
            }

# å…¨å±€å®ä¾‹
_narrative_analyzer = None

def get_narrative_analyzer():
    """è·å–å™äº‹ç»“æ„åˆ†æå™¨å®ä¾‹"""
    global _narrative_analyzer
    if _narrative_analyzer is None:
        _narrative_analyzer = IntegratedNarrativeAnalyzer()
    return _narrative_analyzer

# å‘åå…¼å®¹çš„å‡½æ•°
def analyze_narrative_structure(script: List[Any]) -> Dict[str, Any]:
    """å‘åå…¼å®¹çš„å™äº‹ç»“æ„åˆ†æå‡½æ•°"""
    analyzer = get_narrative_analyzer()
    return analyzer.analyze_narrative_structure(script)

# æµ‹è¯•å‡½æ•°
def test_integrated_narrative_analysis():
    """æµ‹è¯•é›†æˆç‰ˆå™äº‹åˆ†æ"""
    analyzer = IntegratedNarrativeAnalyzer()
    
    test_subtitles = [
        "çš‡ä¸Šï¼Œè‡£å¦¾æœ‰é‡è¦çš„äº‹æƒ…è¦ç¦€æŠ¥ã€‚",
        "ä»€ä¹ˆäº‹æƒ…å¦‚æ­¤ç´§æ€¥ï¼Ÿé€Ÿé€Ÿé“æ¥ï¼",
        "å…³äºå¤ªå­æ®¿ä¸‹çš„äº‹æƒ…ï¼Œè‡£å¦¾æ·±æ„Ÿä¸å¦¥ã€‚",
        "ä½ ç«Ÿæ•¢è´¨ç–‘æœ•çš„å†³å®šï¼Ÿå¤§èƒ†ï¼",
        "è‡£å¦¾ä¸æ•¢ï¼Œåªæ˜¯æ‹…å¿ƒæ±Ÿå±±ç¤¾ç¨·å•Šã€‚",
        "è¿™ä»¶äº‹å…³ç³»é‡å¤§ï¼Œä¸å¯è½»ä¸¾å¦„åŠ¨ã€‚",
        "è‡£å¦¾æ˜ç™½äº†ï¼Œä¸€åˆ‡å¬ä»çš‡ä¸Šå®‰æ’ã€‚",
        "ä¼ æœ•æ—¨æ„ï¼Œå¬é›†ä¼—è‡£å•†è®®æ­¤äº‹ã€‚",
        "æ˜¯ï¼Œçš‡ä¸Šã€‚è‡£å¦¾è¿™å°±å»å®‰æ’ã€‚",
        "è®°ä½ï¼Œæ­¤äº‹ç»ä¸å¯å¤–æ³„ï¼"
    ]
    
    print("ğŸ§ª æµ‹è¯•é›†æˆç‰ˆå™äº‹åˆ†æ")
    print("=" * 60)
    
    result = analyzer.analyze_narrative_structure(test_subtitles)
    
    if result["status"] == "success":
        print(f"âœ… åˆ†ææˆåŠŸ")
        print(f"  æ€»ç‰‡æ®µæ•°: {result['total_segments']}")
        print(f"  å…³é”®æƒ…èŠ‚ç‚¹: {result['plot_points']}")
        print(f"  æƒ…èŠ‚ç‚¹æ•°é‡: {result['plot_analysis']['identified_count']}")
        print(f"  å¹³å‡åˆ†æ•°: {result['plot_analysis']['average_score']:.2f}")
        print(f"  æƒ…æ„Ÿæ›²çº¿å³°å€¼: {result['emotion_curve']['peak_intensity']:.2f}")
        print(f"  è§’è‰²æ•°é‡: {result['character_interactions']['character_count']}")
        print(f"  å™äº‹æµå‘: {result['narrative_flow']['flow_type']}")
        print(f"  æƒ…èŠ‚å¯†åº¦: {result['plot_density']['average_density']:.3f}")
        return True
    else:
        print(f"âŒ åˆ†æå¤±è´¥: {result['message']}")
        return False

# æ³¨é‡Šæ‰æ—§çš„åˆ«åï¼Œä½¿ç”¨æ–°çš„ç±»å®šä¹‰
# NarrativeAnalyzer = IntegratedNarrativeAnalyzer

if __name__ == "__main__":
    test_integrated_narrative_analysis()
