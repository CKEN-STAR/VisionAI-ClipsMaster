#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å·¥ä½œæµç¨‹ç®¡ç†å™¨
å®ç°å®Œæ•´çš„"åŸç‰‡+å­—å¹• â†’ å‰§æœ¬é‡æ„ â†’ æ··å‰ªè§†é¢‘"å·¥ä½œæµç¨‹
"""

import os
import json
import time
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime

from .language_detector import LanguageDetector
from .srt_parser import SRTParser
from .narrative_analyzer import IntegratedNarrativeAnalyzer
from .screenplay_engineer import ScreenplayEngineer
from .rhythm_analyzer import RhythmAnalyzer
from .segment_advisor import SegmentAdvisor
from .clip_generator import ClipGenerator
from .input_validator import InputValidator
from ..exporters.jianying_pro_exporter import JianYingProExporter
from ..utils.exceptions import WorkflowError, ValidationError
from ..utils.log_handler import get_logger

logger = get_logger(__name__)

class WorkflowManager:
    """å·¥ä½œæµç¨‹ç®¡ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–å·¥ä½œæµç¨‹ç®¡ç†å™¨"""
        self.language_detector = LanguageDetector()
        self.srt_parser = SRTParser()
        self.narrative_analyzer = IntegratedNarrativeAnalyzer()
        self.screenplay_engineer = ScreenplayEngineer()
        self.rhythm_analyzer = RhythmAnalyzer()
        self.segment_advisor = SegmentAdvisor()
        self.clip_generator = ClipGenerator()
        self.input_validator = InputValidator()
        self.jianying_exporter = JianYingProExporter()
        
        self.workflow_state = {
            "current_step": 0,
            "total_steps": 7,
            "status": "ready",
            "start_time": None,
            "end_time": None,
            "results": {}
        }
        
        logger.info("ğŸ¬ å·¥ä½œæµç¨‹ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def execute_full_workflow(self, video_path: str, subtitle_path: str, 
                            output_dir: str = "output", 
                            target_length: Optional[Tuple[int, int]] = None) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´å·¥ä½œæµç¨‹
        
        Args:
            video_path: åŸç‰‡è§†é¢‘è·¯å¾„
            subtitle_path: å­—å¹•æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            target_length: ç›®æ ‡é•¿åº¦èŒƒå›´(æœ€å°ç§’æ•°, æœ€å¤§ç§’æ•°)
            
        Returns:
            Dict: å·¥ä½œæµç¨‹ç»“æœ
        """
        try:
            self.workflow_state["status"] = "running"
            self.workflow_state["start_time"] = datetime.now()
            
            logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œå®Œæ•´å·¥ä½œæµç¨‹")
            logger.info(f"ğŸ“¹ åŸç‰‡: {video_path}")
            logger.info(f"ğŸ“ å­—å¹•: {subtitle_path}")
            
            # æ­¥éª¤1: è¾“å…¥éªŒè¯
            self._update_step(1, "è¾“å…¥éªŒè¯")
            validation_result = self._validate_inputs(video_path, subtitle_path)
            
            # æ­¥éª¤2: è¯­è¨€æ£€æµ‹
            self._update_step(2, "è¯­è¨€æ£€æµ‹")
            language_result = self._detect_language(subtitle_path)
            
            # æ­¥éª¤3: å­—å¹•è§£æ
            self._update_step(3, "å­—å¹•è§£æ")
            parsing_result = self._parse_subtitles(subtitle_path)
            
            # æ­¥éª¤4: å‰§æƒ…åˆ†æ
            self._update_step(4, "å‰§æƒ…åˆ†æ")
            analysis_result = self._analyze_narrative(parsing_result["subtitles"])
            
            # æ­¥éª¤5: å‰§æœ¬é‡æ„
            self._update_step(5, "å‰§æœ¬é‡æ„")
            reconstruction_result = self._reconstruct_screenplay(
                parsing_result["subtitles"], 
                analysis_result,
                language_result["language"],
                target_length
            )
            
            # æ­¥éª¤6: è§†é¢‘ç”Ÿæˆ
            self._update_step(6, "è§†é¢‘ç”Ÿæˆ")
            generation_result = self._generate_clips(
                video_path, 
                reconstruction_result["new_subtitles"],
                output_dir
            )
            
            # æ­¥éª¤7: å¯¼å‡ºå·¥ç¨‹
            self._update_step(7, "å¯¼å‡ºå·¥ç¨‹")
            export_result = self._export_project(
                generation_result["output_video"],
                reconstruction_result["new_subtitles"],
                output_dir
            )
            
            # æ±‡æ€»ç»“æœ
            final_result = {
                "status": "success",
                "workflow_id": f"workflow_{int(time.time())}",
                "input": {
                    "video_path": video_path,
                    "subtitle_path": subtitle_path,
                    "detected_language": language_result["language"]
                },
                "output": {
                    "mixed_video": generation_result["output_video"],
                    "new_subtitles": reconstruction_result["new_subtitles"],
                    "jianying_project": export_result["project_file"],
                    "output_directory": output_dir
                },
                "statistics": {
                    "original_duration": parsing_result["total_duration"],
                    "final_duration": generation_result["final_duration"],
                    "compression_ratio": generation_result["final_duration"] / parsing_result["total_duration"],
                    "subtitle_count": len(reconstruction_result["new_subtitles"]),
                    "processing_time": (datetime.now() - self.workflow_state["start_time"]).total_seconds()
                },
                "quality_metrics": {
                    "narrative_coherence": analysis_result.get("coherence_score", 0.8),
                    "emotional_impact": analysis_result.get("emotional_score", 0.7),
                    "length_control": self._check_length_control(
                        generation_result["final_duration"], 
                        parsing_result["total_duration"],
                        target_length
                    )
                }
            }
            
            self.workflow_state["status"] = "completed"
            self.workflow_state["end_time"] = datetime.now()
            self.workflow_state["results"] = final_result
            
            logger.info(f"âœ… å·¥ä½œæµç¨‹æ‰§è¡Œå®Œæˆ")
            logger.info(f"â±ï¸ æ€»è€—æ—¶: {final_result['statistics']['processing_time']:.2f}ç§’")
            logger.info(f"ğŸ¯ å‹ç¼©æ¯”: {final_result['statistics']['compression_ratio']:.2f}")
            
            return final_result
            
        except Exception as e:
            self.workflow_state["status"] = "failed"
            self.workflow_state["end_time"] = datetime.now()
            logger.error(f"âŒ å·¥ä½œæµç¨‹æ‰§è¡Œå¤±è´¥: {e}")
            raise WorkflowError(f"å·¥ä½œæµç¨‹æ‰§è¡Œå¤±è´¥: {e}")
    
    def _update_step(self, step: int, description: str):
        """æ›´æ–°å½“å‰æ­¥éª¤"""
        self.workflow_state["current_step"] = step
        logger.info(f"ğŸ“‹ æ­¥éª¤ {step}/{self.workflow_state['total_steps']}: {description}")
    
    def _validate_inputs(self, video_path: str, subtitle_path: str) -> Dict[str, Any]:
        """éªŒè¯è¾“å…¥æ–‡ä»¶"""
        video_valid = self.input_validator.validate_video_file(video_path)
        subtitle_valid = self.input_validator.validate_srt_file(subtitle_path)
        
        if not video_valid:
            raise ValidationError(f"è§†é¢‘æ–‡ä»¶éªŒè¯å¤±è´¥: {video_path}")
        if not subtitle_valid:
            raise ValidationError(f"å­—å¹•æ–‡ä»¶éªŒè¯å¤±è´¥: {subtitle_path}")
        
        return {"video_valid": video_valid, "subtitle_valid": subtitle_valid}
    
    def _detect_language(self, subtitle_path: str) -> Dict[str, Any]:
        """æ£€æµ‹è¯­è¨€"""
        language = self.language_detector.detect_from_file(subtitle_path)
        logger.info(f"ğŸŒ æ£€æµ‹åˆ°è¯­è¨€: {language}")
        return {"language": language}
    
    def _parse_subtitles(self, subtitle_path: str) -> Dict[str, Any]:
        """è§£æå­—å¹•"""
        subtitles = self.srt_parser.parse(subtitle_path)
        total_duration = self.srt_parser.get_total_duration(subtitles)
        logger.info(f"ğŸ“ è§£æå­—å¹•: {len(subtitles)}æ¡ï¼Œæ€»æ—¶é•¿: {total_duration:.2f}ç§’")
        return {"subtitles": subtitles, "total_duration": total_duration}
    
    def _analyze_narrative(self, subtitles: List[Dict]) -> Dict[str, Any]:
        """åˆ†æå‰§æƒ…"""
        analysis = self.narrative_analyzer.analyze_narrative_structure(subtitles)
        logger.info(f"ğŸ­ å‰§æƒ…åˆ†æå®Œæˆï¼Œè¿è´¯æ€§è¯„åˆ†: {analysis.get('coherence_score', 0.8):.2f}")
        return analysis
    
    def _reconstruct_screenplay(self, subtitles: List[Dict], analysis: Dict, 
                              language: str, target_length: Optional[Tuple[int, int]]) -> Dict[str, Any]:
        """é‡æ„å‰§æœ¬"""
        # ä½¿ç”¨å‰§æœ¬å·¥ç¨‹å¸ˆé‡æ„
        new_subtitles = self.screenplay_engineer.reconstruct_screenplay(
            subtitles, analysis, language
        )
        
        # é•¿åº¦æ§åˆ¶
        if target_length:
            new_subtitles = self._apply_length_control(new_subtitles, target_length)
        
        logger.info(f"âœ‚ï¸ å‰§æœ¬é‡æ„å®Œæˆï¼Œç”Ÿæˆ {len(new_subtitles)} ä¸ªç‰‡æ®µ")
        return {"new_subtitles": new_subtitles}
    
    def _apply_length_control(self, subtitles: List[Dict], 
                            target_length: Tuple[int, int]) -> List[Dict]:
        """åº”ç”¨é•¿åº¦æ§åˆ¶"""
        min_length, max_length = target_length
        
        # ä½¿ç”¨èŠ‚å¥åˆ†æå™¨ä¼˜åŒ–é•¿åº¦
        optimized_subtitles = self.rhythm_analyzer.optimize_for_length(
            subtitles, min_length, max_length
        )
        
        # ä½¿ç”¨ç‰‡æ®µå»ºè®®å™¨è¿›ä¸€æ­¥ä¼˜åŒ–
        final_subtitles = self.segment_advisor.suggest_optimal_segments(
            optimized_subtitles, target_length
        )
        
        return final_subtitles
    
    def _generate_clips(self, video_path: str, subtitles: List[Dict], 
                       output_dir: str) -> Dict[str, Any]:
        """ç”Ÿæˆè§†é¢‘ç‰‡æ®µ"""
        output_video = self.clip_generator.generate_mixed_video(
            video_path, subtitles, output_dir
        )
        
        final_duration = self.clip_generator.get_video_duration(output_video)
        logger.info(f"ğŸ¬ è§†é¢‘ç”Ÿæˆå®Œæˆ: {output_video}ï¼Œæ—¶é•¿: {final_duration:.2f}ç§’")
        
        return {"output_video": output_video, "final_duration": final_duration}
    
    def _export_project(self, video_path: str, subtitles: List[Dict], 
                       output_dir: str) -> Dict[str, Any]:
        """å¯¼å‡ºå‰ªæ˜ å·¥ç¨‹"""
        project_file = self.jianying_exporter.export_project(
            video_path, subtitles, output_dir
        )
        
        logger.info(f"ğŸ“ å‰ªæ˜ å·¥ç¨‹å¯¼å‡ºå®Œæˆ: {project_file}")
        return {"project_file": project_file}
    
    def _check_length_control(self, final_duration: float, original_duration: float,
                            target_length: Optional[Tuple[int, int]]) -> Dict[str, Any]:
        """æ£€æŸ¥é•¿åº¦æ§åˆ¶æ•ˆæœ"""
        compression_ratio = final_duration / original_duration
        
        result = {
            "compression_ratio": compression_ratio,
            "is_too_short": compression_ratio < 0.1,  # å‹ç¼©æ¯”å°äº10%å¯èƒ½è¿‡çŸ­
            "is_too_long": compression_ratio > 0.8,   # å‹ç¼©æ¯”å¤§äº80%å¯èƒ½è¿‡é•¿
            "meets_target": True
        }
        
        if target_length:
            min_length, max_length = target_length
            result["meets_target"] = min_length <= final_duration <= max_length
        
        return result
    
    def get_workflow_status(self) -> Dict[str, Any]:
        """è·å–å·¥ä½œæµç¨‹çŠ¶æ€"""
        return self.workflow_state.copy()
    
    def reset_workflow(self):
        """é‡ç½®å·¥ä½œæµç¨‹çŠ¶æ€"""
        self.workflow_state = {
            "current_step": 0,
            "total_steps": 7,
            "status": "ready",
            "start_time": None,
            "end_time": None,
            "results": {}
        }
        logger.info("ğŸ”„ å·¥ä½œæµç¨‹çŠ¶æ€å·²é‡ç½®")
