#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®å¢å¼ºå™¨ - é€šç”¨æ•°æ®å¢å¼ºå·¥å…·
æ”¯æŒä¸­è‹±æ–‡æ–‡æœ¬å¢å¼ºï¼Œæé«˜è®­ç»ƒæ•°æ®å¤šæ ·æ€§å’Œæ¨¡å‹æ³›åŒ–èƒ½åŠ›
"""

import os
import sys
import json
import random
import re
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, PROJECT_ROOT)

class DataAugmenter:
    """æ•°æ®å¢å¼ºå™¨ - è·¨è¯­è¨€æ–‡æœ¬å¢å¼ºå·¥å…·"""

    def __init__(self, language: str = "zh"):
        """
        åˆå§‹åŒ–æ•°æ®å¢å¼ºå™¨

        Args:
            language: ç›®æ ‡è¯­è¨€ (zh/en)
        """
        self.language = language

        # ä¸­æ–‡å¢å¼ºè§„åˆ™
        self.zh_augmentation_rules = {
            "synonyms": {
                "éœ‡æ’¼": ["æƒŠè‰³", "éœ‡æƒŠ", "æƒŠäºº", "ä»¤äººéœ‡æ’¼"],
                "æƒŠå‘†": ["æƒŠè®¶", "éœ‡æƒŠ", "æƒŠæ„•", "ç›®çªå£å‘†"],
                "ä¸æ•¢ç›¸ä¿¡": ["éš¾ä»¥ç½®ä¿¡", "æ— æ³•ç›¸ä¿¡", "ç®€ç›´ä¸æ•¢ç›¸ä¿¡", "å¤ªä¸å¯æ€è®®"],
                "å²ä¸Šæœ€": ["å†å²æœ€", "å‰æ‰€æœªæœ‰", "ç©ºå‰ç»å", "å²æ— å‰ä¾‹"],
                "å¤ªç²¾å½©": ["éå¸¸ç²¾å½©", "æå…¶ç²¾å½©", "è¶…çº§ç²¾å½©", "æ— æ¯”ç²¾å½©"],
                "æ”¹å˜ä¸€åˆ‡": ["é¢ è¦†ä¸€åˆ‡", "æ”¹å˜å‘½è¿", "æ‰­è½¬ä¹¾å¤", "å½»åº•æ”¹å˜"]
            },
            "intensifiers": ["è¶…çº§", "æå…¶", "éå¸¸", "ç‰¹åˆ«", "ç›¸å½“", "ååˆ†"],
            "exclamations": ["ï¼", "ï¼ï¼", "ï¼ï¼ï¼"],
            "question_words": ["ä»€ä¹ˆ", "æ€ä¹ˆ", "ä¸ºä»€ä¹ˆ", "å“ªé‡Œ", "è°"]
        }

        # è‹±æ–‡å¢å¼ºè§„åˆ™
        self.en_augmentation_rules = {
            "synonyms": {
                "SHOCKING": ["AMAZING", "STUNNING", "INCREDIBLE", "MIND-BLOWING"],
                "AMAZING": ["INCREDIBLE", "FANTASTIC", "WONDERFUL", "SPECTACULAR"],
                "UNBELIEVABLE": ["INCREDIBLE", "ASTONISHING", "MIND-BLOWING", "SHOCKING"],
                "MIND-BLOWING": ["INCREDIBLE", "AMAZING", "STUNNING", "SPECTACULAR"],
                "INCREDIBLE": ["AMAZING", "FANTASTIC", "UNBELIEVABLE", "STUNNING"],
                "STUNNING": ["AMAZING", "INCREDIBLE", "SPECTACULAR", "BREATHTAKING"]
            },
            "intensifiers": ["SUPER", "ULTRA", "EXTREMELY", "INCREDIBLY", "ABSOLUTELY"],
            "exclamations": ["!", "!!", "!!!"],
            "question_words": ["WHAT", "HOW", "WHY", "WHERE", "WHO"]
        }

        print(f"ğŸ”„ æ•°æ®å¢å¼ºå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸŒ ç›®æ ‡è¯­è¨€: {language}")
        print(f"ğŸ“Š å¢å¼ºè§„åˆ™: {'ä¸­æ–‡' if language == 'zh' else 'è‹±æ–‡'}æ¨¡å¼")

    def augment_text_synonyms(self, text: str) -> List[str]:
        """
        åŒä¹‰è¯æ›¿æ¢å¢å¼º

        Args:
            text: åŸå§‹æ–‡æœ¬

        Returns:
            å¢å¼ºåçš„æ–‡æœ¬åˆ—è¡¨
        """
        augmented_texts = []
        rules = self.zh_augmentation_rules if self.language == "zh" else self.en_augmentation_rules

        # ä¸ºæ¯ä¸ªåŒä¹‰è¯ç»„ç”Ÿæˆæ›¿æ¢ç‰ˆæœ¬
        for original, synonyms in rules["synonyms"].items():
            if original in text:
                for synonym in synonyms:
                    augmented_text = text.replace(original, synonym)
                    if augmented_text != text:
                        augmented_texts.append(augmented_text)

        return augmented_texts

    def augment_text_intensifiers(self, text: str) -> List[str]:
        """
        å¼ºåŒ–è¯å¢å¼º

        Args:
            text: åŸå§‹æ–‡æœ¬

        Returns:
            å¢å¼ºåçš„æ–‡æœ¬åˆ—è¡¨
        """
        augmented_texts = []
        rules = self.zh_augmentation_rules if self.language == "zh" else self.en_augmentation_rules

        # åœ¨å…³é”®è¯å‰æ·»åŠ å¼ºåŒ–è¯
        for intensifier in rules["intensifiers"]:
            if self.language == "zh":
                # ä¸­æ–‡å¼ºåŒ–è¯æ’å…¥
                for keyword in ["éœ‡æ’¼", "æƒŠå‘†", "ç²¾å½©", "å‰å®³"]:
                    if keyword in text and intensifier not in text:
                        augmented_text = text.replace(keyword, f"{intensifier}{keyword}")
                        augmented_texts.append(augmented_text)
            else:
                # è‹±æ–‡å¼ºåŒ–è¯æ’å…¥
                for keyword in ["AMAZING", "INCREDIBLE", "STUNNING"]:
                    if keyword in text and intensifier not in text:
                        augmented_text = text.replace(keyword, f"{intensifier} {keyword}")
                        augmented_texts.append(augmented_text)

        return augmented_texts

    def augment_text_punctuation(self, text: str) -> List[str]:
        """
        æ ‡ç‚¹ç¬¦å·å¢å¼º

        Args:
            text: åŸå§‹æ–‡æœ¬

        Returns:
            å¢å¼ºåçš„æ–‡æœ¬åˆ—è¡¨
        """
        augmented_texts = []
        rules = self.zh_augmentation_rules if self.language == "zh" else self.en_augmentation_rules

        # æ·»åŠ ä¸åŒç¨‹åº¦çš„æ„Ÿå¹å·
        for exclamation in rules["exclamations"]:
            if not text.endswith(exclamation):
                # ç§»é™¤åŸæœ‰æ ‡ç‚¹ï¼Œæ·»åŠ æ–°æ ‡ç‚¹
                clean_text = text.rstrip("!ï¼ã€‚.?ï¼Ÿ")
                augmented_text = clean_text + exclamation
                augmented_texts.append(augmented_text)

        return augmented_texts

    def augment_text_structure(self, text: str) -> List[str]:
        """
        å¥å¼ç»“æ„å¢å¼º

        Args:
            text: åŸå§‹æ–‡æœ¬

        Returns:
            å¢å¼ºåçš„æ–‡æœ¬åˆ—è¡¨
        """
        augmented_texts = []
        rules = self.zh_augmentation_rules if self.language == "zh" else self.en_augmentation_rules

        if self.language == "zh":
            # ä¸­æ–‡å¥å¼å˜æ¢
            if not any(q in text for q in rules["question_words"]):
                # æ·»åŠ ç–‘é—®å¥å¼
                question_starters = ["ä½ çŸ¥é“å—ï¼Ÿ", "çŒœçŒœçœ‹ï¼Œ", "ä½ ç›¸ä¿¡å—ï¼Ÿ"]
                for starter in question_starters:
                    augmented_text = starter + text
                    augmented_texts.append(augmented_text)
        else:
            # è‹±æ–‡å¥å¼å˜æ¢
            if not any(q in text.upper() for q in rules["question_words"]):
                # æ·»åŠ ç–‘é—®å¥å¼
                question_starters = ["GUESS WHAT? ", "CAN YOU BELIEVE? ", "DID YOU KNOW? "]
                for starter in question_starters:
                    augmented_text = starter + text
                    augmented_texts.append(augmented_text)

        return augmented_texts

    def augment_single_sample(self, original: str, viral: str,
                            augmentation_factor: int = 3) -> List[Dict[str, Any]]:
        """
        å¯¹å•ä¸ªæ ·æœ¬è¿›è¡Œå¢å¼º

        Args:
            original: åŸå§‹å­—å¹•
            viral: çˆ†æ¬¾å­—å¹•
            augmentation_factor: å¢å¼ºå€æ•°

        Returns:
            å¢å¼ºåçš„æ ·æœ¬åˆ—è¡¨
        """
        augmented_samples = []

        # å¯¹çˆ†æ¬¾å­—å¹•è¿›è¡Œå¤šç§å¢å¼º
        viral_variants = []

        # åŒä¹‰è¯æ›¿æ¢
        viral_variants.extend(self.augment_text_synonyms(viral))

        # å¼ºåŒ–è¯å¢å¼º
        viral_variants.extend(self.augment_text_intensifiers(viral))

        # æ ‡ç‚¹ç¬¦å·å¢å¼º
        viral_variants.extend(self.augment_text_punctuation(viral))

        # å¥å¼ç»“æ„å¢å¼º
        viral_variants.extend(self.augment_text_structure(viral))

        # å»é‡å¹¶é™åˆ¶æ•°é‡
        viral_variants = list(set(viral_variants))
        viral_variants = viral_variants[:augmentation_factor]

        # ç”Ÿæˆå¢å¼ºæ ·æœ¬
        for i, variant in enumerate(viral_variants):
            augmented_sample = {
                "original": original,
                "viral": variant,
                "augmentation_type": f"variant_{i+1}",
                "source_sample": {"original": original, "viral": viral},
                "language": self.language,
                "created_at": datetime.now().isoformat()
            }
            augmented_samples.append(augmented_sample)

        return augmented_samples

    def augment_dataset(self, training_data: List[Dict[str, Any]],
                       augmentation_factor: int = 3) -> Dict[str, Any]:
        """
        å¯¹æ•´ä¸ªæ•°æ®é›†è¿›è¡Œå¢å¼º

        Args:
            training_data: åŸå§‹è®­ç»ƒæ•°æ®
            augmentation_factor: å¢å¼ºå€æ•°

        Returns:
            å¢å¼ºåçš„æ•°æ®é›†å’Œç»Ÿè®¡ä¿¡æ¯
        """
        augmented_dataset = {
            "original_samples": training_data.copy(),
            "augmented_samples": [],
            "statistics": {
                "original_count": len(training_data),
                "augmented_count": 0,
                "total_count": 0,
                "augmentation_ratio": 0.0,
                "language": self.language
            }
        }

        print(f"ğŸ”„ å¼€å§‹æ•°æ®å¢å¼ºï¼ŒåŸå§‹æ ·æœ¬æ•°: {len(training_data)}")

        # å¯¹æ¯ä¸ªæ ·æœ¬è¿›è¡Œå¢å¼º
        for i, sample in enumerate(training_data):
            original = sample.get("original", "")
            viral = sample.get("viral", "")

            if original and viral:
                # ç”Ÿæˆå¢å¼ºæ ·æœ¬
                augmented_samples = self.augment_single_sample(
                    original, viral, augmentation_factor
                )
                augmented_dataset["augmented_samples"].extend(augmented_samples)

                # æ˜¾ç¤ºè¿›åº¦
                if (i + 1) % 10 == 0 or i == len(training_data) - 1:
                    print(f"  ğŸ“Š å·²å¤„ç† {i + 1}/{len(training_data)} ä¸ªæ ·æœ¬")

        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        augmented_count = len(augmented_dataset["augmented_samples"])
        total_count = len(training_data) + augmented_count

        augmented_dataset["statistics"].update({
            "augmented_count": augmented_count,
            "total_count": total_count,
            "augmentation_ratio": augmented_count / len(training_data) if training_data else 0.0
        })

        print(f"âœ… æ•°æ®å¢å¼ºå®Œæˆ:")
        print(f"  ğŸ“Š åŸå§‹æ ·æœ¬: {len(training_data)}")
        print(f"  ğŸ“Š å¢å¼ºæ ·æœ¬: {augmented_count}")
        print(f"  ğŸ“Š æ€»æ ·æœ¬æ•°: {total_count}")
        print(f"  ğŸ“Š å¢å¼ºæ¯”ä¾‹: {augmented_dataset['statistics']['augmentation_ratio']:.1f}x")

        return augmented_dataset

    def get_quality_score(self, text: str) -> float:
        """
        è¯„ä¼°å¢å¼ºæ–‡æœ¬çš„è´¨é‡

        Args:
            text: å¾…è¯„ä¼°æ–‡æœ¬

        Returns:
            è´¨é‡åˆ†æ•° (0.0-1.0)
        """
        score = 0.0
        rules = self.zh_augmentation_rules if self.language == "zh" else self.en_augmentation_rules

        # æ£€æŸ¥æ˜¯å¦åŒ…å«çˆ†æ¬¾å…³é”®è¯
        viral_keywords = list(rules["synonyms"].keys())
        has_viral_keywords = any(keyword in text for keyword in viral_keywords)
        if has_viral_keywords:
            score += 0.4

        # æ£€æŸ¥æ˜¯å¦æœ‰å¼ºåŒ–è¯
        has_intensifiers = any(intensifier in text for intensifier in rules["intensifiers"])
        if has_intensifiers:
            score += 0.2

        # æ£€æŸ¥æ ‡ç‚¹ç¬¦å·
        has_exclamations = any(exc in text for exc in rules["exclamations"])
        if has_exclamations:
            score += 0.2

        # æ£€æŸ¥æ–‡æœ¬é•¿åº¦åˆç†æ€§
        if self.language == "zh":
            if 5 <= len(text) <= 50:
                score += 0.2
        else:
            words = text.split()
            if 3 <= len(words) <= 20:
                score += 0.2

        return min(score, 1.0)

    def filter_high_quality_samples(self, augmented_dataset: Dict[str, Any],
                                   quality_threshold: float = 0.6) -> Dict[str, Any]:
        """
        è¿‡æ»¤é«˜è´¨é‡å¢å¼ºæ ·æœ¬

        Args:
            augmented_dataset: å¢å¼ºåçš„æ•°æ®é›†
            quality_threshold: è´¨é‡é˜ˆå€¼

        Returns:
            è¿‡æ»¤åçš„é«˜è´¨é‡æ•°æ®é›†
        """
        high_quality_samples = []

        for sample in augmented_dataset["augmented_samples"]:
            viral_text = sample.get("viral", "")
            quality_score = self.get_quality_score(viral_text)

            if quality_score >= quality_threshold:
                sample["quality_score"] = quality_score
                high_quality_samples.append(sample)

        # æ›´æ–°æ•°æ®é›†
        filtered_dataset = augmented_dataset.copy()
        filtered_dataset["augmented_samples"] = high_quality_samples
        filtered_dataset["statistics"]["filtered_count"] = len(high_quality_samples)
        filtered_dataset["statistics"]["quality_threshold"] = quality_threshold

        print(f"ğŸ” è´¨é‡è¿‡æ»¤å®Œæˆ:")
        print(f"  ğŸ“Š è¿‡æ»¤å‰: {len(augmented_dataset['augmented_samples'])} ä¸ªå¢å¼ºæ ·æœ¬")
        print(f"  ğŸ“Š è¿‡æ»¤å: {len(high_quality_samples)} ä¸ªé«˜è´¨é‡æ ·æœ¬")
        print(f"  ğŸ“Š è´¨é‡é˜ˆå€¼: {quality_threshold}")

        return filtered_dataset

    def export_augmented_data(self, augmented_dataset: Dict[str, Any],
                            output_path: Optional[str] = None) -> str:
        """
        å¯¼å‡ºå¢å¼ºåçš„æ•°æ®

        Args:
            augmented_dataset: å¢å¼ºåçš„æ•°æ®é›†
            output_path: è¾“å‡ºè·¯å¾„

        Returns:
            å¯¼å‡ºæ–‡ä»¶è·¯å¾„
        """
        if not output_path:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = f"augmented_data_{self.language}_{timestamp}.json"

        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(augmented_dataset, f, ensure_ascii=False, indent=2)

            print(f"ğŸ’¾ å¢å¼ºæ•°æ®å·²å¯¼å‡º: {output_path}")
            return output_path

        except Exception as e:
            print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
            return ""

    def augment_data(self, data: List[Dict[str, str]]) -> List[Dict[str, str]]:
        """
        æ•°æ®å¢å¼ºä¸»æ–¹æ³• - ä¸ºæµ‹è¯•å…¼å®¹æ€§æ·»åŠ 

        Args:
            data: åŸå§‹æ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« 'original' å’Œ 'viral' å­—æ®µ

        Returns:
            å¢å¼ºåçš„æ•°æ®åˆ—è¡¨
        """
        try:
            augmented_data = []

            for item in data:
                # ä¿ç•™åŸå§‹æ•°æ®
                augmented_data.append(item.copy())

                # ç”Ÿæˆå¢å¼ºç‰ˆæœ¬
                if 'original' in item and 'viral' in item:
                    # å¯¹åŸç‰‡å­—å¹•è¿›è¡Œå¢å¼º
                    original_augmented = self.augment_text(item['original'])

                    # å¯¹çˆ†æ¬¾å­—å¹•è¿›è¡Œå¢å¼º
                    viral_augmented = self.augment_text(item['viral'])

                    # åˆ›å»ºå¢å¼ºæ ·æœ¬
                    augmented_item = {
                        'original': original_augmented,
                        'viral': viral_augmented,
                        'augmented': True,
                        'source': 'data_augmenter'
                    }

                    augmented_data.append(augmented_item)

            print(f"ğŸ”„ æ•°æ®å¢å¼ºå®Œæˆ: {len(data)} -> {len(augmented_data)} æ ·æœ¬")
            return augmented_data

        except Exception as e:
            print(f"âŒ æ•°æ®å¢å¼ºå¤±è´¥: {e}")
            return data  # è¿”å›åŸå§‹æ•°æ®ä½œä¸ºå›é€€

    def augment_text(self, text: str) -> str:
        """
        æ–‡æœ¬å¢å¼ºä¸»æ–¹æ³• - ä¸ºæµ‹è¯•å…¼å®¹æ€§æ·»åŠ 

        Args:
            text: åŸå§‹æ–‡æœ¬

        Returns:
            å¢å¼ºåçš„æ–‡æœ¬
        """
        try:
            if not text or not text.strip():
                return text

            # åº”ç”¨å¤šç§å¢å¼ºç­–ç•¥
            augmented_text = text

            # 1. åŒä¹‰è¯æ›¿æ¢
            if self.language == "zh":
                synonyms = self.zh_augmentation_rules["synonyms"]
                for original, replacements in synonyms.items():
                    if original in augmented_text:
                        import random
                        replacement = random.choice(replacements)
                        augmented_text = augmented_text.replace(original, replacement, 1)
            else:
                synonyms = self.en_augmentation_rules["synonyms"]
                for original, replacements in synonyms.items():
                    if original in augmented_text.upper():
                        import random
                        replacement = random.choice(replacements)
                        augmented_text = augmented_text.replace(original, replacement, 1)

            # 2. å¼ºåŒ–è¯æ·»åŠ 
            if self.language == "zh":
                intensifiers = self.zh_augmentation_rules["intensifiers"]
                keywords = ["éœ‡æ’¼", "æƒŠå‘†", "ç²¾å½©"]
                for keyword in keywords:
                    if keyword in augmented_text:
                        import random
                        intensifier = random.choice(intensifiers)
                        augmented_text = augmented_text.replace(keyword, f"{intensifier}{keyword}", 1)
                        break
            else:
                intensifiers = self.en_augmentation_rules["intensifiers"]
                keywords = ["AMAZING", "INCREDIBLE", "STUNNING"]
                for keyword in keywords:
                    if keyword in augmented_text.upper():
                        import random
                        intensifier = random.choice(intensifiers)
                        augmented_text = augmented_text.replace(keyword, f"{intensifier} {keyword}", 1)
                        break

            # 3. æ ‡ç‚¹ç¬¦å·å¢å¼º
            if self.language == "zh":
                if not augmented_text.endswith(("ï¼", "ï¼ï¼", "ï¼ï¼ï¼")):
                    augmented_text = augmented_text.rstrip("ã€‚") + "ï¼"
            else:
                if not augmented_text.endswith(("!", "!!", "!!!")):
                    augmented_text = augmented_text.rstrip(".") + "!"

            return augmented_text

        except Exception as e:
            print(f"âŒ æ–‡æœ¬å¢å¼ºå¤±è´¥: {e}")
            return text  # è¿”å›åŸå§‹æ–‡æœ¬ä½œä¸ºå›é€€


# ä¸ºäº†ä¿æŒå‘åå…¼å®¹æ€§ï¼Œæ·»åŠ åˆ«å
DataAugment = DataAugmenter


if __name__ == "__main__":
    # æµ‹è¯•æ•°æ®å¢å¼ºå™¨
    augmenter = DataAugmenter("zh")

    test_text = "è¿™ä¸ªè§†é¢‘å¤ªéœ‡æ’¼äº†ï¼ä¸æ•¢ç›¸ä¿¡è¿™æ˜¯çœŸçš„ï¼"
    print(f"åŸæ–‡: {test_text}")

    augmented = augmenter.augment_text(test_text)
    print(f"å¢å¼ºå: {augmented}")

    # æµ‹è¯•è‹±æ–‡å¢å¼º
    en_augmenter = DataAugmenter("en")
    en_text = "This is SHOCKING! You won't believe what happens next!"
    print(f"Original: {en_text}")

    en_augmented = en_augmenter.augment_text(en_text)
    print(f"Augmented: {en_augmented}")