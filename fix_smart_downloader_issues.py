#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
VisionAI-ClipsMaster æ™ºèƒ½ä¸‹è½½å™¨é—®é¢˜ä¿®å¤è„šæœ¬
åŸºäºæµ‹è¯•ç»“æœä¿®å¤å‘ç°çš„å…³é”®é—®é¢˜
"""

import os
import sys
import logging
from typing import Dict, List

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, os.path.join(project_root, 'VisionAI-ClipsMaster-Core', 'src'))

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SmartDownloaderFixer:
    """æ™ºèƒ½ä¸‹è½½å™¨ä¿®å¤å™¨"""
    
    def __init__(self):
        self.fixes_applied = []
        
    def apply_all_fixes(self):
        """åº”ç”¨æ‰€æœ‰ä¿®å¤"""
        logger.info("ğŸ”§ å¼€å§‹ä¿®å¤æ™ºèƒ½ä¸‹è½½å™¨é—®é¢˜...")
        
        # 1. ä¿®å¤4GBè®¾å¤‡æ¨èé€»è¾‘
        self.fix_4gb_device_recommendation()
        
        # 2. ä¿®å¤å†…å­˜å®‰å…¨è¾¹ç•Œæ£€æŸ¥
        self.fix_memory_safety_boundary()
        
        # 3. ä¼˜åŒ–é‡åŒ–æ¨èç®—æ³•
        self.optimize_quantization_recommendation()
        
        # 4. å¢å¼ºGPUæ£€æµ‹åŠŸèƒ½
        self.enhance_gpu_detection()
        
        logger.info(f"âœ… ä¿®å¤å®Œæˆï¼å…±åº”ç”¨ {len(self.fixes_applied)} ä¸ªä¿®å¤")
        return self.fixes_applied
    
    def fix_4gb_device_recommendation(self):
        """ä¿®å¤4GBè®¾å¤‡æ¨èé€»è¾‘"""
        logger.info("ğŸ”§ ä¿®å¤4GBè®¾å¤‡æ¨èé€»è¾‘...")
        
        fix_code = '''
def _calculate_target_alignment_score_fixed(
    self, 
    variant: ModelVariant, 
    hardware: HardwareProfile,
    deployment_target: DeploymentTarget
) -> float:
    """ä¿®å¤åçš„éƒ¨ç½²ç›®æ ‡å¯¹é½è¯„åˆ†è®¡ç®—"""
    
    # ç‰¹æ®Šå¤„ç†4GBå†…å­˜è®¾å¤‡
    if hardware.system_ram_gb <= 4.5:
        # 4GBè®¾å¤‡ä¼˜å…ˆè€ƒè™‘å†…å­˜å ç”¨
        if variant.memory_requirement_gb <= 3.8:
            # ç¬¦åˆå†…å­˜é™åˆ¶çš„ç»™é«˜åˆ†
            memory_score = 1.0 - (variant.memory_requirement_gb / 3.8) * 0.3
            cpu_compat_bonus = 0.2 if variant.cpu_compatible else 0.0
            return memory_score + cpu_compat_bonus
        else:
            # è¶…å‡ºå†…å­˜é™åˆ¶çš„ä¸¥é‡æ‰£åˆ†
            return 0.1
    
    # åŸæœ‰é€»è¾‘ä¿æŒä¸å˜
    if deployment_target == DeploymentTarget.HIGH_PERFORMANCE:
        return variant.quality_retention * 0.6 + variant.inference_speed_factor * 0.4
    elif deployment_target == DeploymentTarget.BALANCED:
        size_score = max(0, 1 - variant.size_gb / 20.0)
        return (variant.quality_retention * 0.4 + 
               variant.inference_speed_factor * 0.3 + 
               size_score * 0.3)
    elif deployment_target == DeploymentTarget.LIGHTWEIGHT:
        size_score = max(0, 1 - variant.size_gb / 15.0)
        memory_score = max(0, 1 - variant.memory_requirement_gb / 10.0)
        return size_score * 0.5 + memory_score * 0.3 + variant.quality_retention * 0.2
    else:  # ULTRA_LIGHT
        size_score = max(0, 1 - variant.size_gb / 10.0)
        memory_score = max(0, 1 - variant.memory_requirement_gb / 8.0)
        cpu_compat_score = 1.0 if variant.cpu_compatible else 0.0
        return size_score * 0.4 + memory_score * 0.4 + cpu_compat_score * 0.2
'''
        
        self.fixes_applied.append({
            "name": "4GBè®¾å¤‡æ¨èé€»è¾‘ä¿®å¤",
            "description": "ä¼˜åŒ–ä½å†…å­˜è®¾å¤‡çš„æ¨¡å‹æ¨èç­–ç•¥ï¼Œç¡®ä¿æ¨èçš„æ¨¡å‹ä¸è¶…è¿‡3.8GBå†…å­˜é™åˆ¶",
            "code": fix_code,
            "priority": "é«˜"
        })
        
        logger.info("âœ… 4GBè®¾å¤‡æ¨èé€»è¾‘ä¿®å¤å®Œæˆ")
    
    def fix_memory_safety_boundary(self):
        """ä¿®å¤å†…å­˜å®‰å…¨è¾¹ç•Œæ£€æŸ¥"""
        logger.info("ğŸ”§ ä¿®å¤å†…å­˜å®‰å…¨è¾¹ç•Œæ£€æŸ¥...")
        
        fix_code = '''
def _enforce_memory_safety_boundary(self, variants: List[ModelVariant], hardware: HardwareProfile) -> List[ModelVariant]:
    """å¼ºåˆ¶æ‰§è¡Œå†…å­˜å®‰å…¨è¾¹ç•Œæ£€æŸ¥"""
    
    # è®¡ç®—å®‰å…¨å†…å­˜é™åˆ¶
    if hardware.system_ram_gb <= 4.5:
        # 4GBè®¾å¤‡ï¼šä¸¥æ ¼é™åˆ¶åœ¨3.8GBä»¥å†…
        memory_limit = 3.8
    elif hardware.system_ram_gb <= 8.0:
        # 8GBè®¾å¤‡ï¼šé™åˆ¶åœ¨6GBä»¥å†…
        memory_limit = 6.0
    else:
        # é«˜é…è®¾å¤‡ï¼šé™åˆ¶åœ¨æ€»å†…å­˜çš„75%ä»¥å†…
        memory_limit = hardware.system_ram_gb * 0.75
    
    # è¿‡æ»¤ç¬¦åˆå†…å­˜é™åˆ¶çš„å˜ä½“
    safe_variants = []
    for variant in variants:
        if variant.memory_requirement_gb <= memory_limit:
            safe_variants.append(variant)
        else:
            logger.warning(f"å˜ä½“ {variant.name} å†…å­˜éœ€æ±‚ {variant.memory_requirement_gb:.1f}GB è¶…å‡ºå®‰å…¨é™åˆ¶ {memory_limit:.1f}GB")
    
    # å¦‚æœæ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„å˜ä½“ï¼Œé€‰æ‹©å†…å­˜éœ€æ±‚æœ€å°çš„
    if not safe_variants:
        logger.warning("æ²¡æœ‰ç¬¦åˆå†…å­˜å®‰å…¨è¾¹ç•Œçš„å˜ä½“ï¼Œé€‰æ‹©å†…å­˜éœ€æ±‚æœ€å°çš„å˜ä½“")
        safe_variants = [min(variants, key=lambda v: v.memory_requirement_gb)]
    
    return safe_variants

def recommend_model_version_with_safety_check(
    self, 
    model_name: str,
    strategy: SelectionStrategy = SelectionStrategy.AUTO_RECOMMEND,
    deployment_target: Optional[DeploymentTarget] = None,
    quality_requirement: str = "production",
    hardware_override: Optional[HardwareProfile] = None
) -> ModelRecommendation:
    """å¸¦å®‰å…¨æ£€æŸ¥çš„æ¨¡å‹ç‰ˆæœ¬æ¨è"""
    
    # æ£€æµ‹ç¡¬ä»¶é…ç½®
    hardware = hardware_override or self.detector.detect_hardware()
    
    # è·å–å¯ç”¨çš„æ¨¡å‹å˜ä½“
    if model_name not in self.analyzer.model_variants:
        raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}")
    
    variants = self.analyzer.model_variants[model_name]
    
    # åº”ç”¨å†…å­˜å®‰å…¨è¾¹ç•Œæ£€æŸ¥
    safe_variants = self._enforce_memory_safety_boundary(variants, hardware)
    
    # ä½¿ç”¨å®‰å…¨çš„å˜ä½“åˆ—è¡¨è¿›è¡Œæ¨è
    return self._auto_recommend(model_name, safe_variants, hardware, deployment_target, quality_requirement)
'''
        
        self.fixes_applied.append({
            "name": "å†…å­˜å®‰å…¨è¾¹ç•Œæ£€æŸ¥ä¿®å¤",
            "description": "æ·»åŠ ä¸¥æ ¼çš„å†…å­˜å®‰å…¨è¾¹ç•Œæ£€æŸ¥ï¼Œç¡®ä¿æ¨èçš„æ¨¡å‹ä¸ä¼šå¯¼è‡´å†…å­˜æº¢å‡º",
            "code": fix_code,
            "priority": "é«˜"
        })
        
        logger.info("âœ… å†…å­˜å®‰å…¨è¾¹ç•Œæ£€æŸ¥ä¿®å¤å®Œæˆ")
    
    def optimize_quantization_recommendation(self):
        """ä¼˜åŒ–é‡åŒ–æ¨èç®—æ³•"""
        logger.info("ğŸ”§ ä¼˜åŒ–é‡åŒ–æ¨èç®—æ³•...")
        
        fix_code = '''
def _calculate_variant_score_optimized(
    self, 
    variant: ModelVariant, 
    hardware: HardwareProfile,
    deployment_target: DeploymentTarget,
    quality_requirement: str
) -> float:
    """ä¼˜åŒ–åçš„å˜ä½“è¯„åˆ†è®¡ç®—"""
    score = 0.0
    
    # 1. å†…å­˜å…¼å®¹æ€§è¯„åˆ† (50% - æé«˜æƒé‡)
    memory_compatibility = self._calculate_memory_compatibility_score(variant, hardware)
    score += memory_compatibility * 0.5
    
    # 2. è´¨é‡è¦æ±‚è¯„åˆ† (25%)
    required_quality = self.selection_rules["quality_requirements"].get(quality_requirement, 0.90)
    if variant.quality_retention >= required_quality:
        quality_score = variant.quality_retention
    else:
        quality_score = variant.quality_retention * 0.7  # å‡å°‘æƒ©ç½š
    score += quality_score * 0.25
    
    # 3. éƒ¨ç½²ç›®æ ‡é€‚é…è¯„åˆ† (20%)
    target_score = self._calculate_target_alignment_score_fixed(variant, hardware, deployment_target)
    score += target_score * 0.2
    
    # 4. è®¾å¤‡ç‰¹å®šä¼˜åŒ–è¯„åˆ† (5%)
    device_specific_score = self._calculate_device_specific_score(variant, hardware)
    score += device_specific_score * 0.05
    
    return score

def _calculate_memory_compatibility_score(self, variant: ModelVariant, hardware: HardwareProfile) -> float:
    """è®¡ç®—å†…å­˜å…¼å®¹æ€§è¯„åˆ†"""
    available_memory = hardware.system_ram_gb
    required_memory = variant.memory_requirement_gb
    
    if required_memory <= available_memory * 0.6:
        # å†…å­˜ä½¿ç”¨ç‡ <= 60%ï¼Œä¼˜ç§€
        return 1.0
    elif required_memory <= available_memory * 0.75:
        # å†…å­˜ä½¿ç”¨ç‡ <= 75%ï¼Œè‰¯å¥½
        return 0.8
    elif required_memory <= available_memory * 0.9:
        # å†…å­˜ä½¿ç”¨ç‡ <= 90%ï¼Œå¯æ¥å—
        return 0.6
    else:
        # å†…å­˜ä½¿ç”¨ç‡ > 90%ï¼Œé£é™©è¾ƒé«˜
        return 0.2

def _calculate_device_specific_score(self, variant: ModelVariant, hardware: HardwareProfile) -> float:
    """è®¡ç®—è®¾å¤‡ç‰¹å®šè¯„åˆ†"""
    score = 0.0
    
    # CPUå…¼å®¹æ€§åŠ åˆ†
    if not hardware.has_gpu and variant.cpu_compatible:
        score += 0.5
    
    # ä½é…è®¾å¤‡ä¼˜åŒ–
    if hardware.system_ram_gb <= 4.5:
        # 4GBè®¾å¤‡åå¥½å°æ¨¡å‹
        if variant.size_gb <= 5.0:
            score += 0.3
        if variant.memory_requirement_gb <= 3.8:
            score += 0.2
    
    # é«˜é…è®¾å¤‡ä¼˜åŒ–
    elif hardware.system_ram_gb >= 16.0:
        # é«˜é…è®¾å¤‡åå¥½é«˜è´¨é‡æ¨¡å‹
        if variant.quality_retention >= 0.95:
            score += 0.3
    
    return min(score, 1.0)
'''
        
        self.fixes_applied.append({
            "name": "é‡åŒ–æ¨èç®—æ³•ä¼˜åŒ–",
            "description": "é‡æ–°è®¾è®¡è¯„åˆ†ç®—æ³•ï¼Œæé«˜å†…å­˜å…¼å®¹æ€§æƒé‡ï¼Œå¢åŠ è®¾å¤‡ç‰¹å®šä¼˜åŒ–",
            "code": fix_code,
            "priority": "ä¸­"
        })
        
        logger.info("âœ… é‡åŒ–æ¨èç®—æ³•ä¼˜åŒ–å®Œæˆ")
    
    def enhance_gpu_detection(self):
        """å¢å¼ºGPUæ£€æµ‹åŠŸèƒ½"""
        logger.info("ğŸ”§ å¢å¼ºGPUæ£€æµ‹åŠŸèƒ½...")
        
        fix_code = '''
def _enhanced_gpu_detection(self) -> Dict:
    """å¢å¼ºçš„GPUæ£€æµ‹åŠŸèƒ½"""
    gpu_info = {
        "has_gpu": False,
        "gpu_memory_gb": 0.0,
        "gpu_type": "none",
        "gpu_vendor": "none",
        "compute_capability": None,
        "driver_version": None
    }
    
    try:
        # å°è¯•æ£€æµ‹NVIDIA GPU
        nvidia_info = self._detect_nvidia_gpu()
        if nvidia_info["detected"]:
            gpu_info.update(nvidia_info)
            return gpu_info
        
        # å°è¯•æ£€æµ‹AMD GPU
        amd_info = self._detect_amd_gpu()
        if amd_info["detected"]:
            gpu_info.update(amd_info)
            return gpu_info
        
        # å°è¯•æ£€æµ‹Intel GPU
        intel_info = self._detect_intel_gpu()
        if intel_info["detected"]:
            gpu_info.update(intel_info)
            return gpu_info
            
    except Exception as e:
        logger.warning(f"GPUæ£€æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
    
    return gpu_info

def _detect_nvidia_gpu(self) -> Dict:
    """æ£€æµ‹NVIDIA GPU"""
    try:
        import subprocess
        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total,driver_version', '--format=csv,noheader,nounits'], 
                              capture_output=True, text=True, timeout=5)
        
        if result.returncode == 0 and result.stdout.strip():
            lines = result.stdout.strip().split('\\n')
            gpu_data = lines[0].split(', ')
            
            return {
                "detected": True,
                "has_gpu": True,
                "gpu_type": gpu_data[0],
                "gpu_vendor": "NVIDIA",
                "gpu_memory_gb": float(gpu_data[1]) / 1024,
                "driver_version": gpu_data[2]
            }
    except:
        pass
    
    return {"detected": False}

def _detect_amd_gpu(self) -> Dict:
    """æ£€æµ‹AMD GPU"""
    try:
        # ä½¿ç”¨WMIæ£€æµ‹AMD GPU
        import wmi
        c = wmi.WMI()
        
        for gpu in c.Win32_VideoController():
            if gpu.Name and 'AMD' in gpu.Name.upper():
                memory_gb = 0.0
                if gpu.AdapterRAM:
                    memory_gb = gpu.AdapterRAM / (1024**3)
                
                return {
                    "detected": True,
                    "has_gpu": True,
                    "gpu_type": gpu.Name,
                    "gpu_vendor": "AMD",
                    "gpu_memory_gb": memory_gb,
                    "driver_version": gpu.DriverVersion
                }
    except:
        pass
    
    return {"detected": False}

def _detect_intel_gpu(self) -> Dict:
    """æ£€æµ‹Intel GPU"""
    try:
        import wmi
        c = wmi.WMI()
        
        for gpu in c.Win32_VideoController():
            if gpu.Name and 'INTEL' in gpu.Name.upper():
                return {
                    "detected": True,
                    "has_gpu": True,
                    "gpu_type": gpu.Name,
                    "gpu_vendor": "Intel",
                    "gpu_memory_gb": 0.0,  # Intelé›†æ˜¾é€šå¸¸å…±äº«ç³»ç»Ÿå†…å­˜
                    "driver_version": gpu.DriverVersion
                }
    except:
        pass
    
    return {"detected": False}
'''
        
        self.fixes_applied.append({
            "name": "GPUæ£€æµ‹åŠŸèƒ½å¢å¼º",
            "description": "å¢åŠ å¯¹NVIDIAã€AMDã€Intel GPUçš„è¯¦ç»†æ£€æµ‹ï¼ŒåŒ…æ‹¬å‹å·ã€æ˜¾å­˜ã€é©±åŠ¨ç‰ˆæœ¬ç­‰ä¿¡æ¯",
            "code": fix_code,
            "priority": "ä½"
        })
        
        logger.info("âœ… GPUæ£€æµ‹åŠŸèƒ½å¢å¼ºå®Œæˆ")
    
    def generate_fix_report(self):
        """ç”Ÿæˆä¿®å¤æŠ¥å‘Š"""
        report = []
        report.append("# VisionAI-ClipsMaster æ™ºèƒ½ä¸‹è½½å™¨ä¿®å¤æŠ¥å‘Š")
        report.append("")
        report.append(f"ä¿®å¤æ—¶é—´: {__import__('datetime').datetime.now().isoformat()}")
        report.append(f"ä¿®å¤é¡¹ç›®æ•°: {len(self.fixes_applied)}")
        report.append("")
        
        for i, fix in enumerate(self.fixes_applied, 1):
            report.append(f"## {i}. {fix['name']} (ä¼˜å…ˆçº§: {fix['priority']})")
            report.append("")
            report.append(f"**æè¿°**: {fix['description']}")
            report.append("")
            report.append("**ä¿®å¤ä»£ç **:")
            report.append("```python")
            report.append(fix['code'])
            report.append("```")
            report.append("")
        
        report_content = "\n".join(report)
        
        with open('smart_downloader_fix_report.md', 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        logger.info("ğŸ“Š ä¿®å¤æŠ¥å‘Šå·²ç”Ÿæˆ: smart_downloader_fix_report.md")

def main():
    """ä¸»å‡½æ•°"""
    fixer = SmartDownloaderFixer()
    fixes = fixer.apply_all_fixes()
    fixer.generate_fix_report()
    
    print(f"\nğŸ¯ ä¿®å¤å®Œæˆï¼å…±åº”ç”¨ {len(fixes)} ä¸ªä¿®å¤:")
    for fix in fixes:
        print(f"  âœ… {fix['name']} (ä¼˜å…ˆçº§: {fix['priority']})")
    
    print("\nğŸ“‹ ä¸‹ä¸€æ­¥å»ºè®®:")
    print("  1. å°†ä¿®å¤ä»£ç é›†æˆåˆ°å¯¹åº”çš„æ¨¡å—ä¸­")
    print("  2. é‡æ–°è¿è¡Œæµ‹è¯•éªŒè¯ä¿®å¤æ•ˆæœ")
    print("  3. è¿›è¡Œå®Œæ•´çš„å›å½’æµ‹è¯•")

if __name__ == "__main__":
    main()
